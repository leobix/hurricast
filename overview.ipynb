{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2016_2018\u001b[m\u001b[m\r\n",
      "\u001b[34mdata_era\u001b[m\u001b[m\r\n",
      "\u001b[34mtensor_completion\u001b[m\u001b[m\r\n",
      "y.npy\r\n",
      "y_train_displacement_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_cat_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_cat_baseline_1980_50_20_90_w8.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Load the data using the loader. Depending on the mode chosen, the iterator will output different dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset and corresponding sizes (null elements included):\n",
      "X_vision torch.Size([3735, 8, 9, 25, 25])\n",
      "X_stat torch.Size([3735, 8, 10])\n",
      "target_displacement torch.Size([3735, 8, 2])\n",
      "target_intensity torch.Size([3735])\n",
      "target_intensity_cat torch.Size([3735])\n",
      "target_intensity_cat_baseline torch.Size([3735])\n",
      "Keeping 3143 samples out of the initial 3735.\n",
      "Reshaping the displacement target...\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "import imp\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    data_dir: str\n",
    "    y_name: str\n",
    "    vision_name: str\n",
    "    predict_at: int\n",
    "    window_size: int\n",
    "    train_test_split: float\n",
    "    mode: str\n",
    "    batch_size: int\n",
    "        \n",
    "args = Args(data_dir=\"data/\", \n",
    "            y_name=\"y.npy\",\n",
    "           vision_name=\"vision_data.npy\", \n",
    "           predict_at=8,\n",
    "           window_size=8, \n",
    "           train_test_split=0.8, \n",
    "           batch_size=10, \n",
    "           mode='intensity')\n",
    "\n",
    "from src.prepro import create_loaders\n",
    "##timeit\n",
    "train_loader, test_loader = create_loaders(**vars(args), debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does create_loaders work ?**\n",
    "```python\n",
    "\n",
    "vision_data = np.load(osp.join(data_dir, vision_name),\n",
    "                          allow_pickle=True)\n",
    "y = np.load(osp.join(data_dir, y_name),\n",
    "                allow_pickle=True)\n",
    "\n",
    "#Create named tensors\n",
    "train_tensors, test_tensors = Prepro.process(\n",
    "        y=y, \n",
    "        vision_data=vision_data,\n",
    "        train_split=train_test_split,\n",
    "        predict_at=predict_at,\n",
    "        window_size=window_size)\n",
    "\n",
    "#Filter the relevant keys\n",
    "train_tensors, test_tensors = filter_keys(\n",
    "     train_tensors, test_tensors, mode=mode)\n",
    "\n",
    "#Unroll in tensordataset\n",
    "train_ds = TensorDataset(*train_tensors.values())\n",
    "test_ds = TensorDataset(*test_tensors.values())\n",
    "    \n",
    "#Create collate_fn \n",
    "collate_fn = create_collate_fn()\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            drop_last=True,\n",
    "                            collate_fn=collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_ds, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False, \n",
    "                            collate_fn=collate_fn)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_model x_viz torch.Size([10, 8, 9, 25, 25])\n",
      "in_model x_stat torch.Size([10, 8, 10])\n",
      "in_loss trg_y torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "in_model, in_loss = next(iter(train_loader))\n",
    "for k, v in in_model.items(): print('in_model', k, v.size())\n",
    "for k, v in in_loss.items(): print('in_loss', k, v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD7CAYAAAChbJLhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAeCUlEQVR4nO2dfWxUV5rmn1vf/ijbQGxMGjedJmHoDQNDb1YNSS+IljAIu0Kyg9IQAp0ls4lWEbMhzNCJRYKUEYjxMI0myod2t2lFPbR2gzJNOjA0HaSk0Xab3Rky2yCn04QNNgkQcBmM7bKryrfq3v2DpFz3Vvm+x8Z2OXOen4TEPffUOW+duo/vuee8930N27ZtEEK0wVdqAwghkwtFT4hmUPSEaAZFT4hmUPSEaEZgsju0LAsDAwMIBoMwDGOyuyfkXz22bcM0TVRUVMDnK7yvT7roBwYG8PHHH092t4Rox7x58xCNRgvKb0v0R44cweuvv45MJoMf/OAH2Lhxo/iZYDAIAGg49SaCqQQA4MKKJ/DN9w84Kw4kPduxk2mxLztjyXXSWbGO2TXkOL6y40Xc2fpS7nioVx7GbEae1WRM76etdDootjE05HcW/Pf/Avynv3MU2bZsi9/nPXbBkDxuAb88/obP6SaS2L8Dldtah+3wy24kwbKMWCcUle31R73H318Vchx3btyBb/ys1VHmqy4X+0FFmVwnEvI8bYTDI54zQ+X4dEFzTmtuxiz6a9euYf/+/fj5z3+OUCiE9evX4zvf+Q7uvvtub2O/mNIHUwmEkn258vz/A4A9OOjZjj2QEm1UEn1KvmDsm0MFZYGbPbn/Z3sUhtGUhWa5BevCl5JFj3QRW7p6nccKojcEwfpC8rj5AqMXPQD4um/m/u9XaCNQLtsSyCr8kbIF0fsKhRZM3HQc+4Km2I/hk+sAI4saAAwo9DPC4/OYF/La2tqwZMkS1NTUoLy8HKtWrcLx48fH2hwhZJIY852+q6sLtbW1ueO6ujqcPXtW+fMXVjzhOP7Dmm1jNaUkfLpnf6lNUOcXLzoOVZZPpfui98PX7dH393smsPXx5fxTXx1bv2TMorcsyzF9sG17VKvx33z/QG5K/4c12zD/mFNEdmLqTO+HPndO7z/dsx9fbxn+I5VWmN5nFab3pjC9TytM71Pu6f0vXgTWvuQoUnmml57HQwrT+8AYpvd9f78HVZtaRtVGSGF6H6pWmN5XC9P7GueU+/xTe3DPf21xlPmmVYj9GJUKz/1lwvQ+Ehnx3FC4Ep98+5ERz495el9fX494PJ47jsfjqKurG2tzhJBJYsyiv//++3Hq1CncuHEDyWQS7777LpYtWzaethFCJoAxT+9nzpyJbdu2YfPmzTBNE+vWrcPChQuVP5/5+CqMvi9WwNcA5oeXHedty3urxjblrZzsoFwn2S1PmRO9lQVl8U+Gy0zTe1oOAGmFOj1Z7yldVuFpPATndHgagB7Tu92ifQlbjD55xxQRQ55Sh33OqbkfQM/N4S2t8oi8Sp3JyPeurKnwCCA86oXMwkfKTNxZFhCuWwDwWQqPPUIdr15seF/Tt7VPH4vFEIvFbqcJQsgkQ997QjSDoidEMyh6QjSDoidEMyh6QjSDoidEMyb9ffovGfzUgP/G8F5w4oJzX1hyFU32e796CACplPz1elMjuzPm2rGde+zTAVzuH35P2fDcNb1FvyHbkvJ5f2e/Qj9ZOG2dBiDuU3g7z0W5sE8cgbzX7FeoE3G585quspDCK7yhsLwHH5ku7/cHKgXfhIpCXwt3meRfoloHUmR6Lzf1rPe1xjs9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGSVzzunpLocRH449d/2aM7ZYf9rb+SZpy6abCkEn+nxycAu3n9B0AN2+4f4thdCAyXHI5hNQ+D7BIk4dbvvKFZxDgoIjUEQMnQlEggphsouFwM4rUwlQUiyMtht/r1zHGvL+TpnLhWUJV96WvhuyI1RFNCHWqZzd43k+OGvk2PlWpRC+XOydEPKvCoqeEM2g6AnRDIqeEM2g6AnRDIqeEM2g6AnRDIqeEM0omXNObzoM+4uoNVEAPa4INoPwdsoYNOS/V0khEg0AmApOM8V6Sue1rZJtXCV2TTHHmnxkdxigmJ+Ku8wvRWWB7HwTNOSoOOmMQrQg01knDKBvcHQZeSJC4k8AqP6anGe365Oo5/lBVwJRP4Arl6qctigk9kwOyFGf7M+8r8tKa+Tvk6nxjgbFOz0hmkHRE6IZFD0hmkHRE6IZFD0hmkHRE6IZFD0hmkHRE6IZJXPOyQKw8iLBZFxRYSTXj5CCg4lK9qCAQp1ifUWzwxYOKjgBBRX6yQrNZBQciYqlvnJHzpGi4gBASnCOStuyQ0zQlh14ZlUOuPoFqivSueOvLZWdakLfmS/WsS7Jl3rmnLdjTVfW6fQyq0hZdUp2zjFS8vhH00Oe5zPmyPdr6w5v56bbEv2mTZtw48YNBAK3mnnppZewaNGi22mSEDLBjFn0tm2js7MT77//fk70hJCpz5if6S9cuAAA2LJlCx588EEcPHhw3IwihEwcY75F9/X1YenSpXjhhRdgmiY2b96Mu+66Cw888MB42kcIGWcM21ZYEVPgjTfewJUrV9DS0uJZL51Oo729fTy6JIR4sGDBAoTDhYt6Y77Tnz59GqZpYunSpQBuPeOP5tm+9/HXYXX1AQCmHfshetb8teN8SnjysBRiwKcUVtWzCu24V++/8Y/b0dn0t7njyVq9Tyus3oddts4/8iz+EPuRo2x6Vn5JVzJXJYp/UNyDKbJ6f+glRB55MXc8fqv3V8U6/+9/eK+8X0qXO45nHftLfL7mbxxl1YbC6r3C7kk07L16X1GZHvGcdUcN+n/0wxHPj/mZvr+/H62trUin00gkEjh8+DBWrlw51uYIIZPEmO/0K1aswJkzZ/DQQw/Bsiw8+uijWLx4sfLnbRiw8+4XtuveId2BVfaafe7UNGNsR7pfqTwfjcczVKUl3zkjRZwT8n0KAKDfd/s+WSozF5UHR7+/8Dvll6Uvy7MS6/0PxTod/1Qj1jllVHmer3SpZRaAbtfsNpxRyR4k/459ae+99nhq5Aw3Pl8Vqj0+e1t7bc888wyeeeaZ22mCEDLJ0A2XEM2g6AnRDIqeEM2g6AnRDIqeEM2g6AnRDIqeEM0o2TuxGRieQTSkgBEqGW7SCu6xKtle3K6tgNNlViW4hTuQRdF+hKgffhWHGIUyFcca2bVYbuTDsBxo4/LADMfxtwH8r7yy+R9ViG302/JlfCEk12n3jezaCgCzfc7MNH8M4JIrCks0K3/nKpXxFxzL+nwj9xPwBT2dc3inJ0QzKHpCNIOiJ0QzKHpCNIOiJ0QzKHpCNIOiJ0QzKHpCNKNkzjkpw4dMnoON29nGFBxeVBxvfAqON71+uZ1IEc+avlFGn1GpnRFMUXOqKezJXaYydm6nEzcd8I7hBgA3bbnOzKAzQ8y3Afzf4PDnBnwRSPzRkByX7utDcgSeUxHvdrIIFSlzohKXcVpWjpyTETIM+Tyco7zO3TpPCNEKip4QzaDoCdEMip4QzaDoCdEMip4QzaDoCdGMku3TZw1nIAp3HregsMceyMqb1ir70ZXylinMImX5vVcKwS8AIKGS7044rxKI42YRvwN3Wb9Ptvef7V7P812ZhNhGxCd9I8BfJJNRtzUczCLkl+9LtkKAjGkKv3N0HOSgkm8wMQ79ePqxCDbwTk+IZlD0hGgGRU+IZlD0hGgGRU+IZlD0hGgGRU+IZlD0hGhGyZxzwpaNQJ5TS8Tl4DIegQBCbo+fou3Ijir9RbKJ5DvkRBSCdSj470DyH5Ey4ADAtCLfZ5rLkekPATnoxGCmmEvSMEYRpxo3d/orxTrVRqEDzx2+cO7/pjgqwE2fXOfr3l8HALAy6+1M1B0o/M71rmusTOE3GlJx4BGckryuBUMwgXd6QjRDSfSJRALNzc24dOkSAKCtrQ2xWAyNjY3Yv3//hBpICBlfRNGfOXMGGzZsQGdnJwAglUqhpaUFr732Go4dO4b29nacPHlyou0khIwTougPHTqEXbt2oa6uDgBw9uxZzJkzBw0NDQgEAojFYjh+/PiEG0oIGR/Ehbzdu3c7jru6ulBbW5s7rqurw7Vr10bdcf0bTzqOv3bsL0bdxmQxq0jZvKPPTrodY+Uel633lMgOVZ74hx+W2oSifKNI2X2/2DbZZtw2o169tywLRt7qo23bjmNVrj7+35Dt6gNwS/CX1+xznB+P1Xt3zvvi7Yx+9X7e0WfxcfOPcscqq/dyvnd59b5KIXRy0hXu+p6jz+J8nq0AcCosr97/PnPT8/yAJYe3vitYI9Zxr94/8Q8/xIE//evcscqVdYdCfvqF3qnnlegOOMf2vl9sw+m1zjWtKoVXvqXXxoHbW70P1FXhmz/5sxHPj3r1vr6+HvF4PHccj8dzU39CyNRn1KJftGgROjo6cPHiRWSzWRw9ehTLli2bCNsIIRPAqKf34XAYe/fuxdatW5FOp7F8+XKsXr161B2bhoFM3mOB22Gh2vaeyoYKcosUEjTk6XDIL9exMmUFZRXW8OcqIU+XowqOQjcN75/DUniM+nXIOe2+p0jZO72/F9u5lujxPL921r8V25hphMU6d1iFjk+zreEpv8KwYZpCSKGswrUgRb2pNwuvOXdZsQxDbpIKj3ppKduRx3lb+Kyy6N97773c/5cuXYp33nlH9aOEkCkEPfII0QyKnhDNoOgJ0QyKnhDNoOgJ0QyKnhDNoOgJ0YySRc5J+gyYeU4Kbt/06YKfeXVY9v0OhWSnGVvyZABQmSiMqJLvkFPmkx2FwgrRaspN758jq/A3+s+Dg47jJIA/Dw44yv40tEBsp2yGt71Xh2THm5sKKalCRfzQZ+d1rZImakDh1hVXsEWqYRpOR6LZAK4HnGWVluwEVK7gny9Z49WLZAHv9IRoBkVPiGZQ9IRoBkVPiGZQ9IRoBkVPiGZQ9IRoRsn26cssG8G8OF/lrphfKRQGV8gnqxA4IRiS989VmJFJOY4zAGZEhsuCQbmfkEJcuqiCz4DEjPlOWzsA1C907tPP+fezxXbs694x8uLvxD3PA0Bfb0SsE08VBii5MzucjuaGT75EM4Z875J3z4GUMPzFAnoMurouU7guIwoBYDIK7YxEQMiywzs9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGSVzzonYFqy8LDblrow2QSGx5GCmMLCFm3BKdoiJlJlinZrpzsAU3a4ylUAcgZDsHuIPe9cJViq0URUqUuYcK6vjstiOPeg9LuUz5CAmlsK49KcL7Y0Y+c4r8iVaphCTQsoYAwBSLtNizjnuX0TFpyZheDueAXKSS3MMSWO/hHd6QjSDoidEMyh6QjSDoidEMyh6QjSDoidEMyh6QjSDoidEM0rmnBM1MrCNYQeQKsPpDBISssZUKDjVlFfIDiQq+IOFjhL5Zf6wHAklUC471vgK/VQcGEHZIcMeKrTFXZbtHiyo4yY7oBJrxhufIXvNFPud88sqhUxHAGBBHpdyyfMGgF+oMuAr7KfGla1GcqpRrSMR8GjDL7SvfKdPJBJobm7GpUuXAADPP/88GhsbsXbtWqxduxYnTpxQbYoQUkKU7vRnzpzBzp070dnZmStrb2/HwYMHUVdXN1G2EUImAKU7/aFDh7Br166cwJPJJK5cuYKWlhbEYjG8/PLLsBQS9xFCSo+S6Hfv3o377rsvd9zd3Y0lS5Zgz549OHToEE6fPo233nprwowkhIwfhm2rryp873vfw09/+lPMnu0MoXzixAm8/fbbePXVV8U20uk02tvbR28pIWRULFiwAOFwYUrxMa3enzt3Dp2dnVi1ahUAwLZtBAKjayr1H1+F3dULACj7xxYkm/Y4zk+l1ftgxGnLtdf/BjP/81/mjqVXYoHJW733RZyTt0+278Pcv/0L8XNupNX7TJ/cxuB14QsBiHdXOI79R15ANvZXuePurBw7v88nv6rqm4DV+3uPPIsPYz9ylEUU7qERIS69Cl4t+OuqMOuNJ0c8P6Z9etu2sWfPHvT29sI0Tbz55ptYuXLlWJoihEwyY7rTz58/H08++SQ2bNiATCaDxsZGNDc3j7dthJAJYFSif++993L/37hxIzZu3DjmjivDQzAiaQCACaDqi/9/iV+Ya02fNeB5HgBC0+QptS0H10FmsHBaHSgbnvL7QgpTx/LbT1llFHEOcWOlCr+zu8xKyvZawrhYpjxJTA7K0Y3SlvMSLHeV1RjyI1rGKnxudVMJ+Yf2C48AVdnCx4hZWWe7KntYM8NJsU7S9JZm1iMqkWF4P/rSDZcQzaDoCdEMip4QzaDoCdEMip4QzaDoCdEMip4QzShZEI07/10Swb5bwRw+AfD17zoDO9hF9pvzMQIK+94K7pkq+CsK92/DtcP9W2mFffqowlAHvP8GFwuQ4cbqLxJEw1U01CuPS6DMe/yzQ/L9wueTxyVgFPaTX+Yvcr6gflZh/BXccMv83nv5ERSObZXf6UcQ8Mn2ZrLy2JUFvW0pKxvZf8GKBuEVJoV3ekI0g6InRDMoekI0g6InRDMoekI0g6InRDMoekI0g6InRDNK5pwTmD0NgcFhJ5HAN+5wnDcqyrwbCMvx16zLXbIhphxcwagstCU4b9he60ZCtiUhB4MwMt6OHb6I/HPZQ4Vt+MJORyZDwWnGFnxM/CHZCcUfkOuE/EUy3OSV+RVsrbLkeIkpW3ZIivq97a10xVzsBzCtyhkQoz8hB/RQoTKa8jyfSo4coMTOeH9X3ukJ0QyKnhDNoOgJ0QyKnhDNoOgJ0QyKnhDNoOgJ0QyKnhDNKJlzjvG1WfANVeWOfXOcmXAREZxzFPBZCvlGkmm5ThFHIKMmz/aA7PhhD3bLdYTEhr5qeUz8RaLv+Kc7k0BG4O34AciZf/w1cvYanJfH1racjkP9AKKVw5+LVMiON4nLNWKdb90VF+tEF3h/p+zNQuec2gXOsYx0yPb29chJOTOm9zVV5jEu2XITXq5gvNMTohkUPSGaQdETohkUPSGaQdETohkUPSGaQdETohkl26dHOALkZwNx78tLURwqomIXRnW1WMf2ywEwjEDhMBllw3utRpVsiwp2f9LzvBGSfy7DV5j5xxd17gv758yUbUkLQT8GvG0FgOoH7pbrBJ174x8BmN2yOHc8dOx/i23Mq5F9ILJpOSOS5CeRTRZek4Vlss+GSuafxIB3MI5yyyPDTcr7OuGdnhDNUBL9K6+8gqamJjQ1NaG1tRUA0NbWhlgshsbGRuzfv39CjSSEjB+i6Nva2vCb3/wGhw8fxttvv40PP/wQR48eRUtLC1577TUcO3YM7e3tOHny5GTYSwi5TUTR19bW4rnnnkMoFEIwGMTcuXPR2dmJOXPmoKGhAYFAALFYDMePH58Mewkht4lh27a8qvAFnZ2d2LBhAx577DF0dHRg3759AG7NBn784x/jJz/5idhGOp1Ge3v72C0mhCixYMEChMOFC4LKq/fnz5/HU089hR07dsDv96OzszN3zrZtGIZCvvg85p4/jpB5K4v2R//mP+Bbv/+5s8I4rN7jhsKbbYnRr95/dP8T+FbbgeGCoPzGmXXlqmyLtHofUXizLeMMKX1u/Qv4o//5V852pivsaozD6r1vvrx67x67j+5dh299+FbuWGX1figuv02psnpfPs97fM1rzrcGL760H3Ne3OYoG7wq/0aJXjlM9mDSO8R7uVd++toapF/ZPuJ5pYW8Dz74AI8//ji2b9+Ohx9+GPX19YjHh19VjMfjqKurU2mKEFJiRNF//vnnePrpp7Fv3z40NTUBABYtWoSOjg5cvHgR2WwWR48exbJlyybcWELI7SNO7w8cOIB0Oo29e/fmytavX4+9e/di69atSKfTWL58OVavXj26nsMRwJ+3nOB2zskKURxUAmQUeZ5xY2QLM6wUECoy1aqoGP5/9TSxCV9GzqRjlw94n79+U+5n7hy5rEbB3qjwCDDjTrENXL8iVrGvfFZYmB6eRgca5EcRBPrEKtleefzj/8f7EaCvrzBYx6dnnWUqGXlsW37UCAW97fVqQ2pfFP3OnTuxc+fOoufeeecd6eOEkCkGPfII0QyKnhDNoOgJ0QyKnhDNoOgJ0QyKnhDNoOgJ0YzSRc7JDN36l3+cjyH8PfIp/L1ScIiBX450UrSvvDIj6O0nDQCYO0+sYkj2qvRTU+gObfzJ/c6CgV65nYB3X4G594lNZCPnxDrW7/6loMzuGnbxNmqni22oXMSpz3rEOtd7KjzP92WdYzIdwPUhp1PZtICc1aeyQq4zMOg9/gNpj+s2GYLXp3mnJ0QzKHpCNIOiJ0QzKHpCNIOiJ0QzKHpCNIOiJ0QzKHpCNKNkzjlGpAJGdtjBwCirHNXnbSlwJgBUKgTPVInAU4z8SD8hOUJPMacZN4bgEIOAQj9uRyITMMpd0WeiM+R2hMhF2aufyKbcMVusYy/8k8LP5ZcpRDbK3vwnuU5avr/dzHqP/2cBZ9DL6QAuusqCGfl6GupTsMX2tsXEyNFx/FYIszw+yzs9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpRuiAaM+oB5O0F17n2dIX9cyMpJ55ERg5WkJ9NZSTsYn3l+QnYfXKABkPBr8Au8/YrMCrlzDSFHwIw5Eo2KfQDQPYJsOX9czvlnbEHABAu8yyzr8uJP4c+iot1erpkPxCvvW8AuLvI9eQuK/PLgVsMyFlwMllvW3oCIwfRCAb83KcnhAxD0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGRQ9IZox6fv0tn1rj9J0dT3kNsUQ9jJ9CokfVP6k+b33QwHADhTuSQ8F8vaX/fIwGj6Fd+GNoPdpKCTmKMKQ+3OWwsAYwrjYchuGQqgCq8jvOJRXZgeK7OO7MKtl/wW71juRBQD4K7zrGCj8QkadK1aBwj49FPbp/dmI5/mg1z79jFs+CV9qzY1hj3Rmgujv78fHH388mV0SoiXz5s1DNFroiDXporcsCwMDAwgGgzCkuwkhZNTYtg3TNFFRUQFfkZRsky56Qkhp4UIeIZpB0ROiGRQ9IZpB0ROiGRQ9IZpB0ROiGRQ9IZpRctEfOXIEa9asQWNjI372s5+V2hxPNm3ahKamJqxduxZr167FmTNnSm1SAYlEAs3Nzbh06RIAoK2tDbFYDI2Njdi/f3+JrSvEbe/zzz+PxsbG3BifOHGixBbe4pVXXkFTUxOamprQ2toKYOqP7YjYJeTq1av2ihUr7J6eHntgYMCOxWL2+fPnS2nSiFiWZX/3u9+1TdMstSkj8rvf/c5ubm627733Xvuzzz6zk8mkvXz5cvvTTz+1TdO0t2zZYv/6178utZk53Pbatm03Nzfb165dK7FlTn7729/a3//+9+10Om0PDQ3Zmzdvto8cOTKlx9aLkt7p29rasGTJEtTU1KC8vByrVq3C8ePHS2nSiFy4cAEAsGXLFjz44IM4ePBgiS0q5NChQ9i1axfq6m4lyzx79izmzJmDhoYGBAIBxGKxKTW+bnuTySSuXLmClpYWxGIxvPzyy7DGmmB0HKmtrcVzzz2HUCiEYDCIuXPnorOzc0qPrReli4YLoKurC7W1tbnjuro6nD17toQWjUxfXx+WLl2KF154AaZpYvPmzbjrrrvwwAMPlNq0HLt373YcFxvfa9euTbZZI+K2t7u7G0uWLMGuXbsQjUbx1FNP4a233sIjjzxSIgtvcc899+T+39nZiV/+8pd47LHHpvTYelHSO71lWY6XbmzbnrIv4SxevBitra2IRqOYPn061q1bh5MnT5baLE++SuMLAA0NDXj11VdRV1eHsrIybNq0aUqN8fnz57Flyxbs2LEDDQ0NX6mxzaekoq+vr0c8PhyzPB6P56Z6U43Tp0/j1KlTuWPbthEIlHSiJPJVGl8AOHfuHH71q1/ljqfSGH/wwQd4/PHHsX37djz88MNfubHNp6Siv//++3Hq1CncuHEDyWQS7777LpYtW1ZKk0akv78fra2tSKfTSCQSOHz4MFauXFlqszxZtGgROjo6cPHiRWSzWRw9enTKji9wS+R79uxBb28vTNPEm2++OSXG+PPPP8fTTz+Nffv2oampCcBXb2zzKemf0ZkzZ2Lbtm3YvHkzTNPEunXrsHDhwlKaNCIrVqzAmTNn8NBDD8GyLDz66KNYvHhxqc3yJBwOY+/evdi6dSvS6TSWL1+O1atXl9qsEZk/fz6efPJJbNiwAZlMBo2NjWhubi61WThw4ADS6TT27t2bK1u/fv1Xamzz4fv0hGhGyZ1zCCGTC0VPiGZQ9IRoBkVPiGZQ9IRoBkVPiGZQ9IRoBkVPiGb8fzzPl8IGM04XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(in_model['x_viz'][0,0,1].detach().numpy());plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Update when loading the tensors directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/X_train_stat_1980_50_20_90_w8.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-8977866696da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m path_train_stat = osp.join(\n\u001b[1;32m      2\u001b[0m     \"data\", \"X_train_stat_1980_50_20_90_w8.npy\")\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train_stat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/graphcnn/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/X_train_stat_1980_50_20_90_w8.npy'"
     ]
    }
   ],
   "source": [
    "path_train_stat = osp.join(\n",
    "    \"data\", \"X_train_stat_1980_50_20_90_w8.npy\")\n",
    "x_train = np.load(path_train_stat)\n",
    "x_train = x_train.reshape(x_train.shape[0], args.window_size, -1)\n",
    "print(x_train.shape)\n",
    "\n",
    "path_test_stat = osp.join(\n",
    "    \"data\", \"X_test_stat_1980_50_20_90_w8.npy\")\n",
    "x_test = np.load(path_test_stat)\n",
    "x_test = x_test.reshape(x_test.shape[0], args.window_size, -1)\n",
    "\n",
    "print(x_test.shape)\n",
    "# Select the first 7 values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_train_stat = osp.join(\"data\", \"y.npy\")\n",
    "#x_train = np.load(path_train_stat, allow_pickle=True)\n",
    "#x_train.shape\n",
    "\n",
    "\n",
    "#x_stat_train = torch.Tensor(np.load('data/X_train_stat_1980_50_20_90_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "#                                        allow_pickle=True).reshape(-1, args.window_size, 30)[:,:,:10])[:,-args.sub_window_size:].to(device)\n",
    "#x_stat_test = torch.Tensor(np.load('data/X_test_stat_1980_50_20_90_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "#                                       allow_pickle=True).reshape(-1, args.window_size, 30)[:,:,:10])[:,-args.sub_window_size:].to(device)\n",
    "#x_viz_train = torch.Tensor(np.load('data/X_train_vision_1980_34_20_120_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "#                                       allow_pickle = True).reshape(-1, args.window_size, 9, 25, 25))[:,-args.sub_window_size:].to(device)\n",
    "#x_viz_test = torch.Tensor(np.load('data/X_test_vision_1980_34_20_120_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "#                                      allow_pickle = True).reshape(-1, args.window_size, 9, 25, 25))[:,-args.sub_window_size:].to(device)\n",
    "\n",
    "#x_stat_train = torch.Tensor(\n",
    "#    np.load('data/X_train_stat_1980_50_20_90_w' + str(8) + '.npy',\n",
    "#                                        allow_pickle=True).reshape(-1, 8, 30\n",
    "#                                                                  )[:,:,:10])[:,-8:].to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Models\n",
    "Experimental version in experimental_models (TO COME, see below).\n",
    "___\n",
    "The different configurations are stored in scripts/config.py.\n",
    "We create a model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_loss.keys()\n",
    "from src.models import factory, hurricast_models\n",
    "from src.models import experimental_models as expm\n",
    "from scripts import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "#How do we encode the data ?\n",
    "cnn_enc = expm.CNNEncoder(**config.encoder_config)\n",
    "x_viz = in_model['x_viz']\n",
    "unrolled = x_viz.unbind(1) #Create \n",
    "\n",
    "encode_fn = lambda x: cnn_enc(x).unsqueeze(1)\n",
    "out = list(map(encode_fn, unrolled))\n",
    "#print(len(out)) --> 8\n",
    "#print(out[0].size()) --> bs, 1, 128\n",
    "out = torch.cat(out, dim=1)\n",
    "print(out.size()) #bs, T, 128\n",
    "\n",
    "\n",
    "#==================\n",
    "#We can specify the split argument so that we apply 3 cnns \n",
    "# to the image (first cnn--> first 3 channels/\n",
    "#second cnn --> 4th to 6th channel etc...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pdb\n",
    "transformer_config = dict(\n",
    "    #out_cnn + number of stat\n",
    "    n_in_decoder=128 + 10,\n",
    "    n_out_decoder=None,\n",
    "    n_out_transformer=128,\n",
    "    hidden_configuration_decoder={\n",
    "        'nhead': 2,\n",
    "        'num_layers': 4,\n",
    "        'dropout': 0.1,  # Default\n",
    "        'dim_feedforward': 2048  # Default\n",
    "    })\n",
    "\n",
    "full_encoder_config = dict(\n",
    "    n_in=3 * 3,\n",
    "    n_out=128,\n",
    "    hidden_configuration=(\n",
    "        ('conv', 64),\n",
    "        ('conv', 64),\n",
    "        ('maxpool', None),\n",
    "        ('conv', 256),\n",
    "        ('maxpool', None),\n",
    "        ('flatten', 256 * 4 * 4),\n",
    "        ('linear', 256),\n",
    "        ('fc', 128)\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transfo_config=dict(\n",
    "                n_in=128+10,\n",
    "                n_head=2, \n",
    "                dim_feedforward=2048,\n",
    "                num_layers=64,\n",
    "                dropout=0.1,\n",
    "                window_size=None, \n",
    "                n_out_unroll=None,\n",
    "                max_len_pe=10,\n",
    "                pool_method='default', \n",
    "                activation='tanh')\n",
    "\n",
    "import imp\n",
    "imp.reload(expm)\n",
    "from src.models import experimental_models as expm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_encoder_config = dict(\n",
    "    n_in=3,\n",
    "    n_out=128,\n",
    "    hidden_configuration=(\n",
    "        ('conv', 64),\n",
    "        ('conv', 64),\n",
    "        ('maxpool', None),\n",
    "        ('conv', 256),\n",
    "        ('maxpool', None),\n",
    "        ('flatten', 256 * 4 * 4),\n",
    "        ('linear', 256),\n",
    "        ('fc', 128)\n",
    "    ))\n",
    "\n",
    "transfo_config=dict(\n",
    "                n_in=128+10,\n",
    "                n_head=2, \n",
    "                dim_feedforward=2048,\n",
    "                num_layers=64,\n",
    "                dropout=0.1,\n",
    "                window_size=None, \n",
    "                n_out_unroll=None,\n",
    "                max_len_pe=10,\n",
    "                pool_method='default', \n",
    "                activation='tanh')\n",
    "\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=split_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=True, \n",
    "    no_stat=False)\n",
    "\n",
    "out = Wrap(**in_model)\n",
    "\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-9e304ff522ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     encoder_name=None)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0min_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Harvard/Harvard-Classes/hurricast/src/models/experimental_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_stat, x_viz)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mfused_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mfused_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Harvard/Harvard-Classes/hurricast/src/models/experimental_models.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Harvard/Harvard-Classes/hurricast/src/models/experimental_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_fuz)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mx_fuz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fuz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;31m#out = x_fuz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m#invert bs, T before transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Harvard/Harvard-Classes/hurricast/src/models/experimental_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \"\"\"\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (10) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#out.size()\n",
    "transfo_config=dict(\n",
    "                n_in=10,\n",
    "                n_head=2, \n",
    "                dim_feedforward=2048,\n",
    "                num_layers=64,\n",
    "                dropout=0.1,\n",
    "                window_size=None, \n",
    "                n_out_unroll=None,\n",
    "                max_len_pe=10,\n",
    "                pool_method='default', \n",
    "                activation='tanh')\n",
    "\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=None,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name=None)\n",
    "\n",
    "out = Wrap(**in_model)\n",
    "\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rec_cells(rnn_type):\n",
    "#    _rec_cells = dict(\n",
    "#        lstm=nn.LSTM, \n",
    "#        gru=nn.GRU, \n",
    "#        rnn=nn.RNN)\n",
    "#    assert rnn_type in _rec_cells.keys(), \"\\\n",
    "#        Wrong type of rnn cell specified. Available cells:{}\".format(\n",
    "#        _rec_cells.keys())\n",
    "    #assert rnn_type != 'lstm', \"LSTM not supported yet\"\n",
    "#    return _rec_cells[rnn_type]\n",
    "\n",
    "\n",
    "#def _get_activation_module(name):\n",
    "#    #TODO: Write a func with check and so on.\n",
    "#    _activations_modules = dict(\n",
    "#        relu=nn.ReLU(),\n",
    "#        gelu=GELU(),\n",
    "#        identity=nn.Identity(),\n",
    "#    )\n",
    "#    return _activations_modules[name]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "#lstm_config = dict(n_in=128+10,\n",
    "#                 hidden_dim=256,\n",
    "#                 rnn_num_layers=2,\n",
    "#                 N_OUT=128,\n",
    "#                 rnn_type='gru',\n",
    "#                 dropout=0.1,\n",
    "#                 activation_fn='tanh',\n",
    "#                 bidir=True)\n",
    "\n",
    "\n",
    "    \n",
    "#lstm_config = dict(n_in=128+10,\n",
    "#                 hidden_dim=256,\n",
    "#                 rnn_num_layers=2,\n",
    "#                 N_OUT=128,\n",
    "#                 rnn_type='gru',\n",
    "#                 dropout=0.1,\n",
    "#                 activation_fn='tanh',\n",
    "#                 bidir=True)\n",
    "#Gru = VanillaRNN(**lstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoded_x_viz = Wrap.encode(in_model['x_viz'])\n",
    "#print(encoded_x_viz.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 138])\n"
     ]
    }
   ],
   "source": [
    "fused_x = Wrap.fusion(in_model['x_stat'], encoded_x_viz)\n",
    "print(fused_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 138])\n"
     ]
    }
   ],
   "source": [
    "out_transformer = Wrap.decode(fused_x)\n",
    "print(out_transformer.size()) #Pooled data: either mean pooling, or cls token..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 138])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_transformer.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, hidden = Gru.rnn(fused_x)\n",
    "hidden = hidden[0]\n",
    "print(hidden.size())\n",
    "torch.cat((hidden[-2, :, :], hidden[-1, :, :]), 1).size()\n",
    "#out_rnn[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 25, 25])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_viz.size()\n",
    "#unrolled = x_viz.unbind(1)\n",
    "#x = unrolled[0]\n",
    "#x.size()\n",
    "#x_split = torch.split(x, 3, dim=1)\n",
    "#x_split[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1089,  0.0503, -0.1470,  ...,  0.2681, -0.5071, -0.2926],\n",
       "        [-0.0448,  0.1818,  0.3278,  ...,  0.4195, -0.3653, -0.3424],\n",
       "        [-0.1918, -0.0556,  0.0775,  ...,  0.4764, -0.5221, -0.1965],\n",
       "        ...,\n",
       "        [-0.0077, -0.0079, -0.0717,  ...,  0.5837, -0.2861,  0.0182],\n",
       "        [-0.2135, -0.1460,  0.1935,  ...,  0.4441, -0.4734, -0.1142],\n",
       "        [ 0.0333,  0.0822, -0.1646,  ...,  0.4170, -0.2722,  0.0203]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gru(fused_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#import imp\n",
    "#import src\n",
    "#imp.reload(src.models)\n",
    "#imp.reload(src.models.factory)\n",
    "#imp.reload(src.models.hurricast_models)\n",
    "#import src.models\n",
    "#del args.device\n",
    "#del args.writer\n",
    "from dataclasses import dataclass, field, asdict\n",
    "import imp\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    data_dir: str\n",
    "    y_name: str\n",
    "    vision_name: str\n",
    "    predict_at: int\n",
    "    window_size: int\n",
    "    train_test_split: float\n",
    "    mode: str\n",
    "    batch_size: int\n",
    "        \n",
    "args = Args(data_dir=\"data/\", \n",
    "            y_name=\"y.npy\",\n",
    "           vision_name=\"vision_data.npy\", \n",
    "           predict_at=8,\n",
    "           window_size=8, \n",
    "           train_test_split=0.8, \n",
    "           batch_size=10, \n",
    "           mode='intensity')\n",
    "\"\"\"\n",
    "#assert hasaatr()\n",
    "Gru.N_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prepare the training using  cpu\n"
     ]
    }
   ],
   "source": [
    "#if args.encdec: decoder_config = config.encdec_config\n",
    "#elif args.transformer: decoder_config=config.transformer_config\n",
    "#else: decoder_config = config.lineartransform_config\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts import config\n",
    "from src.models import factory, hurricast_models\n",
    "from src import setup\n",
    "#Just a hack for the notebook\n",
    "args.encdec = True\n",
    "args.transformer = False\n",
    "args.output_dir = 'results/companion_notebook'\n",
    "writer = setup.create_board(args)\n",
    "device = setup.create_device(gpu_nb=-1)\n",
    "args.device = None\n",
    "args.writer = writer\n",
    "# End of the hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENCDEC(\n",
       "  (encoder): CNNEncoder(\n",
       "    (activation): ReLU()\n",
       "    (layers): Sequential(\n",
       "      (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU()\n",
       "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): Flatten()\n",
       "      (12): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ReLU()\n",
       "      (15): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder_cells): Sequential(\n",
       "    (0): GRUCell(138, 128)\n",
       "    (1): GRUCell(128, 128)\n",
       "  )\n",
       "  (last_linear): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_config = config.encoder_config\n",
    "decoder_config = config.encdec_config\n",
    "\n",
    "model = factory.get_model(\n",
    "        mode=args.mode, \n",
    "        encoder_config=encoder_config,\n",
    "        decoder_config=decoder_config, \n",
    "        args=args)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the refistered models?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CNNEncoder': <class 'src.models.hurricast_models.CNNEncoder'>, 'ENCDEC': <class 'src.models.hurricast_models.ENCDEC'>, 'TRANSFORMER': <class 'src.models.hurricast_models.TRANSFORMER'>, 'LINEARTransform': <class 'src.models.hurricast_models.LINEARTransform'>}\n"
     ]
    }
   ],
   "source": [
    "print(factory.MODEL_REGISTRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model creation is wrapped using the models/factory.py file and the function:**\n",
    "```py\n",
    "def get_model(mode, encoder_config, decoder_config, args):\n",
    "    #Needs to upload window size and _OUT_DECODER\n",
    "    #Get some\n",
    "    assert (int(args.encdec) + int(args.transformer) < 2), \"\\\n",
    "    Only one of encdec or transformer can be specified\"\n",
    "\n",
    "    _encoder = MODEL_REGISTRY['CNNEncoder']\n",
    "    if args.encdec:\n",
    "        _model = MODEL_REGISTRY['ENCDEC']\n",
    "    elif args.transformer:\n",
    "        _model = MODEL_REGISTRY['TRANSFORMER']\n",
    "    else:\n",
    "        model = MODEL_REGISTRY['LINEARTransform']\n",
    "\n",
    "    N_OUT_DECODER = 7 if mode == 'intensity_cat' else (\n",
    "        2 - (mode == 'intensity'))  # 7 classes of storms if categorical\n",
    "\n",
    "    #Encoder\n",
    "    encoder_config = encoder_config if isinstance(encoder_config, dict)\\\n",
    "        else vars(encoder_config)\n",
    "\n",
    "    encoder = _encoder(**encoder_config)\n",
    "\n",
    "    #Decoder: Update the config\n",
    "    decoder_config = decoder_config if isinstance(decoder_config, dict)\\\n",
    "        else vars(encoder_config)\n",
    "\n",
    "    if not args.encdec and not args.transformer:\n",
    "        decoder_config['target_intensity'] = args.target_intensity,\n",
    "        decoder_config['target_intensity_cat'] = args.target_intensity_cat\n",
    "\n",
    "    else:\n",
    "        decoder_config['encoder'] = encoder\n",
    "        decoder_config['window_size'] = args.window_size\n",
    "        decoder_config['n_out_decoder'] = N_OUT_DECODER\n",
    "\n",
    "    model = _model(**decoder_config)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    if args.writer is not None:\n",
    "        configs = [encoder_config, decoder_config]\n",
    "        config_ = \"\"\n",
    "        for config__ in configs:\n",
    "            config_ += \"{}\\n\".format(config__)\n",
    "        args.writer.add_text('Configs', config_)\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3  - Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Inner Training loop:   0%|          | 0/251 [00:00<?, ?it/s]\u001b[A/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\n",
      "Inner Training loop:   0%|          | 1/251 [00:00<03:24,  1.22it/s]\u001b[A\n",
      "Inner Training loop:   1%|          | 2/251 [00:01<03:25,  1.21it/s]\u001b[A\n",
      "Inner Training loop:   1%|          | 3/251 [00:02<03:34,  1.16it/s]\u001b[A\n",
      "Inner Training loop:   2%|         | 4/251 [00:03<03:36,  1.14it/s]\u001b[A\n",
      "Inner Training loop:   2%|         | 5/251 [00:04<03:43,  1.10it/s]\u001b[A\n",
      "Inner Training loop:   2%|         | 6/251 [00:05<03:44,  1.09it/s]\u001b[A\n",
      "Inner Training loop:   3%|         | 7/251 [00:06<03:47,  1.07it/s]\u001b[A\n",
      "Inner Training loop:   3%|         | 8/251 [00:07<03:50,  1.05it/s]\u001b[A\n",
      "Inner Training loop:   4%|         | 9/251 [00:08<04:01,  1.00it/s]\u001b[A\n",
      "Inner Training loop:   4%|         | 10/251 [00:09<03:54,  1.03it/s]\u001b[A\n",
      "Inner Training loop:   4%|         | 11/251 [00:10<03:51,  1.04it/s]\u001b[A\n",
      "Inner Training loop:   5%|         | 12/251 [00:11<03:46,  1.06it/s]\u001b[A\n",
      "Inner Training loop:   5%|         | 13/251 [00:12<03:37,  1.09it/s]\u001b[A\n",
      "Inner Training loop:   6%|         | 14/251 [00:12<03:23,  1.16it/s]\u001b[A\n",
      "Inner Training loop:   6%|         | 15/251 [00:13<03:16,  1.20it/s]\u001b[A\n",
      "Inner Training loop:   6%|         | 16/251 [00:14<03:06,  1.26it/s]\u001b[A\n",
      "Inner Training loop:   7%|         | 17/251 [00:15<02:58,  1.31it/s]\u001b[A\n",
      "Inner Training loop:   7%|         | 18/251 [00:15<02:53,  1.34it/s]\u001b[A\n",
      "Inner Training loop:   8%|         | 19/251 [00:16<02:49,  1.37it/s]\u001b[A\n",
      "Inner Training loop:   8%|         | 20/251 [00:17<03:10,  1.21it/s]\u001b[A\n",
      "Inner Training loop:   8%|         | 21/251 [00:18<03:19,  1.15it/s]\u001b[A\n",
      "Inner Training loop:   9%|         | 22/251 [00:19<03:16,  1.17it/s]\u001b[A\n",
      "Inner Training loop:   9%|         | 23/251 [00:20<03:22,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  10%|         | 24/251 [00:21<03:20,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  10%|         | 25/251 [00:21<03:10,  1.18it/s]\u001b[A\n",
      "Inner Training loop:  10%|         | 26/251 [00:22<03:06,  1.21it/s]\u001b[A\n",
      "Inner Training loop:  11%|         | 27/251 [00:23<03:02,  1.23it/s]\u001b[A\n",
      "Inner Training loop:  11%|         | 28/251 [00:24<02:53,  1.29it/s]\u001b[A\n",
      "Inner Training loop:  12%|        | 29/251 [00:24<02:47,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  12%|        | 30/251 [00:25<02:41,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  12%|        | 31/251 [00:26<02:38,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  13%|        | 32/251 [00:26<02:36,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  13%|        | 33/251 [00:27<02:38,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  14%|        | 34/251 [00:28<02:39,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  14%|        | 35/251 [00:29<02:37,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  14%|        | 36/251 [00:29<02:34,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  15%|        | 37/251 [00:30<02:32,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  15%|        | 38/251 [00:31<02:30,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  16%|        | 39/251 [00:31<02:29,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  16%|        | 40/251 [00:32<02:30,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  16%|        | 41/251 [00:33<02:33,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  17%|        | 42/251 [00:34<02:30,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  17%|        | 43/251 [00:34<02:29,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  18%|        | 44/251 [00:35<02:27,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  18%|        | 45/251 [00:36<02:26,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  18%|        | 46/251 [00:36<02:26,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  19%|        | 47/251 [00:37<02:26,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  19%|        | 48/251 [00:38<02:31,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  20%|        | 49/251 [00:39<02:27,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  20%|        | 50/251 [00:39<02:26,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  20%|        | 51/251 [00:40<02:23,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  21%|        | 52/251 [00:41<02:21,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  21%|        | 53/251 [00:42<02:25,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  22%|       | 54/251 [00:43<02:40,  1.22it/s]\u001b[A\n",
      "Inner Training loop:  22%|       | 55/251 [00:43<02:43,  1.20it/s]\u001b[A\n",
      "Inner Training loop:  22%|       | 56/251 [00:44<02:36,  1.25it/s]\u001b[A\n",
      "Inner Training loop:  23%|       | 57/251 [00:45<02:29,  1.30it/s]\u001b[A\n",
      "Inner Training loop:  23%|       | 58/251 [00:46<02:24,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  24%|       | 59/251 [00:46<02:21,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  24%|       | 60/251 [00:47<02:21,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  24%|       | 61/251 [00:48<02:20,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  25%|       | 62/251 [00:48<02:18,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  25%|       | 63/251 [00:49<02:16,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  25%|       | 64/251 [00:50<02:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  26%|       | 65/251 [00:51<02:13,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  26%|       | 66/251 [00:51<02:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  27%|       | 67/251 [00:52<02:14,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  27%|       | 68/251 [00:53<02:16,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  27%|       | 69/251 [00:54<02:13,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  28%|       | 70/251 [00:54<02:11,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  28%|       | 71/251 [00:55<02:09,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  29%|       | 72/251 [00:56<02:08,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  29%|       | 73/251 [00:56<02:06,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  29%|       | 74/251 [00:57<02:08,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  30%|       | 75/251 [00:58<02:09,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  30%|       | 76/251 [00:59<02:07,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  31%|       | 77/251 [00:59<02:05,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  31%|       | 78/251 [01:00<02:02,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  31%|      | 79/251 [01:01<02:01,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  32%|      | 80/251 [01:01<02:01,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  32%|      | 81/251 [01:02<02:02,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  33%|      | 82/251 [01:03<02:04,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  33%|      | 83/251 [01:04<02:02,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  33%|      | 84/251 [01:04<02:00,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  34%|      | 85/251 [01:05<01:59,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  34%|      | 86/251 [01:06<01:58,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  35%|      | 87/251 [01:07<01:59,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  35%|      | 88/251 [01:07<01:57,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  35%|      | 89/251 [01:08<01:59,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  36%|      | 90/251 [01:09<01:57,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  36%|      | 91/251 [01:09<01:55,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  37%|      | 92/251 [01:10<01:53,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  37%|      | 93/251 [01:11<01:52,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  37%|      | 94/251 [01:12<01:54,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  38%|      | 95/251 [01:12<01:51,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  38%|      | 96/251 [01:13<01:52,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  39%|      | 97/251 [01:14<01:50,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  39%|      | 98/251 [01:14<01:50,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  39%|      | 99/251 [01:15<01:49,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  40%|      | 100/251 [01:16<01:48,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  40%|      | 101/251 [01:17<01:49,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  41%|      | 102/251 [01:17<01:47,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  41%|      | 103/251 [01:18<01:48,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  41%|     | 104/251 [01:19<01:46,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  42%|     | 105/251 [01:20<01:44,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  42%|     | 106/251 [01:20<01:43,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  43%|     | 107/251 [01:21<01:43,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  43%|     | 108/251 [01:22<01:44,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  43%|     | 109/251 [01:22<01:42,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  44%|     | 110/251 [01:23<01:42,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  44%|     | 111/251 [01:24<01:40,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  45%|     | 112/251 [01:25<01:38,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  45%|     | 113/251 [01:25<01:37,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  45%|     | 114/251 [01:26<01:36,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  46%|     | 115/251 [01:27<01:37,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  46%|     | 116/251 [01:27<01:36,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  47%|     | 117/251 [01:28<01:36,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  47%|     | 118/251 [01:29<01:34,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  47%|     | 119/251 [01:30<01:33,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  48%|     | 120/251 [01:30<01:32,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  48%|     | 121/251 [01:31<01:30,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  49%|     | 122/251 [01:32<01:32,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  49%|     | 123/251 [01:32<01:31,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  49%|     | 124/251 [01:33<01:31,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  50%|     | 125/251 [01:34<01:29,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  50%|     | 126/251 [01:35<01:28,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  51%|     | 127/251 [01:35<01:27,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  51%|     | 128/251 [01:36<01:26,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  51%|    | 129/251 [01:37<01:28,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  52%|    | 130/251 [01:37<01:26,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  52%|    | 131/251 [01:38<01:27,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  53%|    | 132/251 [01:39<01:26,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  53%|    | 133/251 [01:40<01:25,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  53%|    | 134/251 [01:40<01:30,  1.29it/s]\u001b[A\n",
      "Inner Training loop:  54%|    | 135/251 [01:41<01:28,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  54%|    | 136/251 [01:42<01:27,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  55%|    | 137/251 [01:43<01:25,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  55%|    | 138/251 [01:43<01:24,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  55%|    | 139/251 [01:44<01:22,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  56%|    | 140/251 [01:45<01:21,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  56%|    | 141/251 [01:46<01:19,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  57%|    | 142/251 [01:46<01:20,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  57%|    | 143/251 [01:47<01:20,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  57%|    | 144/251 [01:48<01:20,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  58%|    | 145/251 [01:49<01:18,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  58%|    | 146/251 [01:49<01:16,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  59%|    | 147/251 [01:50<01:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  59%|    | 148/251 [01:51<01:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  59%|    | 149/251 [01:51<01:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  60%|    | 150/251 [01:52<01:12,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  60%|    | 151/251 [01:53<01:13,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  61%|    | 152/251 [01:54<01:11,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  61%|    | 153/251 [01:54<01:10,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  61%|   | 154/251 [01:55<01:08,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  62%|   | 155/251 [01:56<01:11,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  62%|   | 156/251 [01:57<01:14,  1.28it/s]\u001b[A\n",
      "Inner Training loop:  63%|   | 157/251 [01:58<01:14,  1.26it/s]\u001b[A\n",
      "Inner Training loop:  63%|   | 158/251 [01:58<01:13,  1.26it/s]\u001b[A\n",
      "Inner Training loop:  63%|   | 159/251 [01:59<01:10,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  64%|   | 160/251 [02:00<01:07,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  64%|   | 161/251 [02:00<01:05,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  65%|   | 162/251 [02:01<01:03,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  65%|   | 163/251 [02:02<01:04,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  65%|   | 164/251 [02:03<01:02,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  66%|   | 165/251 [02:03<01:02,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  66%|   | 166/251 [02:04<01:01,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  67%|   | 167/251 [02:05<00:59,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  67%|   | 168/251 [02:05<00:58,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  67%|   | 169/251 [02:06<00:57,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  68%|   | 170/251 [02:07<00:58,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  68%|   | 171/251 [02:08<00:57,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  69%|   | 172/251 [02:08<00:57,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  69%|   | 173/251 [02:09<00:55,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  69%|   | 174/251 [02:10<00:54,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  70%|   | 175/251 [02:10<00:53,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  70%|   | 176/251 [02:11<00:52,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  71%|   | 177/251 [02:12<00:53,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  71%|   | 178/251 [02:13<00:51,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  71%|  | 179/251 [02:13<00:52,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  72%|  | 180/251 [02:14<00:50,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  72%|  | 181/251 [02:15<00:49,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  73%|  | 182/251 [02:15<00:48,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  73%|  | 183/251 [02:16<00:47,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  73%|  | 184/251 [02:17<00:50,  1.32it/s]\u001b[A\n",
      "Inner Training loop:  74%|  | 185/251 [02:18<00:55,  1.18it/s]\u001b[A\n",
      "Inner Training loop:  74%|  | 186/251 [02:19<00:56,  1.16it/s]\u001b[A\n",
      "Inner Training loop:  75%|  | 187/251 [02:20<00:56,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  75%|  | 188/251 [02:21<00:56,  1.11it/s]\u001b[A\n",
      "Inner Training loop:  75%|  | 189/251 [02:22<00:54,  1.14it/s]\u001b[A\n",
      "Inner Training loop:  76%|  | 190/251 [02:22<00:51,  1.19it/s]\u001b[A\n",
      "Inner Training loop:  76%|  | 191/251 [02:23<00:49,  1.22it/s]\u001b[A\n",
      "Inner Training loop:  76%|  | 192/251 [02:24<00:46,  1.28it/s]\u001b[A\n",
      "Inner Training loop:  77%|  | 193/251 [02:24<00:43,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  77%|  | 194/251 [02:25<00:41,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  78%|  | 195/251 [02:26<00:40,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  78%|  | 196/251 [02:27<00:40,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  78%|  | 197/251 [02:27<00:38,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  79%|  | 198/251 [02:28<00:38,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  79%|  | 199/251 [02:29<00:37,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  80%|  | 200/251 [02:29<00:36,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  80%|  | 201/251 [02:30<00:35,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  80%|  | 202/251 [02:31<00:34,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  81%|  | 203/251 [02:32<00:34,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  81%| | 204/251 [02:32<00:33,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  82%| | 205/251 [02:33<00:33,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  82%| | 206/251 [02:34<00:32,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  82%| | 207/251 [02:34<00:31,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  83%| | 208/251 [02:35<00:30,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  83%| | 209/251 [02:36<00:29,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  84%| | 210/251 [02:37<00:29,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  84%| | 211/251 [02:37<00:28,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  84%| | 212/251 [02:38<00:28,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  85%| | 213/251 [02:39<00:27,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  85%| | 214/251 [02:39<00:26,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  86%| | 215/251 [02:40<00:25,  1.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Training loop:  86%| | 216/251 [02:41<00:24,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  86%| | 217/251 [02:42<00:24,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  87%| | 218/251 [02:42<00:23,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  87%| | 219/251 [02:43<00:23,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  88%| | 220/251 [02:44<00:22,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  88%| | 221/251 [02:44<00:21,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  88%| | 222/251 [02:45<00:20,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  89%| | 223/251 [02:46<00:19,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  89%| | 224/251 [02:47<00:19,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  90%| | 225/251 [02:47<00:18,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  90%| | 226/251 [02:48<00:18,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  90%| | 227/251 [02:49<00:17,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  91%| | 228/251 [02:50<00:16,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  91%| | 229/251 [02:50<00:15,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  92%|| 230/251 [02:51<00:15,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  92%|| 231/251 [02:52<00:14,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  92%|| 232/251 [02:52<00:13,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  93%|| 233/251 [02:53<00:13,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  93%|| 234/251 [02:54<00:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  94%|| 235/251 [02:55<00:11,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  94%|| 236/251 [02:55<00:10,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  94%|| 237/251 [02:56<00:09,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  95%|| 238/251 [02:57<00:09,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  95%|| 239/251 [02:57<00:08,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  96%|| 240/251 [02:58<00:07,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  96%|| 241/251 [02:59<00:07,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  96%|| 242/251 [03:00<00:06,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  97%|| 243/251 [03:00<00:05,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  97%|| 244/251 [03:01<00:04,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  98%|| 245/251 [03:02<00:04,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  98%|| 246/251 [03:02<00:03,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  98%|| 247/251 [03:03<00:02,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  99%|| 248/251 [03:04<00:02,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  99%|| 249/251 [03:05<00:01,  1.41it/s]\u001b[A\n",
      "Inner Training loop: 100%|| 250/251 [03:05<00:00,  1.41it/s]\u001b[A\n",
      "Inner Training loop: 100%|| 251/251 [03:06<00:00,  1.35it/s]\u001b[A\n",
      "/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([629])) that is different to the input size (torch.Size([629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 0 | Loss 0.9798471331596375: 100%|| 1/1 [03:14<00:00, 194.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write confusion_matrix due to name 'workspace' is not defined\n",
      "Could not write accuracy due to name 'workspace' is not defined\n",
      "Could not write precision due to name 'workspace' is not defined\n",
      "Could not write recall due to name 'workspace' is not defined\n",
      "Could not write f1 due to name 'workspace' is not defined\n",
      "Could not write f1_micro due to name 'workspace' is not defined\n",
      "Could not write f1_macro due to name 'workspace' is not defined\n",
      "Could not write classification_report due to name 'workspace' is not defined\n",
      "Epoch: 01 | Time: 3m 14s\n",
      "\tTrain Loss: 1.0093 | Train PPL:   2.744\n",
      "\t Val. Loss: 0.980 |  Val. PPL:   2.664\n",
      "\t Final test ACC 0.980\n",
      "Problem 'Args' object has no attribute 'lr'\n",
      "Problem 'Args' object has no attribute 'l2_reg'\n",
      "Problem 'Args' object has no attribute 'lr'\n",
      "Problem 'Args' object has no attribute 'model'\n",
      "Problem 'Args' object has no attribute 'num_epochs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([629])) that is different to the input size (torch.Size([629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#Hack for the notebook\n",
    "from src import metrics, run\n",
    "args.n_epochs = 1\n",
    "args.get_training_stats = True\n",
    "task = 'regression'\n",
    "train_loss_fn, \\\n",
    "eval_loss_fn, metrics_fn = metrics.create_metrics_fn(task)\n",
    "\n",
    "best_model, \\\n",
    "        optimizer, \\\n",
    "        training_stats = run.train(\n",
    "            model, optimizer,\n",
    "            num_epochs=args.n_epochs,\n",
    "            train_loss_fn=train_loss_fn,\n",
    "            test_loss_fn=eval_loss_fn,\n",
    "            metrics_fn=metrics_fn,\n",
    "            train_iterator=train_loader,\n",
    "            val_iterator=test_loader,\n",
    "            test_iterator=test_loader,\n",
    "            mode=args.mode,\n",
    "            task=task,\n",
    "            get_training_stats=args.get_training_stats,\n",
    "            clip=None,\n",
    "            scheduler=None,\n",
    "            l2_reg=0.,\n",
    "            save=False,\n",
    "            args=args,\n",
    "            output_dir=args.output_dir,\n",
    "            writer=args.writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the training work exactly?\n",
    "1. **We Backprop and train for one epoch**\n",
    "```py\n",
    "train_losses, \\\n",
    "preds, true_preds = train_epoch(\n",
    "                        model=model,\n",
    "                        train_iterator=train_iterator,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=train_loss_fn,\n",
    "                        global_step=epoch,\n",
    "                        task=get_training_stats,\n",
    "                        return_pt=True,\n",
    "                        l2_reg=l2_reg,\n",
    "                        clip=clip,\n",
    "                        scheduler=scheduler)\n",
    "```\n",
    "2. **Obtain the training metrics.**\n",
    "```py\n",
    "train_metrics = metrics_fn(preds, true_preds)\n",
    "```   \n",
    "3. **Eval (metrics obtained in the function directly).**\n",
    "```py\n",
    "preds, true_preds, \\\n",
    "valid_loss, eval_metrics = evaluate(\n",
    "                                    model=model, \n",
    "                                    iterator=val_iterator,\n",
    "                                    loss_fn=test_loss_fn,\n",
    "                                    metrics_func=metrics_fn,\n",
    "                                    task=task)\n",
    "```\n",
    "\n",
    "**We repeat the above for each epoch.**\n",
    "\n",
    "The final output of the training is: \n",
    "```py\n",
    "best_model, optimizer, training_stats : dict = {\n",
    "                                'train_metrics': ...,\n",
    "                                'eval_metrics': ...,\n",
    "                                'test_metrics': ...,\n",
    "                                'test_preds': ...,\n",
    "                                'test_labels': ...\n",
    "                                }\n",
    "```                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
