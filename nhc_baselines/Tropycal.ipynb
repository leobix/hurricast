{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/plot/plot.py:16: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tracks/plot.py:24: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/dataset.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(warn_message)\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/plot.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/recon/plot.py:22: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n"
     ]
    }
   ],
   "source": [
    "import tropycal.tracks as tracks\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data_processing as proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining forecast data\n",
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (12.45 seconds)\n",
      "timesteps of forecast for  joyce 29\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  kirk 33\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  leslie 84\n",
      "timesteps of forecast for  rosa 34\n",
      "no forecast for walaka 2018\n",
      "timesteps of forecast for  sergio 61\n",
      "timesteps of forecast for  michael 28\n",
      "timesteps of forecast for  nadine 20\n",
      "timesteps of forecast for  tara 16\n",
      "timesteps of forecast for  vicente 18\n",
      "timesteps of forecast for  willa 29\n",
      "The dataframe of storms with forecast has been created.\n",
      "one-hot added for  BASIN\n",
      "df0 columns : Index(['SID', 'ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
      "       'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
      "       'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category',\n",
      "       'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp',\n",
      "       'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'HWRF_24_lat',\n",
      "       'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'AP01_24_lat',\n",
      "       'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp', 'NAM_24_lat',\n",
      "       'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp', 'basin_EP', 'basin_NI',\n",
      "       'basin_SI', 'basin_SP', 'basin_WP'],\n",
      "      dtype='object')\n",
      "The dictionary of storms has been created.\n",
      "The trajectories have now been padded.\n",
      "There are 5 storms with 44 features, and maximum number of steps is 120 and minimum is 120.\n",
      "creating tensor, dropping SID and ISO_TIME features\n",
      "The tensor has now been created.\n"
     ]
    }
   ],
   "source": [
    "from utils import data_processing as proc\n",
    "#testing that the code works \n",
    "e, d= proc.prepare_tabular_data_vision(path=\"../data/last3years.csv\", min_wind=50, min_steps=15,\n",
    "                  max_steps=120, get_displacement=True, forecast=True, one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (11.93 seconds)\n",
      "all available models dict_keys(['CARQ', 'NAM', 'AC00', 'AEMN', 'AP01', 'AP02', 'AP03', 'AP04', 'AP05', 'AP06', 'AP07', 'AP08', 'AP09', 'AP10', 'AP11', 'AP12', 'AP13', 'AP14', 'AP15', 'AP16', 'AP17', 'AP18', 'AP19', 'AP20', 'AVNO', 'AVNX', 'CLP5', 'CTCX', 'DSHP', 'GFSO', 'HCCA', 'IVCN', 'IVDR', 'LGEM', 'OCD5', 'PRFV', 'SHF5', 'SHIP', 'TABD', 'TABM', 'TABS', 'TCLP', 'XTRP', 'CMC', 'NGX', 'UKX', 'AEMI', 'AHNI', 'AVNI', 'CEMN', 'CHCI', 'CTCI', 'DSPE', 'EGRR', 'LGME', 'NAMI', 'NEMN', 'RVCN', 'RVCX', 'SHPE', 'TBDE', 'TBME', 'TBSE', 'TVCA', 'TVCE', 'TVCN', 'TVCX', 'TVDG', 'UE00', 'UE01', 'UE02', 'UE03', 'UE04', 'UE05', 'UE06', 'UE07', 'UE08', 'UE09', 'UE10', 'UE11', 'UE12', 'UE13', 'UE14', 'UE15', 'UE16', 'UE17', 'UE18', 'UE19', 'UE20', 'UE21', 'UE22', 'UE23', 'UE24', 'UE25', 'UE26', 'UE27', 'UE28', 'UE29', 'UE30', 'UE31', 'UE32', 'UE33', 'UE34', 'UE35', 'UEMN', 'CEMI', 'CMCI', 'COTC', 'EGRI', 'HMON', 'HWRF', 'NGXI', 'NVGM', 'PRV2', 'PRVI', 'UEMI', 'UKXI', 'CEM2', 'CMC2', 'COTI', 'EGR2', 'HHFI', 'HHNI', 'HMNI', 'HWFI', 'ICON', 'IVRI', 'NGX2', 'NVGI', 'OFCP', 'TCOA', 'TCOE', 'TCON', 'UEM2', 'UKX2', 'CHC2', 'CTC2', 'NAM2', 'OFCL', 'OFPI', 'AEM2', 'AHN2', 'AVN2', 'DRCL', 'HHF2', 'HHN2', 'HMN2', 'HWF2', 'NVG2', 'OFCI', 'OFP2', 'FSSE', 'RI25', 'RI30'])\n"
     ]
    }
   ],
   "source": [
    "#here is an example of how to use Tropycal \n",
    "#read north atlantic datasets\n",
    "hurdat= tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "#example to get forecast for one storm \n",
    "storm = hurdat.get_storm(('michael', 2018))\n",
    "forecast = storm.get_operational_forecasts()\n",
    "print('all available models', storm.get_operational_forecasts().keys()) \n",
    "\n",
    "# I chose models to use:\n",
    "# #'HWRF','SHIP','NVGM','AEMI','NAM \n",
    "model_list = set(['HWRF','SHIP', 'AEMI','CLAP5','EMXI','CMC']).intersection(forecast.keys())\n",
    "\n",
    "#This website has the explanation of all the models: \n",
    "#https://www.nhc.noaa.gov/modelsummary.shtml#:~:text=The%20National%20Hurricane%20Center%20 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get forecast of hurricane based on name and year \n",
    "def get_forecast(hurdat, name, year, pred=24): #pred: hours prediction \n",
    "    try:\n",
    "        storm = hurdat.get_storm((name, year))\n",
    "        forecast = storm.get_operational_forecasts()\n",
    "        #choose models \n",
    "        #\"Ideally we are interested in SHIFOR5/SHIPS/GFS/EMXI/HWRF\" - Leonard \n",
    "        model_list = set(['HWRF','SHIP','SHF5','GFS','EMXI','CLAP5','NAM','AP01','CMC']).intersection(forecast.keys())\n",
    "        #create empty df \n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "        for model in model_list:  \n",
    "            df_model = pd.DataFrame()\n",
    "            for time in forecast[model]:    \n",
    "                df = pd.DataFrame(forecast[model][time])\n",
    "                temp = df.loc[df['fhr']==pred]\n",
    "                #select columns\n",
    "                temp = temp[['lat','lon','vmax','mslp']]\n",
    "                temp = temp.add_prefix(str(model)+'_'+str(pred)+'_')\n",
    "                temp['datetime'] = pd.to_datetime(time, format = '%Y%m%d%H')\n",
    "                df_model = pd.concat([df_model, temp], axis=0)\n",
    "            if df_model.shape[0]>0: \n",
    "                df_out = df_out.merge(df_model, on='datetime', how='outer')\n",
    "        df_out = df_out.sort_values(by='datetime')         \n",
    "    except:\n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "    return df_out\n",
    "\n",
    "def join_forecast(df, pred=24):\n",
    "    print('joining forecast data')\n",
    "    #create a dataframe to store joined data\n",
    "    df_all= pd.DataFrame()\n",
    "\n",
    "    # read hurdat data set for both basins: north atlantic and east pacific\n",
    "    hurdat = tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "\n",
    "    #get list of storm names and year\n",
    "    df['NAME'] = df['NAME'].str.lower()\n",
    "    df['YEAR'] = df['ISO_TIME'].dt.year\n",
    "    storm_list = df[['SID','NAME','YEAR','BASIN']].drop_duplicates(['SID']) #get list of storm names and year\n",
    "    storm_list.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    for i in range(len(storm_list)):\n",
    "        SID = storm_list['SID'][i]\n",
    "        name = storm_list['NAME'][i]\n",
    "        year= storm_list['YEAR'][i]\n",
    "        basin = storm_list['BASIN'][i]\n",
    "        \n",
    "        #get stat data for particular storm\n",
    "        df_stat = df.loc[df['NAME']==name]\n",
    "        \n",
    "        #no forecast for these basins \n",
    "        if basin in ['SP','SI','NI','WP']:\n",
    "            df_all = pd.concat([df_all, df_stat], axis=0)        \n",
    "        else:  \n",
    "            #try to get forecast for particular storm\n",
    "            df_forecast = get_forecast(hurdat, name, year, pred)\n",
    "            if df_forecast.shape[0]>0:\n",
    "                print('timesteps of forecast for ',name, df_forecast.shape[0])\n",
    "                #join with dataframe\n",
    "                df_forecast['NAME']= name\n",
    "                df_joined = df_stat.merge(df_forecast, how='left', left_on=['ISO_TIME','NAME'], right_on=['datetime','NAME'])\n",
    "                df_joined.drop('datetime', axis=1, inplace=True)\n",
    "                df_all = pd.concat([df_all, df_joined], axis=0)\n",
    "            else:\n",
    "                print('no forecast for', name, year)\n",
    "                df_all = pd.concat([df_all, df_stat], axis=0)  \n",
    "    #drop duplicated values \n",
    "    df1.drop_duplicates(subset=['SID','ISO_TIME'], keep='last')\n",
    "    #sort values \n",
    "    df2.sort_values(by=['SID','ISO_TIME'], ascending=True)\n",
    "    df_all.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    #drop added columns\n",
    "    df_all.drop(['NAME','YEAR'], inplace=True, axis=1)\n",
    "    \n",
    "    print(\"The dataframe of storms with forecast has been created.\")\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exposed version of the prepare_tabular_vision data \n",
    "#testing it works with the prepare_tabular_vision code \n",
    "min_wind=50\n",
    "min_steps=15\n",
    "max_steps=120 \n",
    "get_displacement=True \n",
    "one_hot = False\n",
    "#documentation on data https://www.ncdc.noaa.gov/ibtracs/pdf/IBTrACS_v04_column_documentation.pdf \n",
    "# path=\"../data/since1980.csv\"\n",
    "path=\"../data/last3years.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.drop(0, axis=0, inplace=True) #drop secondary column names\n",
    "# select interesting columns\n",
    "df0 = data[['SID','NAME', 'BASIN','ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'STORM_DIR']]\n",
    "# transform data from String to numeric\n",
    "df0 = proc.numeric_data(df0)\n",
    "# smooth cos & sign of day\n",
    "df0 = proc.smooth_features(df0)\n",
    "# # add wind category\n",
    "df0['wind_category'] = df0.apply(lambda x: proc.sust_wind_to_cat_val(x['WMO_WIND']), axis=1)\n",
    "# df0 = df0.iloc[15000:17000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining forecast data\n",
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (15.55 seconds)\n",
      "              SID       NAME  YEAR BASIN\n",
      "0   2018255N37320      joyce  2018   NaN\n",
      "1   2018258S10072  not_named  2018    SI\n",
      "2   2018263N26249  not_named  2018    EP\n",
      "3   2018264N14145      trami  2018    WP\n",
      "4   2018265N08338       kirk  2018   NaN\n",
      "5   2018265N13308  not_named  2018   NaN\n",
      "6   2018265N35315     leslie  2018   NaN\n",
      "7   2018268N14253       rosa  2018    EP\n",
      "8   2018269N29151  not_named  2018    WP\n",
      "9   2018270N12218     walaka  2018    EP\n",
      "10  2018270S11162       liua  2018    SP\n",
      "11  2018271N07151   kong-rey  2018    WP\n",
      "12  2018273N12259     sergio  2018    EP\n",
      "13  2018280N18273    michael  2018   NaN\n",
      "14  2018281N12062      luban  2018    NI\n",
      "15  2018282N09333     nadine  2018   NaN\n",
      "16  2018282N15087      titli  2018    NI\n",
      "17  2018288N17257       tara  2018    EP\n",
      "18  2018292N13269    vicente  2018    EP\n",
      "19  2018292N14261      willa  2018    EP\n",
      "20  2018295N08158       yutu  2018    WP\n",
      "no. of forecast for  joyce 29\n",
      "no forecast for not_named 2018\n",
      "no. of forecast for  kirk 33\n",
      "no forecast for not_named 2018\n",
      "no. of forecast for  leslie 84\n",
      "no. of forecast for  rosa 34\n",
      "no forecast for walaka 2018\n",
      "no. of forecast for  sergio 61\n",
      "no. of forecast for  michael 28\n",
      "no. of forecast for  nadine 20\n",
      "no. of forecast for  tara 16\n",
      "no. of forecast for  vicente 18\n",
      "no. of forecast for  willa 29\n",
      "The dataframe of storms with forecast has been created.\n",
      "one-hot added for  BASIN\n"
     ]
    }
   ],
   "source": [
    "#crop out small section for testing \n",
    "df1 = df0.iloc[15000:16000]\n",
    "df1 = join_forecast(df1, pred=24)\n",
    "df2 = proc.add_one_hot(df1, df1['BASIN'],'_basin')\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df0 columns : Index(['SID', 'ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
      "       'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
      "       'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category',\n",
      "       'AP01_24_lat', 'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp',\n",
      "       'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp',\n",
      "       'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'HWRF_24_lat',\n",
      "       'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'NAM_24_lat',\n",
      "       'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp', '_basin_EP', '_basin_NI',\n",
      "       '_basin_SI', '_basin_SP', '_basin_WP'],\n",
      "      dtype='object')\n",
      "The dictionary of storms has been created.\n",
      "The trajectories have now been padded.\n",
      "There are 4 storms with 42 features, and maximum number of steps is 120 and minimum is 120.\n",
      "The tensor has now been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 42, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makesure it works with rest of the code \n",
    "#drop category column\n",
    "df0 = df2.copy()\n",
    "df0.drop(['BASIN'], axis=1, inplace=True)\n",
    "\n",
    "print('df0 columns :', df0.columns)\n",
    "# get a dict with the storms with a windspeed and number of timesteps greater to a threshold\n",
    "storms = proc.sort_storm(df0, min_wind, min_steps)\n",
    "# pad the trajectories to a fix length\n",
    "d = proc.pad_traj(storms, max_steps)\n",
    "# print the shape of the tensor\n",
    "m, n, t_max, t_min, t_hist = proc.tensor_shape(d)\n",
    "# create the tensor\n",
    "t, p_list = proc.create_tensor(d, m)\n",
    "\n",
    "# #put t in format storm * timestep * features\n",
    "e = t.transpose((2, 0, 1))\n",
    "for tt in e:\n",
    "    try:\n",
    "        tt[0] = datetime.strptime(tt[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        pass\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (11.37 seconds)\n"
     ]
    }
   ],
   "source": [
    "# df0.loc[df0['NAME']=='michael']['BASIN']\n",
    "# df1\n",
    "# read hurdat data set for both basins: north atlantic and east pacific\n",
    "hurdat = tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "# get_forecast(hurdat, 'michael',2018, 24)\n",
    "# pred=24\n",
    "storm = hurdat.get_storm(('michael', 2018))\n",
    "forecast = storm.get_operational_forecasts()\n",
    "# #choose models \n",
    "# model_list = set(['NAM','AP01','HWRF','SHIP', 'AEMI','CLAP5','EMXI','CMC']).intersection(forecast.keys())\n",
    "# #create empty df \n",
    "# df_out = pd.DataFrame(columns=['datetime'])\n",
    "# for model in model_list:  \n",
    "#     df_model = pd.DataFrame()\n",
    "#     for time in forecast[model]:    \n",
    "#         df = pd.DataFrame(forecast[model][time])\n",
    "#         temp = df.loc[df['fhr']==pred]\n",
    "#         #select columns\n",
    "#         temp = temp[['lat','lon','vmax','mslp']]\n",
    "#         temp = temp.add_prefix(str(model)+'_'+str(pred)+'_')\n",
    "#         temp['datetime'] = pd.to_datetime(time, format = '%Y%m%d%H')\n",
    "#         df_model = pd.concat([df_model, temp], axis=0)\n",
    "#     df_out = df_out.merge(df_model, on='datetime', how='outer')\n",
    "# df_out = df_out.sort_values(by='datetime') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
