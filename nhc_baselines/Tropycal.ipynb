{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tropycal.tracks as tracks\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data_processing as proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (9.85 seconds)\n",
      "all available models dict_keys(['CARQ', 'NAM', 'AC00', 'AEMN', 'AP01', 'AP02', 'AP03', 'AP04', 'AP05', 'AP06', 'AP07', 'AP08', 'AP09', 'AP10', 'AP11', 'AP12', 'AP13', 'AP14', 'AP15', 'AP16', 'AP17', 'AP18', 'AP19', 'AP20', 'AVNO', 'AVNX', 'CLP5', 'CTCX', 'DSHP', 'GFSO', 'HCCA', 'IVCN', 'IVDR', 'LGEM', 'OCD5', 'PRFV', 'SHF5', 'SHIP', 'TABD', 'TABM', 'TABS', 'TCLP', 'XTRP', 'CMC', 'NGX', 'UKX', 'AEMI', 'AHNI', 'AVNI', 'CEMN', 'CHCI', 'CTCI', 'DSPE', 'EGRR', 'LGME', 'NAMI', 'NEMN', 'RVCN', 'RVCX', 'SHPE', 'TBDE', 'TBME', 'TBSE', 'TVCA', 'TVCE', 'TVCN', 'TVCX', 'TVDG', 'UE00', 'UE01', 'UE02', 'UE03', 'UE04', 'UE05', 'UE06', 'UE07', 'UE08', 'UE09', 'UE10', 'UE11', 'UE12', 'UE13', 'UE14', 'UE15', 'UE16', 'UE17', 'UE18', 'UE19', 'UE20', 'UE21', 'UE22', 'UE23', 'UE24', 'UE25', 'UE26', 'UE27', 'UE28', 'UE29', 'UE30', 'UE31', 'UE32', 'UE33', 'UE34', 'UE35', 'UEMN', 'CEMI', 'CMCI', 'COTC', 'EGRI', 'HMON', 'HWRF', 'NGXI', 'NVGM', 'PRV2', 'PRVI', 'UEMI', 'UKXI', 'CEM2', 'CMC2', 'COTI', 'EGR2', 'HHFI', 'HHNI', 'HMNI', 'HWFI', 'ICON', 'IVRI', 'NGX2', 'NVGI', 'OFCP', 'TCOA', 'TCOE', 'TCON', 'UEM2', 'UKX2', 'CHC2', 'CTC2', 'NAM2', 'OFCL', 'OFPI', 'AEM2', 'AHN2', 'AVN2', 'DRCL', 'HHF2', 'HHN2', 'HMN2', 'HWF2', 'NVG2', 'OFCI', 'OFP2', 'FSSE', 'RI25', 'RI30'])\n"
     ]
    }
   ],
   "source": [
    "#read north atlantic datasets\n",
    "hurdat= tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "#example to get forecast for one storm \n",
    "storm = hurdat.get_storm(('michael', 2018))\n",
    "forecast = storm.get_operational_forecasts()\n",
    "print('all available models', storm.get_operational_forecasts().keys()) \n",
    "\n",
    "# I chose models to use:\n",
    "# #'HWRF','SHIP','NVGM','AEMI','NAM \n",
    "model_list = set(['HWRF','SHIP', 'AEMI','CLAP5','EMXI','CMC']).intersection(forecast.keys())\n",
    "\n",
    "#This website has the explanation of all the models: \n",
    "#https://www.nhc.noaa.gov/modelsummary.shtml#:~:text=The%20National%20Hurricane%20Center%20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get forecast of hurricane based on name and year \n",
    "def get_forecast(hurdat, name, year, pred=24): #pred: hours prediction \n",
    "    try:\n",
    "        storm = hurdat.get_storm((name, year))\n",
    "        forecast = storm.get_operational_forecasts()\n",
    "        #choose models \n",
    "        model_list = set(['HWRF','SHIP', 'AEMI','CLAP5','EMXI','CMC']).intersection(forecast.keys())\n",
    "        #create empty df \n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "        for model in model_list:  \n",
    "            df_model = pd.DataFrame()\n",
    "            for time in forecast[model]:    \n",
    "                df = pd.DataFrame(forecast[model][time])\n",
    "                temp = df.loc[df['fhr']==pred]\n",
    "                #select columns\n",
    "                temp = temp[['lat','lon','vmax','mslp']]\n",
    "                temp = temp.add_prefix(str(model)+'_'+str(pred)+'_')\n",
    "                temp['datetime'] = pd.to_datetime(time, format = '%Y%m%d%H')\n",
    "                df_model = pd.concat([df_model, temp], axis=0)\n",
    "            df_out = df_out.merge(df_model, on='datetime', how='outer')\n",
    "        df_out = df_out.sort_values(by='datetime')         \n",
    "    except:\n",
    "        print('no forecast for', name, year)\n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def join_forecast(df, pred=24):\n",
    "    print('joining forecast data')\n",
    "    # read hurdat data set for both basins: north atlantic and east pacific \n",
    "    hurdat = tracks.TrackDataset(basin='both',source='hurdat',include_btk=False) \n",
    "    #get list of storm names and year \n",
    "    df['NAME'] = df['NAME'].str.lower()\n",
    "    df['YEAR'] = df['ISO_TIME'].dt.year\n",
    "    storm_list= df.loc[df['BASIN'].isin(['NA','EP'])] #north atlantic and east pacific\n",
    "    storm_list = storm_list[['NAME','YEAR']].drop_duplicates() #get list of storm names and year \n",
    "    storm_list.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    for i in range(len(storm_list)):\n",
    "        name  =storm_list['NAME'][i]\n",
    "        year = storm_list['YEAR'][i]\n",
    "        #get forecast for particular storm \n",
    "        df_forecast = get_forecast(hurdat, name, year, pred)\n",
    "        #join with dataframe\n",
    "        df_forecast['NAME']= name\n",
    "        df_out = df.merge(df_forecast, how='left', left_on=['ISO_TIME','NAME'], right_on=['datetime','NAME'])\n",
    "    #drop added columns\n",
    "    df_out.drop(['NAME','datetime','YEAR'], inplace=True )\n",
    "    return df_out \n",
    "# df1 = df0.iloc[:4000]\n",
    "# df2 = join_forecast(df1, pred=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing it works with the prepare_tabular_vision code \n",
    "min_wind=50\n",
    "min_steps=15\n",
    "max_steps=120 \n",
    "get_displacement=True \n",
    "one_hot = True\n",
    "#documentation on data https://www.ncdc.noaa.gov/ibtracs/pdf/IBTrACS_v04_column_documentation.pdf \n",
    "path=\"../data/last3years.csv\"\n",
    "one_hot =False\n",
    "data = pd.read_csv(path)\n",
    "data.drop(0, axis=0, inplace=True) #drop secondary column names\n",
    "# select interesting columns\n",
    "df0 = data[['SID','NAME', 'BASIN','ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'STORM_DIR']]\n",
    "# transform data from String to numeric\n",
    "df0 = numeric_data(df0)\n",
    "# smooth cos & sign of day\n",
    "df0 = smooth_features(df0)\n",
    "# # add wind category\n",
    "df0['wind_category'] = df0.apply(lambda x: sust_wind_to_cat_val(x['WMO_WIND']), axis=1)\n",
    "df0 = df0.iloc[:3000]\n",
    "# join forecast data:\n",
    "df0 = join_forecast(df0)\n",
    "if one_hot:\n",
    "    #adding BASIN and NATURE feature as a one hot\n",
    "    df0 = add_one_hot(df0, data['BASIN'], 'basin')\n",
    "    df0 = add_one_hot(df0, data['NATURE'], 'nature')\n",
    "    #add category one_hot\n",
    "    #df0 = add_one_hot(df0, df0['wind_category'], 'category')\n",
    "print('df0 columns :', df0.columns)\n",
    "\n",
    "# get a dict with the storms with a windspeed and number of timesteps greater to a threshold\n",
    "storms = sort_storm(df0, min_wind, min_steps)\n",
    "# pad the trajectories to a fix length\n",
    "d = pad_traj(storms, max_steps)\n",
    "# print(d)\n",
    "if get_displacement:\n",
    "    d = add_displacement_lat_lon2(d)\n",
    "# print the shape of the tensor\n",
    "m, n, t_max, t_min, t_hist = tensor_shape(d)\n",
    "# create the tensor\n",
    "t, p_list = create_tensor(d, m)\n",
    "\n",
    "#put t in format storm * timestep * features\n",
    "e = t.transpose((2, 0, 1))\n",
    "for tt in e:\n",
    "    try:\n",
    "        tt[0] = datetime.strptime(tt[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
