{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/plot/plot.py:16: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tracks/plot.py:24: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/dataset.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(warn_message)\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/plot.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/recon/plot.py:22: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n"
     ]
    }
   ],
   "source": [
    "import tropycal.tracks as tracks\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import data_processing as proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining forecast data\n",
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (12.8 seconds)\n",
      "no forecast for pali 2016\n",
      "timesteps of forecast for  alex 21\n",
      "timesteps of forecast for  bonnie 42\n",
      "no forecast for not_named 2016\n",
      "timesteps of forecast for  colin 17\n",
      "timesteps of forecast for  danielle 11\n",
      "timesteps of forecast for  agatha 14\n",
      "timesteps of forecast for  blas 40\n",
      "timesteps of forecast for  celia 63\n",
      "timesteps of forecast for  darby 64\n",
      "timesteps of forecast for  estelle 35\n",
      "timesteps of forecast for  georgette 29\n",
      "timesteps of forecast for  frank 32\n",
      "timesteps of forecast for  howard 40\n",
      "timesteps of forecast for  earl 34\n",
      "timesteps of forecast for  ivette 39\n",
      "timesteps of forecast for  javier 15\n",
      "timesteps of forecast for  kay 30\n",
      "timesteps of forecast for  fiona 36\n",
      "timesteps of forecast for  gaston 55\n",
      "timesteps of forecast for  lester 66\n",
      "timesteps of forecast for  madeline 50\n",
      "no forecast for not_named 2016\n",
      "timesteps of forecast for  hermine 77\n",
      "timesteps of forecast for  newton 25\n",
      "timesteps of forecast for  orlene 35\n",
      "timesteps of forecast for  ian 32\n",
      "timesteps of forecast for  karl 51\n",
      "timesteps of forecast for  julia 38\n",
      "timesteps of forecast for  paine 28\n",
      "timesteps of forecast for  lisa 34\n",
      "timesteps of forecast for  ulika 27\n",
      "timesteps of forecast for  roslyn 37\n",
      "timesteps of forecast for  matthew 61\n",
      "no forecast for songda 2016\n",
      "timesteps of forecast for  nicole 66\n",
      "timesteps of forecast for  seymour 28\n",
      "timesteps of forecast for  tina 24\n",
      "no forecast for otto 2016\n",
      "timesteps of forecast for  arlene 16\n",
      "timesteps of forecast for  adrian 18\n",
      "timesteps of forecast for  beatriz 15\n",
      "timesteps of forecast for  calvin 11\n",
      "timesteps of forecast for  bret 18\n",
      "timesteps of forecast for  cindy 21\n",
      "timesteps of forecast for  dora 20\n",
      "no forecast for not_named 2017\n",
      "timesteps of forecast for  eugene 27\n",
      "timesteps of forecast for  fernanda 48\n",
      "timesteps of forecast for  don 12\n",
      "no forecast for not_named 2017\n",
      "timesteps of forecast for  greg 49\n",
      "timesteps of forecast for  hilary 42\n",
      "timesteps of forecast for  irwin 50\n",
      "timesteps of forecast for  emily 11\n",
      "no forecast for not_named 2017\n",
      "timesteps of forecast for  franklin 27\n",
      "timesteps of forecast for  jova 13\n",
      "timesteps of forecast for  gert 58\n",
      "timesteps of forecast for  harvey 72\n",
      "timesteps of forecast for  kenneth 28\n",
      "no forecast for not_named 2017\n",
      "timesteps of forecast for  irma 60\n",
      "timesteps of forecast for  lidia 25\n",
      "timesteps of forecast for  jose 75\n",
      "timesteps of forecast for  katia 17\n",
      "timesteps of forecast for  otis 36\n",
      "timesteps of forecast for  norma 26\n",
      "timesteps of forecast for  max 9\n",
      "timesteps of forecast for  lee 57\n",
      "timesteps of forecast for  maria 66\n",
      "timesteps of forecast for  pilar 17\n",
      "timesteps of forecast for  nate 20\n",
      "timesteps of forecast for  ramon 11\n",
      "timesteps of forecast for  ophelia 38\n",
      "timesteps of forecast for  selma 9\n",
      "timesteps of forecast for  philippe 22\n",
      "no forecast for rina 2017\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  alberto 38\n",
      "timesteps of forecast for  aletta 30\n",
      "timesteps of forecast for  bud 29\n",
      "no forecast for carlotta 2018\n",
      "timesteps of forecast for  daniel 16\n",
      "timesteps of forecast for  emilia 27\n",
      "timesteps of forecast for  fabio 34\n",
      "timesteps of forecast for  beryl 51\n",
      "timesteps of forecast for  chris 29\n",
      "no forecast for not_named 2018\n",
      "no forecast for gilma 2018\n",
      "timesteps of forecast for  hector 66\n",
      "timesteps of forecast for  debby 23\n",
      "timesteps of forecast for  ileana 12\n",
      "timesteps of forecast for  john 26\n",
      "timesteps of forecast for  kristy 32\n",
      "timesteps of forecast for  lane 72\n",
      "timesteps of forecast for  ernesto 22\n",
      "timesteps of forecast for  miriam 35\n",
      "timesteps of forecast for  norman 57\n",
      "timesteps of forecast for  florence 79\n",
      "timesteps of forecast for  olivia 77\n",
      "timesteps of forecast for  gordon 23\n",
      "timesteps of forecast for  isaac 55\n",
      "timesteps of forecast for  helene 41\n",
      "timesteps of forecast for  paul 28\n",
      "timesteps of forecast for  joyce 29\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  kirk 33\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  leslie 84\n",
      "timesteps of forecast for  rosa 34\n",
      "no forecast for walaka 2018\n",
      "timesteps of forecast for  sergio 61\n",
      "timesteps of forecast for  michael 28\n",
      "timesteps of forecast for  nadine 20\n",
      "timesteps of forecast for  tara 16\n",
      "timesteps of forecast for  vicente 18\n",
      "timesteps of forecast for  willa 29\n",
      "timesteps of forecast for  oscar 32\n",
      "timesteps of forecast for  xavier 24\n",
      "timesteps of forecast for  andrea 10\n",
      "timesteps of forecast for  alvin 25\n",
      "timesteps of forecast for  barbara 41\n",
      "timesteps of forecast for  cosme 19\n",
      "timesteps of forecast for  barry 36\n",
      "no forecast for not_named 2019\n",
      "timesteps of forecast for  dalila 33\n",
      "no forecast for not_named 2019\n",
      "timesteps of forecast for  flossie 48\n",
      "no forecast for erick 2019\n",
      "timesteps of forecast for  gil 14\n",
      "timesteps of forecast for  henriette 17\n",
      "timesteps of forecast for  ivo 39\n",
      "timesteps of forecast for  chantal 26\n",
      "timesteps of forecast for  erin 28\n",
      "timesteps of forecast for  dorian 69\n",
      "timesteps of forecast for  juliette 32\n",
      "timesteps of forecast for  gabrielle 38\n",
      "timesteps of forecast for  fernand 11\n",
      "timesteps of forecast for  akoni 16\n",
      "timesteps of forecast for  kiko 62\n",
      "timesteps of forecast for  humberto 39\n",
      "timesteps of forecast for  jerry 42\n",
      "timesteps of forecast for  mario 30\n",
      "timesteps of forecast for  lorena 25\n",
      "timesteps of forecast for  imelda 11\n",
      "timesteps of forecast for  karen 31\n",
      "timesteps of forecast for  lorenzo 44\n",
      "no forecast for not_named 2019\n",
      "The dataframe of storms with forecast has been created.\n",
      "one-hot added for  BASIN\n",
      "df0 columns : Index(['SID', 'ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
      "       'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
      "       'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category',\n",
      "       'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp',\n",
      "       'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'AP01_24_lat',\n",
      "       'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp', 'SHIP_24_lat',\n",
      "       'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'NAM_24_lat',\n",
      "       'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp', 'basin_EP', 'basin_NI',\n",
      "       'basin_SI', 'basin_SP', 'basin_WP'],\n",
      "      dtype='object')\n",
      "The dictionary of storms has been created.\n",
      "The trajectories have now been padded.\n",
      "There are 93 storms with 44 features, and maximum number of steps is 120 and minimum is 120.\n",
      "creating tensor, dropping SID and ISO_TIME features\n",
      "The tensor has now been created.\n"
     ]
    }
   ],
   "source": [
    "from utils import data_processing as proc\n",
    "#testing that the code works \n",
    "e, d= proc.prepare_tabular_data_vision(path=\"../data/last3years.csv\", min_wind=50, min_steps=15,\n",
    "                  max_steps=120, get_displacement=True, forecast=True, one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/y_2016_50_15_120_forecast_test.npy', e, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (7.78 seconds)\n",
      "all available models dict_keys(['CARQ', 'NAM', 'AC00', 'AEMN', 'AP01', 'AP02', 'AP03', 'AP04', 'AP05', 'AP06', 'AP07', 'AP08', 'AP09', 'AP10', 'AP11', 'AP12', 'AP13', 'AP14', 'AP15', 'AP16', 'AP17', 'AP18', 'AP19', 'AP20', 'AVNO', 'AVNX', 'CLP5', 'CTCX', 'DSHP', 'GFSO', 'HCCA', 'IVCN', 'IVDR', 'LGEM', 'OCD5', 'PRFV', 'SHF5', 'SHIP', 'TABD', 'TABM', 'TABS', 'TCLP', 'XTRP', 'CMC', 'NGX', 'UKX', 'AEMI', 'AHNI', 'AVNI', 'CEMN', 'CHCI', 'CTCI', 'DSPE', 'EGRR', 'LGME', 'NAMI', 'NEMN', 'RVCN', 'RVCX', 'SHPE', 'TBDE', 'TBME', 'TBSE', 'TVCA', 'TVCE', 'TVCN', 'TVCX', 'TVDG', 'UE00', 'UE01', 'UE02', 'UE03', 'UE04', 'UE05', 'UE06', 'UE07', 'UE08', 'UE09', 'UE10', 'UE11', 'UE12', 'UE13', 'UE14', 'UE15', 'UE16', 'UE17', 'UE18', 'UE19', 'UE20', 'UE21', 'UE22', 'UE23', 'UE24', 'UE25', 'UE26', 'UE27', 'UE28', 'UE29', 'UE30', 'UE31', 'UE32', 'UE33', 'UE34', 'UE35', 'UEMN', 'CEMI', 'CMCI', 'COTC', 'EGRI', 'HMON', 'HWRF', 'NGXI', 'NVGM', 'PRV2', 'PRVI', 'UEMI', 'UKXI', 'CEM2', 'CMC2', 'COTI', 'EGR2', 'HHFI', 'HHNI', 'HMNI', 'HWFI', 'ICON', 'IVRI', 'NGX2', 'NVGI', 'OFCP', 'TCOA', 'TCOE', 'TCON', 'UEM2', 'UKX2', 'CHC2', 'CTC2', 'NAM2', 'OFCL', 'OFPI', 'AEM2', 'AHN2', 'AVN2', 'DRCL', 'HHF2', 'HHN2', 'HMN2', 'HWF2', 'NVG2', 'OFCI', 'OFP2', 'FSSE', 'RI25', 'RI30'])\n"
     ]
    }
   ],
   "source": [
    "#here is an example of how to use Tropycal \n",
    "#read north atlantic datasets\n",
    "hurdat= tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "#example to get forecast for one storm \n",
    "storm = hurdat.get_storm(('michael', 2018))\n",
    "forecast = storm.get_operational_forecasts()\n",
    "print('all available models', storm.get_operational_forecasts().keys()) \n",
    "\n",
    "#models to use:\n",
    "all_models = ['CLP5','SHF5','A98E','P91E','SHIP','DSHP','GFSO','LBAR','CMC','EMXI','NGPS','GFDL','HWRF','UKXI','GUNS','FSSE','AEMN','OFCL']\n",
    "model_list = set(all_models).intersection(forecast.keys())\n",
    "\n",
    "#This website has the explanation of all the models: \n",
    "#https://www.nhc.noaa.gov/modelsummary.shtml#:~:text=The%20National%20Hurricane%20Center%20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models: \n",
    "- Stat models: \n",
    "    CLP5: Climatology and Persistence Model (CLIPER5)\n",
    "    SHF5: Statistical Hurricane Intensity Forecast (SHIFOR5) \n",
    "- Stat-dynamical:\n",
    "    A98E, P91E: NHC91/NHC98 Models\n",
    "    SHIP: Statistical Hurricane Intensity Prediction Scheme (SHIPS)\n",
    "    DSHP: Decay-SHIPS\n",
    "    Logistic Growth Equation Model Summary (LGEM)\n",
    "- Dynamical:\n",
    "    GFSO: U.S. National Weather Service Global Forecast System (GFS)\n",
    "    LBAR: Limited Area Sine Transform Barotropic (LBAR) Model\n",
    "    CMC: Canadian Meteorological Centre (CMC) Global Environmental Multiscale Model (GEM)\n",
    "    EMXI: European Center for Medium-range Weather Forecasting (ECMWF) Model\n",
    "    NGPS: Navy Operational Global Atmospheric Prediction System (NOGAPS)\n",
    "    GFDL: NWS Geophysical Fluid Dynamics Model (GFDL) Hurricane Model\n",
    "    HWRF: Hurricane Weather Research and Forecasting Model (HWRF)\n",
    "    UKM (UKXI): United Kingdom Meteorological Office (UKMET) Model\n",
    "- Ensemble: \n",
    "    GUNS: Average of GFDI, UKMI, NGPI, and GFSI \n",
    "    FSSE: Florida State University Super Ensemble (FSSE)\n",
    "    AEMN: National Weather Service Global Ensemble Forecast System (GEFS)\n",
    "- Official: \n",
    "    OFCL: NHC Official Forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get forecast of hurricane based on name and year \n",
    "def get_forecast(hurdat, name, year, pred=24): #pred: hours prediction \n",
    "    try:\n",
    "        storm = hurdat.get_storm((name, year))\n",
    "        forecast = storm.get_operational_forecasts()\n",
    "        #choose models \n",
    "        #\"Ideally we are interested in SHIFOR5/SHIPS/GFS/EMXI/HWRF\" - Leonard \n",
    "        model_list = set(['HWRF','SHIP','SHF5','GFS','EMXI','CLAP5','NAM','AP01','CMC']).intersection(forecast.keys())\n",
    "        #create empty df \n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "        for model in model_list:  \n",
    "            df_model = pd.DataFrame()\n",
    "            for time in forecast[model]:    \n",
    "                df = pd.DataFrame(forecast[model][time])\n",
    "                temp = df.loc[df['fhr']==pred]\n",
    "                #select columns\n",
    "                temp = temp[['lat','lon','vmax','mslp']]\n",
    "                temp = temp.add_prefix(str(model)+'_'+str(pred)+'_')\n",
    "                temp['datetime'] = pd.to_datetime(time, format = '%Y%m%d%H')\n",
    "                df_model = pd.concat([df_model, temp], axis=0)\n",
    "            if df_model.shape[0]>0: \n",
    "                df_out = df_out.merge(df_model, on='datetime', how='outer')\n",
    "        df_out = df_out.sort_values(by='datetime')         \n",
    "    except:\n",
    "        df_out = pd.DataFrame(columns=['datetime'])\n",
    "    return df_out\n",
    "\n",
    "def join_forecast(df, pred=24):\n",
    "    print('joining forecast data')\n",
    "    #create a dataframe to store joined data\n",
    "    df_all= pd.DataFrame()\n",
    "\n",
    "    # read hurdat data set for both basins: north atlantic and east pacific\n",
    "    hurdat = tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "\n",
    "    #get list of storm names and year\n",
    "    df['NAME'] = df['NAME'].str.lower()\n",
    "    df['YEAR'] = df['ISO_TIME'].dt.year\n",
    "    storm_list = df[['SID','NAME','YEAR','BASIN']].drop_duplicates(['SID']) #get list of storm names and year\n",
    "    storm_list.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    for i in range(len(storm_list)):\n",
    "        SID = storm_list['SID'][i]\n",
    "        name = storm_list['NAME'][i]\n",
    "        year= storm_list['YEAR'][i]\n",
    "        basin = storm_list['BASIN'][i]\n",
    "        \n",
    "        #get stat data for particular storm\n",
    "        df_stat = df.loc[df['NAME']==name]\n",
    "        \n",
    "        #no forecast for these basins \n",
    "        if basin in ['SP','SI','NI','WP']:\n",
    "            df_joined = df_stat    \n",
    "        else:  \n",
    "            #try to get forecast for particular storm\n",
    "            df_forecast = get_forecast(hurdat, name, year, pred)\n",
    "            if df_forecast.shape[0]>0:\n",
    "                print('timesteps of forecast for ',name, df_forecast.shape[0])\n",
    "                #join with dataframe\n",
    "                df_forecast['NAME']= name\n",
    "                df_joined = df_stat.merge(df_forecast, how='left', left_on=['ISO_TIME','NAME'], right_on=['datetime','NAME'])\n",
    "                df_joined.drop('datetime', axis=1, inplace=True)\n",
    "            else:\n",
    "                print('no forecast for', name, year)\n",
    "                df_joined = df_stat\n",
    "        df_all = pd.concat([df_all, df_joined], axis=0)        \n",
    "\n",
    "    #drop duplicated values \n",
    "    df_all.drop_duplicates(subset=['SID','ISO_TIME'], keep='last', inplace=True)\n",
    "    #sort values \n",
    "    df_all.sort_values(by=['SID','ISO_TIME'], ascending=True, inplace=True)\n",
    "    df_all.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    #drop added columns\n",
    "    df_all.drop(['NAME','YEAR'], inplace=True, axis=1)\n",
    "    \n",
    "    print(\"The dataframe of storms with forecast has been created.\")\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exposed version of the prepare_tabular_vision data \n",
    "#testing it works with the prepare_tabular_vision code \n",
    "min_wind=50\n",
    "min_steps=15\n",
    "max_steps=120 \n",
    "get_displacement=True \n",
    "one_hot = False\n",
    "#documentation on data https://www.ncdc.noaa.gov/ibtracs/pdf/IBTrACS_v04_column_documentation.pdf \n",
    "# path=\"../data/since1980.csv\"\n",
    "path=\"../data/last3years.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.drop(0, axis=0, inplace=True) #drop secondary column names\n",
    "# select interesting columns\n",
    "df0 = data[['SID','NAME', 'BASIN','ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'STORM_DIR']]\n",
    "# transform data from String to numeric\n",
    "df0 = proc.numeric_data(df0)\n",
    "# smooth cos & sign of day\n",
    "df0 = proc.smooth_features(df0)\n",
    "# # add wind category\n",
    "df0['wind_category'] = df0.apply(lambda x: proc.sust_wind_to_cat_val(x['WMO_WIND']), axis=1)\n",
    "# df0 = df0.iloc[15000:17000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining forecast data\n",
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (7.64 seconds)\n",
      "timesteps of forecast for  joyce 29\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  kirk 33\n",
      "no forecast for not_named 2018\n",
      "timesteps of forecast for  leslie 84\n",
      "timesteps of forecast for  rosa 34\n",
      "no forecast for walaka 2018\n",
      "timesteps of forecast for  sergio 61\n",
      "timesteps of forecast for  michael 28\n",
      "timesteps of forecast for  nadine 20\n",
      "timesteps of forecast for  tara 16\n",
      "timesteps of forecast for  vicente 18\n",
      "timesteps of forecast for  willa 29\n",
      "The dataframe of storms with forecast has been created.\n",
      "one-hot added for  BASIN\n"
     ]
    }
   ],
   "source": [
    "#crop out small section for testing \n",
    "df1 = df0.iloc[15000:16000]\n",
    "df1 = join_forecast(df1, pred=24)\n",
    "df2 = proc.add_one_hot(df1, df1['BASIN'],'_basin')\n",
    "# df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SID', 'ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
       "       'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
       "       'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category',\n",
       "       'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp',\n",
       "       'AP01_24_lat', 'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp',\n",
       "       'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp',\n",
       "       'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'NAM_24_lat',\n",
       "       'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp', '_basin_EP', '_basin_NI',\n",
       "       '_basin_SI', '_basin_SP', '_basin_WP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df0 columns : Index(['SID', 'ISO_TIME', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
      "       'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
      "       'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category',\n",
      "       'AP01_24_lat', 'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp',\n",
      "       'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp',\n",
      "       'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'HWRF_24_lat',\n",
      "       'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'NAM_24_lat',\n",
      "       'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp', '_basin_EP', '_basin_NI',\n",
      "       '_basin_SI', '_basin_SP', '_basin_WP'],\n",
      "      dtype='object')\n",
      "The dictionary of storms has been created.\n",
      "The trajectories have now been padded.\n",
      "There are 4 storms with 42 features, and maximum number of steps is 120 and minimum is 120.\n",
      "The tensor has now been created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 42, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#makesure it works with rest of the code \n",
    "#drop category column\n",
    "df0 = df2.copy()\n",
    "df0.drop(['BASIN'], axis=1, inplace=True)\n",
    "\n",
    "print('df0 columns :', df0.columns)\n",
    "# get a dict with the storms with a windspeed and number of timesteps greater to a threshold\n",
    "storms = proc.sort_storm(df0, min_wind, min_steps)\n",
    "# pad the trajectories to a fix length\n",
    "d = proc.pad_traj(storms, max_steps)\n",
    "# print the shape of the tensor\n",
    "m, n, t_max, t_min, t_hist = proc.tensor_shape(d)\n",
    "# create the tensor\n",
    "t, p_list = proc.create_tensor(d, m)\n",
    "\n",
    "# #put t in format storm * timestep * features\n",
    "e = t.transpose((2, 0, 1))\n",
    "for tt in e:\n",
    "    try:\n",
    "        tt[0] = datetime.strptime(tt[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    except:\n",
    "        pass\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Starting to read in HURDAT2 data\n",
      "--> Completed reading in HURDAT2 data (11.37 seconds)\n"
     ]
    }
   ],
   "source": [
    "# df0.loc[df0['NAME']=='michael']['BASIN']\n",
    "# df1\n",
    "# read hurdat data set for both basins: north atlantic and east pacific\n",
    "hurdat = tracks.TrackDataset(basin='both',source='hurdat',include_btk=False)\n",
    "# get_forecast(hurdat, 'michael',2018, 24)\n",
    "# pred=24\n",
    "storm = hurdat.get_storm(('michael', 2018))\n",
    "forecast = storm.get_operational_forecasts()\n",
    "# #choose models \n",
    "# model_list = set(['NAM','AP01','HWRF','SHIP', 'AEMI','CLAP5','EMXI','CMC']).intersection(forecast.keys())\n",
    "# #create empty df \n",
    "# df_out = pd.DataFrame(columns=['datetime'])\n",
    "# for model in model_list:  \n",
    "#     df_model = pd.DataFrame()\n",
    "#     for time in forecast[model]:    \n",
    "#         df = pd.DataFrame(forecast[model][time])\n",
    "#         temp = df.loc[df['fhr']==pred]\n",
    "#         #select columns\n",
    "#         temp = temp[['lat','lon','vmax','mslp']]\n",
    "#         temp = temp.add_prefix(str(model)+'_'+str(pred)+'_')\n",
    "#         temp['datetime'] = pd.to_datetime(time, format = '%Y%m%d%H')\n",
    "#         df_model = pd.concat([df_model, temp], axis=0)\n",
    "#     df_out = df_out.merge(df_model, on='datetime', how='outer')\n",
    "# df_out = df_out.sort_values(by='datetime') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
