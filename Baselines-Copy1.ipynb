{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import Prepro\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset and corresponding sizes (null elements included):\n",
      "X_vision torch.Size([3735, 8, 9, 25, 25])\n",
      "X_stat torch.Size([3735, 8, 10])\n",
      "target_displacement torch.Size([3735, 8, 2])\n",
      "target_intensity torch.Size([3735])\n",
      "target_intensity_cat torch.Size([3735])\n",
      "target_intensity_cat_baseline torch.Size([3735])\n",
      "Keeping 3143 samples out of the initial 3735.\n",
      "Reshaping the displacement target...\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.8 #how much train test data\n",
    "predict_at = 8 #steps_out\n",
    "window_size = 8 #how many timesteps from the past to take ie steps_in\n",
    "\n",
    "#vision_data = np.load('data/vision_data_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "vision_data = np.load('data/vision_data_50_20_60_3years_v2.npy', allow_pickle = True)\n",
    "#vision_data = np.load('../../../Volumes/Samsung_T5/vision_data_50_20_90_1980_v3.npy', allow_pickle = True)\n",
    "#vision_data = np.load('data/vision_data_50_20_90_1980_v3.npy', allow_pickle = True)\n",
    "#y = np.load('data/y_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "y = np.load('data/y_50_20_60_3years_v2.npy', allow_pickle = True) \n",
    "#y = np.load('../../../Volumes/Samsung_T5/y_50_20_90_1980_v3.npy', allow_pickle = True) \n",
    "#y = np.load('data/y_50_20_90_1980_v3.npy', allow_pickle = True) \n",
    "train_tensors, test_tensors = Prepro.process(vision_data, y, train_test_split, predict_at = predict_at, window_size =  window_size)\n",
    "x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.5125e+00, -1.7131e+02,  3.0000e+01,  1.0040e+03,  1.9080e+03,\n",
       "         3.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1250e-01,\n",
       "        -7.0000e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stat_train[0,1,:]\n",
    "#'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'STORM_DIR', \n",
    "\n",
    "\n",
    "#'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "#'STORM_SPEED', 'STORM_DIR', 'storm_category', 'basin_EP', 'basin_NI',\n",
    "#'basin_SI', 'basin_SP', 'basin_WP', 'nature_DS', 'nature_ET',\n",
    "#'nature_MX', 'nature_NR', 'nature_SS', 'nature_TS'\n",
    "#'STORM CATEGORY', \n",
    "#'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fresh(X):\n",
    "    data = np.array(X)\n",
    "    n, t, p = X.shape\n",
    "    new_data = np.zeros((n, t, p+2))\n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            new_data[i,j,2:] = data[i,j]\n",
    "            new_data[i,j,0] = int(i)\n",
    "            new_data[i,j,1] = int(j)\n",
    "    new_data = new_data.reshape(n*t, -1)\n",
    "    new_data = pd.DataFrame(new_data).rename(columns={0: \"storm_id\", 1: \"time\"})\n",
    "    new_data = new_data.astype({\"storm_id\": 'int32', \"time\": 'int32'})\n",
    "    for i in range(p+2):\n",
    "        new_data = new_data.rename(columns={i:\"feat_\"+str(i-1)})\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prepare_fresh(np.concatenate((x_stat_train, x_stat_test), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [00:54<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "df_features = extract_features(a, column_id=\"storm_id\", column_sort=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [05:59<00:00, 17.98s/it]\n"
     ]
    }
   ],
   "source": [
    "features_filtered_direct = extract_relevant_features(a, pd.Series(np.concatenate((tgt_intensity_cat_train, tgt_intensity_cat_test), axis = 0)), column_id='storm_id', column_sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a4a6f2828>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4a45f5f8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(x_viz_train[70,7,6], cmap = 'CMRmap') #CMRmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([628, 8, 9, 25, 25])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_viz_train.shape\n",
    "#samples * timesteps * number of maps * size of map * size of map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([628, 8, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stat_train.shape\n",
    "#samples * number of past timesteps * number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_stat_train.reshape(-1, window_size*x_stat_train.shape[2])\n",
    "X_test = x_stat_test.reshape(-1,window_size*x_stat_train.shape[2])\n",
    "\n",
    "X_train_vision = x_viz_train.reshape(x_viz_train.shape[0], -1)\n",
    "X_test_vision = x_viz_test.reshape(x_viz_test.shape[0], -1)\n",
    "\n",
    "X_train_tab_vision = np.concatenate((X_train, X_train_vision), axis = 1)\n",
    "X_test_tab_vision = np.concatenate((X_test, X_test_vision), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "511290000 requested and 421057536 written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f8c6a3d9db1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_train_vision_1980_50_20_90.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_vision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_test_vision_1980_50_20_90.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_vision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/y_train_intensity_1980_50_20_90.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_cat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m--> 553\u001b[0;31m                            pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[0;31mOSError\u001b[0m: 511290000 requested and 421057536 written"
     ]
    }
   ],
   "source": [
    "np.save('data/X_train_stat_1980_50_20_90.npy', X_train, allow_pickle = True)\n",
    "np.save('data/X_test_stat_1980_50_20_90.npy', X_test, allow_pickle = True)\n",
    "\n",
    "np.save('data/X_train_vision_1980_50_20_90.npy', X_train_vision, allow_pickle = True)\n",
    "np.save('data/X_test_vision_1980_50_20_90.npy', X_test_vision, allow_pickle = True)\n",
    "\n",
    "np.save('data/y_train_intensity_1980_50_20_90.npy', tgt_intensity_cat_train, allow_pickle = True)\n",
    "np.save('data/y_test_intensity_1980_50_20_90.npy', tgt_intensity_cat_test, allow_pickle = True)\n",
    "\n",
    "np.save('data/y_train_displacement_1980_50_20_90.npy', tgt_displacement_train, allow_pickle = True)\n",
    "np.save('data/y_test_displacement_1980_50_20_90.npy', tgt_displacement_test, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/X_train_stat_1980_50_20_90_w12.npy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 8\n",
    "'data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "X_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "X_train_vision = np.load('data/X_train_vision_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "X_test_vision = np.load('data/X_test_vision_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "tgt_intensity_cat_train = np.load('data/y_train_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_intensity_cat_test = np.load('data/y_test_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "tgt_intensity_cat_baseline_train = np.load('data/y_train_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_intensity_cat_baseline_test = np.load('data/y_test_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "tgt_displacement_train = np.load('data/y_train_displacement_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_displacement_test = np.load('data/y_test_displacement_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/X_train_1980_50_20_90.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.5090543259557344\n",
      "Baseline score 0.4949698189134809\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=100)\n",
    "xgb.fit(features_filtered_direct[:1984], tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(features_filtered_direct[1984:])\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.545271629778672\n",
      "Baseline score 0.4949698189134809\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=8, n_estimators=100)\n",
    "xgb.fit(np.concatenate((features_filtered_direct[:1984], X_train), axis = 1), tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(np.concatenate((features_filtered_direct[1984:], X_test), axis = 1))\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.5230524642289348\n",
      "Baseline score 0.45151033386327505\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=80)\n",
    "xgb.fit(X_train, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-47b2e8190d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tab_vision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_cat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tab_vision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"XGB score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_intensity_cat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_intensity_cat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_cat_baseline_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=100)\n",
    "xgb.fit(X_train_tab_vision, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test_tab_vision)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.3762575452716298\n",
      "Baseline score 0.4949698189134809\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=100)\n",
    "xgb.fit(X_train_vision, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test_vision)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score 0.845625770110896\n",
      "Baseline score 0.8804787889456082\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train, tgt_intensity_cat_train)\n",
    "yhat = rf.predict(X_test)\n",
    "print(\"RF score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[18:04:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB x score 0.8286559\n",
      "XGB y score 1.2342972\n"
     ]
    }
   ],
   "source": [
    "xgb_x = XGBRegressor(max_depth=5, n_estimators=100)\n",
    "xgb_y = XGBRegressor(max_depth=5, n_estimators=100)\n",
    "xgb_x.fit(X_train, tgt_displacement_train[:,0])\n",
    "xgb_y.fit(X_train, tgt_displacement_train[:,1])\n",
    "\n",
    "yhat_x = xgb_x.predict(X_test)\n",
    "yhat_y = xgb_y.predict(X_test)\n",
    "print(\"XGB x score\", mean_absolute_error(tgt_displacement_test[:,0], yhat_x))\n",
    "print(\"XGB y score\", mean_absolute_error(tgt_displacement_test[:,1], yhat_y))\n",
    "#be careful for interpretation because the displacement is in degree + standardized + I did not code any baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:32:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB x score 12.20803\n"
     ]
    }
   ],
   "source": [
    "xgb_intensity = XGBRegressor(max_depth=5, n_estimators=100)\n",
    "xgb_intensity.fit(X_train, tgt_intensity_train)\n",
    "\n",
    "yhat_intensity = xgb_intensity.predict(X_test)\n",
    "print(\"XGB x score\", mean_absolute_error(tgt_intensity_test, yhat_intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7458,  0.8419,  0.9379,  ..., -0.5869, -0.5909, -0.5949])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_intensity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7578)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_displacement_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_fresh_2(X):\n",
    "    data = X.reshape(X.shape[0], window_size, X.shape[1]//window_size)\n",
    "    n, t, p = data.shape\n",
    "    new_data = np.zeros((n, t, p+2))\n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            new_data[i,j,2:] = data[i,j]\n",
    "            new_data[i,j,0] = int(i)\n",
    "            new_data[i,j,1] = int(j)\n",
    "    new_data = new_data.reshape(n*t, -1)\n",
    "    new_data = pd.DataFrame(new_data).rename(columns={0: \"storm_id\", 1: \"time\"})\n",
    "    new_data = new_data.astype({\"storm_id\": 'int32', \"time\": 'int32'})\n",
    "    for i in range(p+2):\n",
    "        new_data = new_data.rename(columns={i:\"feat_\"+str(i-1)})\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/X_train_stat_1980_50_20_90_w8.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55e39062c9a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_train_stat_1980_50_20_90_w'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_test_stat_1980_50_20_90_w'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/X_train_stat_1980_50_20_90_w8.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "window_size = 8\n",
    "\n",
    "X_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "X_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "X_train_vision = np.load('data/X_train_vision_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "X_test_vision = np.load('data/X_test_vision_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "tgt_intensity_cat_train = np.load('data/y_train_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_intensity_cat_test = np.load('data/y_test_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "tgt_intensity_cat_baseline_train = np.load('data/y_train_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_intensity_cat_baseline_test = np.load('data/y_test_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "tgt_displacement_train = np.load('data/y_train_displacement_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_displacement_test = np.load('data/y_test_displacement_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "def prepare_fresh_2(X):\n",
    "    data = X.reshape(X.shape[0], window_size, X.shape[1]//window_size)\n",
    "    n, t, p = data.shape\n",
    "    new_data = np.zeros((n, t, p+2))\n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            new_data[i,j,2:] = data[i,j]\n",
    "            new_data[i,j,0] = int(i)\n",
    "            new_data[i,j,1] = int(j)\n",
    "    new_data = new_data.reshape(n*t, -1)\n",
    "    new_data = pd.DataFrame(new_data).rename(columns={0: \"storm_id\", 1: \"time\"})\n",
    "    new_data = new_data.astype({\"storm_id\": 'int32', \"time\": 'int32'})\n",
    "    for i in range(p+2):\n",
    "        new_data = new_data.rename(columns={i:\"feat_\"+str(i-1)})\n",
    "    return new_data\n",
    "\n",
    "a = prepare_fresh_2(np.concatenate((X_train, X_test), axis = 0))\n",
    "features_filtered_direct = extract_relevant_features(a, pd.Series(np.concatenate((tgt_intensity_cat_train, tgt_intensity_cat_test), axis = 0)), column_id='storm_id', column_sort='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_scenarios3 = iai.GridSearch(\n",
    "        iai.OptimalTreeClassifier(\n",
    "            random_seed=1,\n",
    "            criterion = 'misclassification'\n",
    "        ),\n",
    "        max_depth=range(3, 4),\n",
    "    )\n",
    "\n",
    "grid_scenarios3.fit(X_train2, tgt_intensity_cat_train)\n",
    "lnr_scenarios3 = grid_scenarios3.get_learner()\n",
    "print(grid_scenarios3.get_grid_results())\n",
    "\n",
    "print(\"Classification based scenarios, Accuracy: \", lnr_scenarios3.score(X_test, tgt_intensity_cat_test, criterion='misclassification'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'STORM_DIR', 'storm_category', 'cat_basin_EP', 'cat_basin_NI',\n",
    "'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "'cat_UNKNOWN', \n",
    "'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i//22)\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train2.columns if c.lower()[-1] == '0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAT_0',\n",
       " 'LON_0',\n",
       " 'WMO_WIND_0',\n",
       " 'WMO_PRES_0',\n",
       " 'DIST2LAND_0',\n",
       " 'STORM_SPEED_0',\n",
       " 'STORM_DIR_0',\n",
       " 'storm_category_0',\n",
       " 'basin_EP_0',\n",
       " 'cat_basin_NI_0',\n",
       " 'cat_basin_SI_0',\n",
       " 'cat_basin_SP_0',\n",
       " 'cat_basin_WP_0',\n",
       " 'cat_nature_DS_0',\n",
       " 'cat_nature_ET_0',\n",
       " 'cat_nature_MX_0',\n",
       " 'cat_nature_NR_0',\n",
       " 'cat_nature_SS_0',\n",
       " 'cat_nature_TS_0',\n",
       " 'STORM CATEGORY_0',\n",
       " 'STORM_DISPLACEMENT_X_0',\n",
       " 'STORM_DISPLACEMENT_Y_0',\n",
       " 'LAT_1',\n",
       " 'LON_1',\n",
       " 'WMO_WIND_1',\n",
       " 'WMO_PRES_1',\n",
       " 'DIST2LAND_1',\n",
       " 'STORM_SPEED_1',\n",
       " 'STORM_DIR_1',\n",
       " 'storm_category_1',\n",
       " 'basin_EP_1',\n",
       " 'STORM CATEGORY_1',\n",
       " 'STORM_DISPLACEMENT_X_1',\n",
       " 'STORM_DISPLACEMENT_Y_1',\n",
       " 'LAT_2',\n",
       " 'LON_2',\n",
       " 'WMO_WIND_2',\n",
       " 'WMO_PRES_2',\n",
       " 'DIST2LAND_2',\n",
       " 'STORM_SPEED_2',\n",
       " 'STORM_DIR_2',\n",
       " 'storm_category_2',\n",
       " 'basin_EP_2',\n",
       " 'STORM CATEGORY_2',\n",
       " 'STORM_DISPLACEMENT_X_2',\n",
       " 'STORM_DISPLACEMENT_Y_2',\n",
       " 'LAT_3',\n",
       " 'LON_3',\n",
       " 'WMO_WIND_3',\n",
       " 'WMO_PRES_3',\n",
       " 'DIST2LAND_3',\n",
       " 'STORM_SPEED_3',\n",
       " 'STORM_DIR_3',\n",
       " 'storm_category_3',\n",
       " 'basin_EP_3',\n",
       " 'STORM CATEGORY_3',\n",
       " 'STORM_DISPLACEMENT_X_3',\n",
       " 'STORM_DISPLACEMENT_Y_3',\n",
       " 'LAT_4',\n",
       " 'LON_4',\n",
       " 'WMO_WIND_4',\n",
       " 'WMO_PRES_4',\n",
       " 'DIST2LAND_4',\n",
       " 'STORM_SPEED_4',\n",
       " 'STORM_DIR_4',\n",
       " 'storm_category_4',\n",
       " 'basin_EP_4',\n",
       " 'STORM CATEGORY_4',\n",
       " 'STORM_DISPLACEMENT_X_4',\n",
       " 'STORM_DISPLACEMENT_Y_4',\n",
       " 'LAT_5',\n",
       " 'LON_5',\n",
       " 'WMO_WIND_5',\n",
       " 'WMO_PRES_5',\n",
       " 'DIST2LAND_5',\n",
       " 'STORM_SPEED_5',\n",
       " 'STORM_DIR_5',\n",
       " 'storm_category_5',\n",
       " 'basin_EP_5',\n",
       " 'STORM CATEGORY_5',\n",
       " 'STORM_DISPLACEMENT_X_5',\n",
       " 'STORM_DISPLACEMENT_Y_5',\n",
       " 'LAT_6',\n",
       " 'LON_6',\n",
       " 'WMO_WIND_6',\n",
       " 'WMO_PRES_6',\n",
       " 'DIST2LAND_6',\n",
       " 'STORM_SPEED_6',\n",
       " 'STORM_DIR_6',\n",
       " 'storm_category_6',\n",
       " 'basin_EP_6',\n",
       " 'STORM CATEGORY_6',\n",
       " 'STORM_DISPLACEMENT_X_6',\n",
       " 'STORM_DISPLACEMENT_Y_6',\n",
       " 'LAT_7',\n",
       " 'LON_7',\n",
       " 'WMO_WIND_7',\n",
       " 'WMO_PRES_7',\n",
       " 'DIST2LAND_7',\n",
       " 'STORM_SPEED_7',\n",
       " 'STORM_DIR_7',\n",
       " 'storm_category_7',\n",
       " 'basin_EP_7',\n",
       " 'STORM CATEGORY_7',\n",
       " 'STORM_DISPLACEMENT_X_7',\n",
       " 'STORM_DISPLACEMENT_Y_7']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for tsfresh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import extract_relevant_features\n",
    "\n",
    "window_size = 16\n",
    "\n",
    "X_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "X_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "tgt_intensity_train = np.load('data/y_train_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "tgt_intensity_test = np.load('data/y_test_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "\n",
    "def prepare_fresh(X):\n",
    "    data = X.reshape(X.shape[0], window_size, X.shape[1]//window_size)\n",
    "    n, t, p = data.shape\n",
    "    new_data = np.zeros((n, t, p+2))\n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            new_data[i,j,2:] = data[i,j]\n",
    "            new_data[i,j,0] = int(i)\n",
    "            new_data[i,j,1] = int(j)\n",
    "    new_data = new_data.reshape(n*t, -1)\n",
    "    new_data = pd.DataFrame(new_data).rename(columns={0: \"storm_id\", 1: \"time\"})\n",
    "    new_data = new_data.astype({\"storm_id\": 'int32', \"time\": 'int32'})\n",
    "    for i in range(p+2):\n",
    "        new_data = new_data.rename(columns={i:\"feat_\"+str(i-1)})\n",
    "    return new_data\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'STORM_DIR', 'storm_category', 'cat_basin_EP', 'cat_basin_NI',\n",
    "'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "'cat_UNKNOWN', \n",
    "'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i//22)\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = np.array(X_train[cols])\n",
    "X_test = np.array(X_test[cols])\n",
    "\n",
    "a = prepare_fresh(np.concatenate((X_train, X_test), axis = 0))\n",
    "features_filtered_direct = extract_relevant_features(a, pd.Series(np.concatenate((tgt_intensity_train, tgt_intensity_test), axis = 0)), column_id='storm_id', column_sort='time')\n",
    "X\n",
    "np.save('data/test_features_filtered_direct_w' + str(window_size) +'.npy', np.array(features_filtered_direct), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRESH\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "window_size = 16\n",
    "\n",
    "X_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "X_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "tgt_intensity_train = np.load('data/y_train_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "tgt_intensity_test = np.load('data/y_test_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "\n",
    "fresh = np.load('data/test_features_filtered_direct_w' + str(window_size) +'.npy', allow_pickle = True)\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'STORM_DIR', 'storm_category', 'cat_basin_EP', 'cat_basin_NI',\n",
    "'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "'cat_UNKNOWN', \n",
    "'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i//22)\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-1] == '0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = np.array(X_train[cols])\n",
    "X_test = np.array(X_test[cols])\n",
    "n = tgt_intensity_train.shape[0]\n",
    "train = np.concatenate((fresh[:n], X_train), axis = 1)\n",
    "test = np.concatenate((fresh[n:], X_test), axis = 1)\n",
    "\n",
    "for i in range(6, 8)\n",
    "    xgb = XGBClassifier(max_depth=i, n_estimators=100)\n",
    "    xgb.fit(train, tgt_intensity_train)\n",
    "    yhat = xgb.predict(test)\n",
    "    print(\"XGB score depth\", i, \": \", mean_absolute_error(tgt_intensity_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PURE XGB\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "window_size = 16\n",
    "\n",
    "X_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "X_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle = True)\n",
    "\n",
    "tgt_intensity_cat_train = np.load('data/y_train_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "tgt_intensity_cat_test = np.load('data/y_test_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "\n",
    "tgt_intensity_train = np.load('data/y_train_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "tgt_intensity_test = np.load('data/y_test_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'STORM_DIR', 'storm_category', 'cat_basin_EP', 'cat_basin_NI',\n",
    "'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "'cat_UNKNOWN', \n",
    "'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i//22)\n",
    "\n",
    "    \n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "baseline = np.array(X_test['WMO_WIND_15'])\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-1] == '0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = np.array(X_train[cols])\n",
    "X_test = np.array(X_test[cols])\n",
    "\n",
    "for i in range(5,6):\n",
    "    xgb_intensity = XGBRegressor(max_depth=i, n_estimators=100)\n",
    "    xgb_intensity.fit(X_train, tgt_intensity_train)\n",
    "    yhat = xgb_intensity.predict(X_test)\n",
    "    print(\"XGB MAE score depth\", i, \": \", mean_absolute_error(tgt_intensity_test, yhat)*1.852)\n",
    "    print(\"Baseline MAE score\", mean_absolute_error(tgt_intensity_test, baseline)*1.852)\n",
    "        \n",
    "for i in range(3,6):\n",
    "    xgb_intensity_cat = XGBClassifier(max_depth=i, n_estimators=100)\n",
    "    xgb_intensity_cat.fit(X_train, tgt_intensity_cat_train)\n",
    "    yhat = xgb_intensity_cat.predict(X_test)\n",
    "    print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in [50, 80, 100, 150, 200]:\n",
    "    xgb_intensity_cat = XGBClassifier(max_depth=4, n_estimators=e)\n",
    "    xgb_intensity_cat.fit(X_train, tgt_intensity_cat_train)\n",
    "    yhat = xgb_intensity_cat.predict(X_test)\n",
    "    print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
