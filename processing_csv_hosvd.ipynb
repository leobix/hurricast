{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (1,2,8,9,14,19,20,25,161,162) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>SUBBASIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>...</th>\n",
       "      <th>BOM_GUST_PER</th>\n",
       "      <th>REUNION_GUST</th>\n",
       "      <th>REUNION_GUST_PER</th>\n",
       "      <th>USA_SEAHGT</th>\n",
       "      <th>USA_SEARAD_NE</th>\n",
       "      <th>USA_SEARAD_SE</th>\n",
       "      <th>USA_SEARAD_SW</th>\n",
       "      <th>USA_SEARAD_NW</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016005N02187</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>EP</td>\n",
       "      <td>CP</td>\n",
       "      <td>PALI</td>\n",
       "      <td>2016-01-05 06:00:00</td>\n",
       "      <td>NR</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>-173.500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016005N02187</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>EP</td>\n",
       "      <td>CP</td>\n",
       "      <td>PALI</td>\n",
       "      <td>2016-01-05 09:00:00</td>\n",
       "      <td>NR</td>\n",
       "      <td>2.04500</td>\n",
       "      <td>-173.353</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016005N02187</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>EP</td>\n",
       "      <td>CP</td>\n",
       "      <td>PALI</td>\n",
       "      <td>2016-01-05 12:00:00</td>\n",
       "      <td>NR</td>\n",
       "      <td>2.10000</td>\n",
       "      <td>-173.200</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016005N02187</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>EP</td>\n",
       "      <td>CP</td>\n",
       "      <td>PALI</td>\n",
       "      <td>2016-01-05 15:00:00</td>\n",
       "      <td>NR</td>\n",
       "      <td>2.17750</td>\n",
       "      <td>-173.042</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016005N02187</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>EP</td>\n",
       "      <td>CP</td>\n",
       "      <td>PALI</td>\n",
       "      <td>2016-01-05 18:00:00</td>\n",
       "      <td>NR</td>\n",
       "      <td>2.30000</td>\n",
       "      <td>-172.900</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SID SEASON NUMBER BASIN SUBBASIN  NAME             ISO_TIME  \\\n",
       "1  2016005N02187   2016      1    EP       CP  PALI  2016-01-05 06:00:00   \n",
       "2  2016005N02187   2016      1    EP       CP  PALI  2016-01-05 09:00:00   \n",
       "3  2016005N02187   2016      1    EP       CP  PALI  2016-01-05 12:00:00   \n",
       "4  2016005N02187   2016      1    EP       CP  PALI  2016-01-05 15:00:00   \n",
       "5  2016005N02187   2016      1    EP       CP  PALI  2016-01-05 18:00:00   \n",
       "\n",
       "  NATURE      LAT       LON  ... BOM_GUST_PER REUNION_GUST REUNION_GUST_PER  \\\n",
       "1     NR  2.00000  -173.500  ...          NaN          NaN              NaN   \n",
       "2     NR  2.04500  -173.353  ...          NaN          NaN              NaN   \n",
       "3     NR  2.10000  -173.200  ...          NaN          NaN              NaN   \n",
       "4     NR  2.17750  -173.042  ...          NaN          NaN              NaN   \n",
       "5     NR  2.30000  -172.900  ...          NaN          NaN              NaN   \n",
       "\n",
       "  USA_SEAHGT USA_SEARAD_NE USA_SEARAD_SE USA_SEARAD_SW USA_SEARAD_NW  \\\n",
       "1        NaN           NaN           NaN           NaN           NaN   \n",
       "2        NaN           NaN           NaN           NaN           NaN   \n",
       "3        NaN           NaN           NaN           NaN           NaN   \n",
       "4        NaN           NaN           NaN           NaN           NaN   \n",
       "5        NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "  STORM_SPEED STORM_DIR  \n",
       "1           3        73  \n",
       "2           3        71  \n",
       "3           3        67  \n",
       "4           4        56  \n",
       "5           4        38  \n",
       "\n",
       "[5 rows x 163 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here set up the path of your file, a priori it should be on same directory\n",
    "data0 = pd.read_csv(\"ibtracs.last3years.list.v04r00.csv\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "#drop first row \n",
    "data= data0.drop(data0.index[0])\n",
    "data = data.replace(' ', np.nan)#fill space with nan\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns after dropna =  30\n"
     ]
    }
   ],
   "source": [
    "# #count missing values along columns\n",
    "# print('missing value percentages for columns=', data.isnull().sum(axis=0)/data.shape[0])\n",
    "#drop columns with nan threashold > 0.6\n",
    "data1 = data.dropna(axis=1, thresh=int(0.5*len(data)))\n",
    "print('number of columns after dropna = ', data1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SID', 'SEASON', 'NUMBER', 'BASIN', 'SUBBASIN', 'NAME', 'ISO_TIME',\n",
       "       'NATURE', 'LAT', 'LON', 'TRACK_TYPE', 'DIST2LAND', 'LANDFALL', 'IFLAG',\n",
       "       'USA_ATCF_ID', 'USA_LAT', 'USA_LON', 'USA_STATUS', 'USA_WIND',\n",
       "       'USA_PRES', 'USA_SSHS', 'USA_R34_NE', 'USA_R34_SE', 'USA_R34_SW',\n",
       "       'USA_R34_NW', 'USA_POCI', 'USA_ROCI', 'USA_RMW', 'STORM_SPEED',\n",
       "       'STORM_DIR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SID             object\n",
       "BASIN           object\n",
       "ISO_TIME        object\n",
       "DIST2LAND      float64\n",
       "LAT            float64\n",
       "LON            float64\n",
       "USA_WIND       float64\n",
       "USA_PRES       float64\n",
       "USA_SSHS       float64\n",
       "USA_R34_NE     float64\n",
       "USA_R34_SE     float64\n",
       "USA_R34_SW     float64\n",
       "USA_R34_NW     float64\n",
       "USA_POCI       float64\n",
       "USA_ROCI       float64\n",
       "USA_RMW        float64\n",
       "STORM_SPEED    float64\n",
       "STORM_DIR      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#allows to keep only specific columns\n",
    "def select_data(data):\n",
    "    return data[['SID', 'BASIN','ISO_TIME', 'DIST2LAND', 'LAT', 'LON',  'USA_WIND',\n",
    "       'USA_PRES', 'USA_SSHS', 'USA_R34_NE', 'USA_R34_SE', 'USA_R34_SW',\n",
    "       'USA_R34_NW', 'USA_POCI', 'USA_ROCI', 'USA_RMW', 'STORM_SPEED',\n",
    "       'STORM_DIR']]#, 'BASIN', 'NATURE']]\n",
    "\n",
    "#convert columns to numeric values\n",
    "#and interpolate missing values\n",
    "def numeric_data(data):\n",
    "    for i in ['DIST2LAND', 'LAT', 'LON',  'USA_WIND',\n",
    "       'USA_PRES', 'USA_SSHS', 'USA_R34_NE', 'USA_R34_SE', 'USA_R34_SW',\n",
    "       'USA_R34_NW', 'USA_POCI', 'USA_ROCI', 'USA_RMW', 'STORM_SPEED',\n",
    "       'STORM_DIR']:\n",
    "        data[i]=pd.to_numeric(data[i],errors='coerce').astype('float64')\n",
    "        data[i]=data[i].interpolate(method='linear')\n",
    "        data[i]=data[i].fillna(method='ffill')\n",
    "        data[i]=data[i].fillna(method='bfill')\n",
    "    return data\n",
    "\n",
    "# df0 is  cleaned data \n",
    "df0 = select_data(data)\n",
    "df0 = numeric_data(df0)\n",
    "df0.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select storms belong to certain basin, storm them in a dictionary \n",
    "def storm_to_dict(data, basin='EP', min_steps=30, min_wind=30): \n",
    "    #create empty dictionary\n",
    "    dict0={}\n",
    "    ind = 0\n",
    "    #groupby SID \n",
    "    grouped = data.groupby('SID')\n",
    "    for name, df in grouped:\n",
    "#         df.reset_index(inplace=True)#reset index \n",
    "        if df['BASIN'].iloc[0]==basin:  #select only particular basin \n",
    "            if df.shape[0]>=min_steps: #select only if enough data is present \n",
    "                df = df.loc[df['USA_WIND']>=min_wind] #keep only greater than min speed\n",
    "                df = df[['DIST2LAND', 'LAT', 'LON',  'USA_WIND',\n",
    "       'USA_PRES', 'USA_SSHS', 'USA_R34_NE', 'USA_R34_SE', 'USA_R34_SW',\n",
    "       'USA_R34_NW', 'USA_POCI', 'USA_ROCI', 'USA_RMW', 'STORM_SPEED',\n",
    "       'STORM_DIR']] #keep only numerical columns \n",
    "                dict0.update({ind:df})\n",
    "                ind+=1\n",
    "    print('number of storms in basin %s is %s' %(basin, len(dict0)))\n",
    "    return dict0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>USA_WIND</th>\n",
       "      <th>USA_PRES</th>\n",
       "      <th>USA_SSHS</th>\n",
       "      <th>USA_R34_NE</th>\n",
       "      <th>USA_R34_SE</th>\n",
       "      <th>USA_R34_SW</th>\n",
       "      <th>USA_R34_NW</th>\n",
       "      <th>USA_POCI</th>\n",
       "      <th>USA_ROCI</th>\n",
       "      <th>USA_RMW</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1897.0</td>\n",
       "      <td>3.40000</td>\n",
       "      <td>-171.300</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1908.0</td>\n",
       "      <td>3.51250</td>\n",
       "      <td>-171.307</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1930.0</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>-171.300</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1965.0</td>\n",
       "      <td>4.02751</td>\n",
       "      <td>-171.200</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.40000</td>\n",
       "      <td>-171.100</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DIST2LAND      LAT      LON  USA_WIND  USA_PRES  USA_SSHS  USA_R34_NE  \\\n",
       "17     1897.0  3.40000 -171.300      30.0    1004.0      -3.0        90.0   \n",
       "18     1908.0  3.51250 -171.307      30.0    1004.0      -3.0        90.0   \n",
       "19     1930.0  3.70000 -171.300      30.0    1004.0      -1.0        90.0   \n",
       "20     1965.0  4.02751 -171.200      37.0    1002.0       0.0        90.0   \n",
       "21     2010.0  4.40000 -171.100      45.0    1000.0       0.0        90.0   \n",
       "\n",
       "    USA_R34_SE  USA_R34_SW  USA_R34_NW  USA_POCI  USA_ROCI  USA_RMW  \\\n",
       "17        60.0        90.0        80.0    1008.0     230.0     90.0   \n",
       "18        60.0        90.0        80.0    1008.0     250.0     90.0   \n",
       "19        60.0        90.0        80.0    1009.0     270.0     90.0   \n",
       "20        60.0        90.0        80.0    1008.0     260.0     82.0   \n",
       "21        60.0        90.0        80.0    1008.0     250.0     75.0   \n",
       "\n",
       "    STORM_SPEED  STORM_DIR  \n",
       "17          2.0        3.0  \n",
       "18          3.0        0.0  \n",
       "19          5.0       11.0  \n",
       "20          7.0       16.0  \n",
       "21          7.0       12.0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storm_dict[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate maximum time steps among hurricanes \n",
    "def get_tensor_shape(dict0):\n",
    "    tmax= 0 \n",
    "    #get the max time steps: \n",
    "    for i in dict0:\n",
    "        if  dict0[i].shape[0]> tmax :\n",
    "            tmax = dict0[i].shape[0]\n",
    "    \n",
    "    #dimensions \n",
    "    d0 = len(dict0)\n",
    "    d1 = dict0[0].shape[1]\n",
    "    d2=tmax\n",
    "    print('tensor shape is ', [d0,d1,d2])\n",
    "    return d0, d1, d2\n",
    "\n",
    "\n",
    "#create a tensor\n",
    "def dict_to_tensor(storm_dict):\n",
    "    d0, d1, d2 = get_tensor_shape(storm_dict) #d2 = max time step among hurricanes \n",
    "    tensor = np.zeros((d0,d1,d2)) #pad with zero \n",
    "    \n",
    "    for i in storm_dict:\n",
    "        m = storm_dict[i]\n",
    "        d2 = m.shape[0]\n",
    "        tensor[i,:,:d2] = m.to_numpy().T\n",
    "    \n",
    "    #return list of features \n",
    "    p_list = storm_dict[0].columns.tolist()\n",
    "    return tensor, p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(since_1980=False, basin = 'EP'):\n",
    "    if since_1980 == True:\n",
    "        path = \"ibtracs.since1980.list.v04r00.csv\"\n",
    "    else:\n",
    "        path = \"ibtracs.last3years.list.v04r00.csv\"\n",
    "    #read csv \n",
    "    df= pd.read_csv(path) \n",
    "    df= df.drop(data0.index[0]) #drop first row  \n",
    "    df = df.replace(' ', np.nan) #fill space with nan\n",
    "    \n",
    "    #drop columns with nan threashold > 0.6\n",
    "    df = df.dropna(axis=1, thresh=int(0.5*len(data)))\n",
    "    \n",
    "    df = select_data(df) #select useful columns \n",
    "    df = numeric_data(df) #formate to numeric \n",
    "    \n",
    "    #select based on basin \n",
    "    storm_dict = storm_to_dict(df, basin, min_steps=30, min_wind=30)\n",
    "    \n",
    "    #create tensor based on storm_dict \n",
    "    tensor, p_list  = dict_to_tensor(storm_dict)\n",
    "    return tensor, p_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of storms in basin EP is 67\n",
      "tensor shape is  [67, 15, 117]\n"
     ]
    }
   ],
   "source": [
    "tensor, p_list = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- load forecast data ----- \n",
    "from scipy.io import loadmat\n",
    "test=loadmat('forecast_tensor.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'forecast_tensor'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('models', 'O'), ('X', 'O'), ('X_flag', 'O'), ('nhc', 'O'), ('Y', 'O'), ('label', 'O'), ('predict', 'O'), ('time', 'O')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['forecast_tensor'][0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['forecast_tensor'][0][0]['nhc'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
