{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from run import Prepro\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import tensorly as tl #tensorly package\n",
    "from tensorly.decomposition import tucker #tucker decomp package\n",
    "from utils import utils_tensor as utils \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compression_error</th>\n",
       "      <th>intensity_cat_accu</th>\n",
       "      <th>intensity_cat_accu_base</th>\n",
       "      <th>mae_dx</th>\n",
       "      <th>mae_dy</th>\n",
       "      <th>mae_intensity</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>past_n_steps</th>\n",
       "      <th>pred_n_steps</th>\n",
       "      <th>reduced_ranks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.117535</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.960</td>\n",
       "      <td>1.390</td>\n",
       "      <td>12.448000</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>[5, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.757579</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.927</td>\n",
       "      <td>1.409</td>\n",
       "      <td>12.548000</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>[10, 7, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.952783</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.914</td>\n",
       "      <td>1.358</td>\n",
       "      <td>12.535000</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>[15, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.504854</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.392</td>\n",
       "      <td>2.593</td>\n",
       "      <td>2.911</td>\n",
       "      <td>15.597000</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[5, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.073582</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.392</td>\n",
       "      <td>2.335</td>\n",
       "      <td>2.911</td>\n",
       "      <td>15.682000</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[10, 7, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.310780</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.392</td>\n",
       "      <td>2.310</td>\n",
       "      <td>3.000</td>\n",
       "      <td>16.356001</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[15, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.630795</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.590</td>\n",
       "      <td>10.574000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>[5, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.482150</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.968</td>\n",
       "      <td>1.619</td>\n",
       "      <td>10.119000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>[10, 7, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.650156</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1.016</td>\n",
       "      <td>1.467</td>\n",
       "      <td>10.378000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>[15, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.076771</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.384</td>\n",
       "      <td>14.305000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>[5, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.457538</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.897</td>\n",
       "      <td>3.507</td>\n",
       "      <td>15.116000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>[10, 7, 10, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.987965</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.428</td>\n",
       "      <td>2.630</td>\n",
       "      <td>3.486</td>\n",
       "      <td>14.474000</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>[15, 7, 5, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compression_error  intensity_cat_accu  intensity_cat_accu_base  mae_dx  \\\n",
       "0           28.117535               0.565                    0.495   0.960   \n",
       "1           16.757579               0.590                    0.495   0.927   \n",
       "2           26.952783               0.594                    0.495   0.914   \n",
       "3           28.504854               0.500                    0.392   2.593   \n",
       "4           17.073582               0.570                    0.392   2.335   \n",
       "5           27.310780               0.562                    0.392   2.310   \n",
       "6           28.630795               0.622                    0.559   1.000   \n",
       "7           17.482150               0.616                    0.559   0.968   \n",
       "8           26.650156               0.630                    0.559   1.016   \n",
       "9           30.076771               0.560                    0.428   2.776   \n",
       "10          18.457538               0.576                    0.428   2.897   \n",
       "11          27.987965               0.584                    0.428   2.630   \n",
       "\n",
       "    mae_dy  mae_intensity  max_depth  past_n_steps  pred_n_steps  \\\n",
       "0    1.390      12.448000          5            16             8   \n",
       "1    1.409      12.548000          5            16             8   \n",
       "2    1.358      12.535000          5            16             8   \n",
       "3    2.911      15.597000          5            16            16   \n",
       "4    2.911      15.682000          5            16            16   \n",
       "5    3.000      16.356001          5            16            16   \n",
       "6    1.590      10.574000          5            24             8   \n",
       "7    1.619      10.119000          5            24             8   \n",
       "8    1.467      10.378000          5            24             8   \n",
       "9    3.384      14.305000          5            24            16   \n",
       "10   3.507      15.116000          5            24            16   \n",
       "11   3.486      14.474000          5            24            16   \n",
       "\n",
       "      reduced_ranks  \n",
       "0      [5, 7, 5, 5]  \n",
       "1   [10, 7, 10, 10]  \n",
       "2     [15, 7, 5, 5]  \n",
       "3      [5, 7, 5, 5]  \n",
       "4   [10, 7, 10, 10]  \n",
       "5     [15, 7, 5, 5]  \n",
       "6      [5, 7, 5, 5]  \n",
       "7   [10, 7, 10, 10]  \n",
       "8     [15, 7, 5, 5]  \n",
       "9      [5, 7, 5, 5]  \n",
       "10  [10, 7, 10, 10]  \n",
       "11    [15, 7, 5, 5]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../cluster_results/xgb_tensor_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "#vision_data = np.load('data/vision_data_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "vision_data = np.load('../data/vision_data_50_20_60_3years_v2.npy', allow_pickle = True)\n",
    "# vision_data = np.load('../../../Volumes/Samsung_T5/vision_data_50_20_90_1980_v3.npy', allow_pickle = True)\n",
    "#y = np.load('data/y_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "y = np.load('../data/y_50_20_60_3years_v2.npy', allow_pickle = True) \n",
    "# y = np.load('../../../Volumes/Samsung_T5/y_50_20_90_1980_v3.npy', allow_pickle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 60, 3, 3, 25, 25)\n",
      "(83, 60, 11)\n"
     ]
    }
   ],
   "source": [
    "print(vision_data.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset and corresponding sizes (null elements included):\n",
      "X_vision torch.Size([3071, 16, 9, 25, 25])\n",
      "X_stat torch.Size([3071, 16, 10])\n",
      "target_displacement torch.Size([3071, 8, 2])\n",
      "target_intensity torch.Size([3071])\n",
      "target_intensity_cat torch.Size([3071])\n",
      "target_intensity_cat_baseline torch.Size([3071])\n",
      "Keeping 2481 samples out of the initial 3071.\n",
      "Reshaping the displacement target...\n"
     ]
    }
   ],
   "source": [
    "train_test_split = 0.2 #how much train test data\n",
    "predict_at = 8 #steps_out\n",
    "window_size = 16 #how many timesteps from the past to take ie steps_in\n",
    "\n",
    "train_tensors, test_tensors = Prepro.process(vision_data, y, train_test_split, predict_at = predict_at, window_size=window_size)\n",
    "x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 60, 3, 3, 25, 25)\n",
      "torch.Size([496, 16, 10])\n",
      "torch.Size([496, 16, 9, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "print(vision_data.shape)\n",
    "print(x_stat_train.shape)\n",
    "print(x_viz_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximation error= 0.05237335717538372\n"
     ]
    }
   ],
   "source": [
    "viz_reduce, error = viz_reduce(x_viz_train, [5,5,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5555_lala.npy'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranks_to_str(ranks):  \n",
    "    # Converting integer list to string list \n",
    "    s = [str(i) for i in ranks] \n",
    "    # Join list items using join() \n",
    "    out = \"\".join(s)\n",
    "    return out \n",
    "\n",
    "str(ranks_to_str([5,5,5,5]))+'_lala.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c41585390>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = x_viz_train[:,-4:,:,6:19,6:19] \n",
    "plt.imshow(test[2,1,1,:,:])\n",
    "plt.figure()\n",
    "plt.imshow(x_viz_train[2,1,1,:,:])\n",
    "plt.figure()\n",
    "# plt.imshow(x_viz_reduce[2,1,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/X_train_viz_reduce_1980_50_20_90_w8.npy', viz_reduce, allow_pickle=True)\n",
    "# np.save('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', X_train, allow_pickle = True)\n",
    "# x_viz_reduce=np.load('../data/X_train_viz_reduce.npy',  allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_reduce2 = np.load('../data/X_train_viz_reduce.npy',allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 625)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viz_reduce2.reshape(viz_reduce2[0],-1,-1,-1)\n",
    "# viz_reduce2.reshape(viz_reduce2.shape[0],-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([496, 16, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_reduce2.reshape(viz_reduce2.shape[0],-1).shape\n",
    "x_stat_train.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vision data reduce dims \n",
    "def viz_reduce(tensors, core_ranks): #input: tensors, sample_size = first dimension\n",
    "    tensors = tensors.numpy()\n",
    "    #low rank decomp\n",
    "    core_out = np.zeros((tensors.shape[0], core_ranks[0], core_ranks[1], core_ranks[2], core_ranks[3]))\n",
    "    approx_error = 0 \n",
    "    for i in range(tensors.shape[0]):\n",
    "        tensor = tensors[i]\n",
    "        core, factors = tucker(tensor, core_ranks)\n",
    "        core_out[i,:,:,:] = core \n",
    "        #calculate approximation error\n",
    "        approx = utils.tucker_to_tensor(core, factors)\n",
    "        approx_error +=  tl.norm(approx-tensor)/tl.norm(tensor)*100  #euclidean norm\n",
    "    approx_error = approx_error/tensors.shape[0]\n",
    "    \n",
    "    core_out = torch.tensor(core_out).float()\n",
    "#     print('approximation error=', approx_error)\n",
    "    return core_out,  approx_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.get_norms_4d(x_viz_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function intaking x_stat, x_viz and concat them according to ranks \n",
    "def concat_stat_viz(x_stat_train, x_viz_train, reduced_ranks): #third arg is vision tensor's dimensions \n",
    "    #reshape tabular data \n",
    "    X_train = x_stat_train.reshape(x_stat_train.shape[0], -1)\n",
    "\n",
    "    #compress vision data according to reduced_ranks \n",
    "    viz = np.zeros((x_viz_train.shape[0], np.prod(reduced_ranks)))\n",
    "    avg_error = 0 \n",
    "    for i in range(x_viz_train.shape[0]):\n",
    "        viz[i,:], error = utils.viz_to_arr(x_viz_train[i].numpy(), reduced_ranks)\n",
    "        avg_error += error \n",
    "    X_train = np.concatenate((X_train.numpy(), viz), axis=1)\n",
    "    compression_error = avg_error/x_viz_train.shape[0]\n",
    "    \n",
    "    return X_train, compression_error \n",
    "\n",
    "#concat viz with tabular \n",
    "X_train, error =utils.concat_stat_viz(x_stat_train, x_viz_train, reduced_ranks=[10,7,10,10])\n",
    "X_test, error  =concat_stat_viz(x_stat_test, x_viz_test, reduced_ranks=[10,7,10,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize x:\n",
    "def standardize_x(x_viz_train, x_viz_test, x_stat_train, x_stat_test):\n",
    "    means = x_viz_train.mean(dim=(0, 1, 3, 4))\n",
    "    stds = x_viz_train.std(dim=(0, 1, 3, 4))\n",
    "\n",
    "    means_stat = x_stat_train.mean(dim=(0, 1))\n",
    "    stds_stat = x_stat_train.std(dim=(0, 1))\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        x_viz_train[:, :, i] = (x_viz_train[:, :, i] - means[i]) / stds[i]\n",
    "        x_viz_test[:, :, i] = (x_viz_test[:, :, i] - means[i]) / stds[i]\n",
    "\n",
    "    for i in range(len(means_stat)):\n",
    "        x_stat_train[:, :, i] = (x_stat_train[:, :, i] - means_stat[i]) / stds_stat[i]\n",
    "        x_stat_test[:, :, i] = (x_stat_test[:, :, i] - means_stat[i]) / stds_stat[i]\n",
    "    return x_viz_train, x_viz_test, x_stat_train, x_stat_test\n",
    "\n",
    "#standardize y: \n",
    "def standardize_y(y_train, y_test):\n",
    "    y_train = y_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "    mean = y_train.mean()\n",
    "    std = y_train.std()\n",
    "    y_train = (y_train-mean)/std\n",
    "    y_test = (y_test-mean)/std\n",
    "    return y_train, y_test, mean , std \n",
    "\n",
    "x_viz_train, x_viz_test, x_stat_train, x_stat_test = standardize_x(x_viz_train, x_viz_test, x_stat_train, x_stat_test)\n",
    "tgt_intensity_train,tgt_intensity_test, mean_intensity, std_intensity  = standardize_y(tgt_intensity_train,tgt_intensity_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.021875"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #get training and test tensors\n",
    "# ##maybe we don't have to call this for each prediction period, since x is the same, just y different? \n",
    "# # train_tensors, test_tensors = Prepro.process(vision_data, y, train_test_split, predict_at = predict_at, window_size=window_size)\n",
    "# # x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "# # x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors\n",
    "\n",
    "#need to standardize \n",
    "\n",
    "# # #concat viz with tabular \n",
    "# # X_train, compress_error =concat_stat_viz(x_stat_train, x_viz_train, reduced_ranks)\n",
    "# # X_test, _ =concat_stat_viz(x_stat_test, x_viz_test, reduced_ranks)\n",
    "\n",
    "# #run XGB on intensity\n",
    "xgb = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "xgb.fit(X_train, tgt_intensity_train)\n",
    "yhat = xgb.predict(X_test)\n",
    "mae_intensity = mean_absolute_error(tgt_intensity_test*std_intensity + mean_intensity, yhat*std_intensity+mean_intensity) \n",
    "\n",
    "\n",
    "\n",
    "# # xgb = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "# # xgb.fit(X_train, tgt_displacement_train[:,0])\n",
    "# # yhat = xgb.predict(X_test)\n",
    "# # mae_dx = mean_absolute_error(tgt_displacement_test[:,0], yhat) \n",
    "# # mae_dx\n",
    "\n",
    "# mae_intensity\n",
    "mae_intensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(vision_data, stat_data, window_size, predict_at, max_depth, reduced_ranks):\n",
    "    #get training and test tensors\n",
    "    ##maybe we don't have to call this for each prediction period, since x is the same, just y different?\n",
    "    train_test_split=0.8\n",
    "    train_tensors, test_tensors = Prepro.process(vision_data, stat_data, train_test_split, predict_at = predict_at, window_size=window_size)\n",
    "    x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "    x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors\n",
    "\n",
    "    #standardize:\n",
    "    means = x_viz_train.mean(dim=(0, 1, 3, 4))\n",
    "    stds = x_viz_train.std(dim=(0, 1, 3, 4))\n",
    "\n",
    "    means_stat = x_stat_train.mean(dim=(0, 1))\n",
    "    stds_stat = x_stat_train.std(dim=(0, 1))\n",
    "\n",
    "    for i in range(len(means)):\n",
    "        x_viz_train[:, :, i] = (x_viz_train[:, :, i] - means[i]) / stds[i]\n",
    "        x_viz_test[:, :, i] = (x_viz_test[:, :, i] - means[i]) / stds[i]\n",
    "\n",
    "    for i in range(len(means_stat)):\n",
    "        x_stat_train[:, :, i] = (x_stat_train[:, :, i] - means_stat[i]) / stds_stat[i]\n",
    "        x_stat_test[:, :, i] = (x_stat_test[:, :, i] - means_stat[i]) / stds_stat[i]\n",
    "\n",
    "    #concat viz with tabular\n",
    "    X_train, compress_error =utils.concat_stat_viz(x_stat_train, x_viz_train, reduced_ranks)\n",
    "    X_test, _ =utils.concat_stat_viz(x_stat_test, x_viz_test, reduced_ranks)\n",
    "\n",
    "    #run XGB on intensity\n",
    "    xgb = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "    xgb.fit(X_train, tgt_intensity_train)\n",
    "    yhat = xgb.predict(X_test)\n",
    "    mae_intensity = mean_absolute_error(tgt_intensity_test, yhat)\n",
    "    \n",
    "    mean_intensity = tgt_intensity_train.mean()\n",
    "    std_intensity = tgt_intensity_train.std()\n",
    "\n",
    "    #run XGB on displacement\n",
    "    xgb = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "    xgb.fit(X_train, tgt_displacement_train[:,0])\n",
    "    yhat = xgb.predict(X_test)\n",
    "    mae_dx = mean_absolute_error(tgt_displacement_test[:,0], yhat)\n",
    "\n",
    "    xgb = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "    xgb.fit(X_train, tgt_displacement_train[:,1])\n",
    "    yhat = xgb.predict(X_test)\n",
    "    mae_dy = mean_absolute_error(tgt_displacement_test[:,1], yhat)\n",
    "\n",
    "    # #run XGB on intensity category\n",
    "    xgb = XGBClassifier(max_depth=max_depth, n_estimators=80)\n",
    "    xgb.fit(X_train, tgt_intensity_cat_train)\n",
    "    yhat = xgb.predict(X_test)\n",
    "    score_xgb = accuracy_score(tgt_intensity_cat_test, yhat)\n",
    "    score_base = accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test)\n",
    "\n",
    "    return np.round(mae_intensity,3) , np.round(mae_dx,3), np.round(mae_dy,3), np.round(,3), np.round(score_xgb,3), np.round(score_base,3), compress_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4,  6,  8, 10, 12, 14, 16, 18])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset and corresponding sizes (null elements included):\n",
      "X_vision torch.Size([4233, 8, 9, 25, 25])\n",
      "X_stat torch.Size([4233, 8, 10])\n",
      "target_displacement torch.Size([4233, 2, 2])\n",
      "target_intensity torch.Size([4233])\n",
      "target_intensity_cat torch.Size([4233])\n",
      "target_intensity_cat_baseline torch.Size([4233])\n",
      "Keeping 3641 samples out of the initial 4233.\n",
      "Reshaping the displacement target...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6298e2226b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mrun_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-6298e2226b06>\u001b[0m in \u001b[0;36mrun_xgb\u001b[0;34m(window_size, predict_at, reduced_ranks)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#concat viz with tabular\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_error\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mconcat_stat_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_stat_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_viz_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mconcat_stat_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_stat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_viz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4afa779b4be1>\u001b[0m in \u001b[0;36mconcat_stat_viz\u001b[0;34m(x_stat_train, x_viz_train, reduced_ranks)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mavg_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_viz_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mviz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviz_to_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_viz_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mavg_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     print('average tensor approx pct error is', avg_error/x_viz_train.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hurricast/utils_tensor.py\u001b[0m in \u001b[0;36mviz_to_arr\u001b[0;34m(tensor, reduced_ranks)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mviz_to_arr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m#low rank decomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtucker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mout_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mtucker\u001b[0;34m(tensor, rank, ranks, n_iter_max, init, svd, tol, random_state, verbose)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mmodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     return partial_tucker(tensor, modes, rank=rank, ranks=ranks, n_iter_max=n_iter_max, init=init,\n\u001b[0;32m--> 154\u001b[0;31m                           svd=svd, tol=tol, random_state=random_state, verbose=verbose)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorly/decomposition/_tucker.py\u001b[0m in \u001b[0;36mpartial_tucker\u001b[0;34m(tensor, modes, rank, n_iter_max, init, tol, svd, random_state, verbose, ranks)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mcore_approximation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_mode_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0meigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorly/backend/core.py\u001b[0m in \u001b[0;36mpartial_svd\u001b[0;34m(self, matrix, n_eigenvecs, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eigenvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[0;32m--> 721\u001b[0;31m                 \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m                 \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_xgb(window_size, predict_at, reduced_ranks = [5,7,10,10]):\n",
    "    #get training and test tensors\n",
    "    ##maybe we don't have to call this for each prediction period, since x is the same, just y different? \n",
    "    train_tensors, test_tensors = Prepro.process(vision_data, y, train_test_split, predict_at = predict_at, window_size=window_size)\n",
    "    x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "    x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors\n",
    "    \n",
    "    #concat viz with tabular \n",
    "    X_train, compress_error =concat_stat_viz(x_stat_train, x_viz_train, reduced_ranks)\n",
    "    X_test, _ =concat_stat_viz(x_stat_test, x_viz_test, reduced_ranks)\n",
    "    \n",
    "    #run XGB on intensity\n",
    "    xgb = XGBRegressor(max_depth=max_depth, n_estimators=80)\n",
    "    xgb.fit(X_train, tgt_intensity_train)\n",
    "    yhat = xgb.predict(X_test)\n",
    "    score_xgb = mean_absolute_error(tgt_intensity_test, yhat)    \n",
    "    \n",
    "    #run XGB on displacement \n",
    "    xgb2 = XGBRegressor(max_depth=5, n_estimators=80)\n",
    "    xgb2.fit(X_train, tgt_displacement_train)\n",
    "    yhat2 = xgb.predict(X_test)\n",
    "    disp_xgb = mean_absolute_error(tgt_displacement_test, yhat2) \n",
    "    disp_base = mean_absolute_error(tgt_intensity_cat_test, tgt_displacement_baseline_test)\n",
    "    \n",
    "    return intensity_xgb, intensity_base, disp_xgb, disp_base, compress_error \n",
    "\n",
    "    \n",
    "run_xgb(window_size=8, predict_at=2, reduced_ranks = [5,7,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # #vision data to array data using tensor decomp \n",
    "# # def viz_to_arr(tensor, reduced_ranks):\n",
    "# #     #low rank decomp \n",
    "# #     core, factors = tucker(tensor, reduced_ranks)\n",
    "# #     out_arr = core.flatten()\n",
    "    \n",
    "# #     #calculate approximation error\n",
    "# #     approx = tucker_to_tensor(core, factors)\n",
    "# #     approx_error = tl.norm(approx-tensor)/tl.norm(tensor)*100  #euclidean norm \n",
    "    \n",
    "# #     return out_arr,  approx_error\n",
    "\n",
    "# out_arr, error = viz_to_arr(x_viz_train[50].numpy(), [5,7,10,10])\n",
    "# print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.8000e+00, -1.7200e+02,  5.5000e+01,  9.9400e+02,  2.1470e+03,\n",
       "         8.0000e+00,  3.2100e+02,  1.0000e+00,  4.1247e-01, -3.0800e-01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stat_train[0,1,:]\n",
    "#'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'STORM_DIR', \n",
    "\n",
    "\n",
    "#'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "#'STORM_SPEED', 'STORM_DIR', 'storm_category', 'basin_EP', 'basin_NI',\n",
    "#'basin_SI', 'basin_SP', 'basin_WP', 'nature_DS', 'nature_ET',\n",
    "#'nature_MX', 'nature_NR', 'nature_SS', 'nature_TS'\n",
    "#'STORM CATEGORY', \n",
    "#'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2514, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_displacement_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2514, 8, 9, 25, 25])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_viz_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c4a648320>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVbUlEQVR4nO3dXYycV3kH8P8z3/vhtb1e29iO7STEVbBQMZUTqFK1SVGjwEUTLiKRiypSkcwFkUjFTcQN9KISN0ClCiEZESUXEIQElFSNClFEFZAqyoIi4sgNcUyIP9a79n6Od3c+36cXHqMl8Zz/ye7szC7n/5Ms7845e97zvjPPvrt7nnmOuTtE5E9fbtATEJH+ULCLJELBLpIIBbtIIhTsIoko9PNg+ZERL4yP9/OQ3UUsQhjpY1nEGBF96Fxi5hpxmBj0UBG3B4/ok7FXXr6PJ83ELFj1alGLnRNpb12bR7u6fMtefQ32wvg4Dv3Tk5t/IOevAmvzYfKNcHthhR+nsMKPk2uEXym5iLnGnE8MFoRZiZ9zc5Qfp7YnfM7tXS06hhVjvpNynpFzijlMq0c/JOfId41CuP3KP/9b96HXM5+bzOwhM3vdzM6Z2VMbGUtENte6g93M8gC+DuDjAI4DeMzMjvdqYiLSWxu5s98L4Jy7n3f3BoDvAni4N9MSkV7bSLAfAnBhzecXO4/9ETM7ZWaTZjbZXl7ewOFEZCM2Euy3+qvGu/564O6n3f2ku5/Mj4xs4HAishEbCfaLAA6v+fw2AJc3Nh0R2SwbCfZfAjhmZneYWQnApwA835tpiUivrXud3d1bZvYEgB8DyAN42t1fC38RYO3wmma+Hj5urs7XefNN2gU5soYe0yffjMikiEm2YKfUo+SdLB/Rh6yjr+znJ9TYx9fIUQyPYwV+QsbWpAFkzZgMH9beo+ydmOexHn6SaD5Fq/tcN5RU4+4vAHhhI2OISH8oN14kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRPT1/eyWAcVqeM0yR9bI2XvMY8a40Wfja+QRb5uPKrDA5huzht4u8z61PXwytf3hg2VDEW+cj7mFkHwLz/ggHlHgIhexXs+iIIt5rzo5HwBRLxgvhq+vs9yCwDXRnV0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJRF+TamBAViIbIgTefA8grmB/RL5Mlo/YSCIjBRYi5pKLqOPAEm8aY3yujTF+mOYYvzBONiGISh6J2LyhOBTOJMrl+RitVkQ1jgh5ciyW6AIAWUQSUFQOFt2GiLwmlVQjIgp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJRH+TaiJ2hKEJMRHfnjyiD91ZA6BZEB6R0+ExSUAsj6jEh4hJmMnKEUk1w+ELs2Oc78RbKfJMohxJDskiqrqwMQCg2eYvhuXVcJmfRjWiDFBEspGV+YshRxKScrmYF1SXr133V4rItqJgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRPQ1qcbzQGNnOCmgUAgnJ9hSRLJFRN5BTOJNvh5uL67wMWKq5tR3h8+psTMiGSbifIaOVGmfD+6fCrbHJLustCKygIjVVpH2WVit0D5L1WHap7UUnm++yrOnWAUmAPBixHZV5MVbGQrvfxaqdLOhYDeztwBUAbQBtNz95EbGE5HN04s7+wPufq0H44jIJtLv7CKJ2GiwO4CfmNmvzOzUrTqY2SkzmzSzyfYyfxOFiGyOjf4Yf5+7XzazfQBeNLP/c/eX13Zw99MATgNA+fDhiD9Xichm2NCd3d0vd/6fAfBDAPf2YlIi0nvrDnYzGzGzHTc/BvAggDO9mpiI9NZGfozfD+CHZnZznO+4+38Fv8JAv72wHWFi1pNjikoUl/lvFAW2jh6xxUcWcYXZObWG+VwffuB/aZ9D5QXaZ6qxM9i+1OJr20eH52ifC6u7g+3LTb5W7xFr/jF92C4rdJcc8KIfAFAcDq+RA4Cx3YEa4RdU6HzXHezufh7Ah9b79SLSX1p6E0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRPR3RxhzZKXwm/OboywJImLnjYgM/HY5oghGMzyQRRTJiJlLc0e4/cG/eYWOEbM7ynRzjPaZa4wE2z+y8zwdY7E9RPvUSbZRKcd3lRkphucKhIs53LRcDO/4Ui9tvBgHALTqPNwsH57vEEnMCZ2v7uwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJELBLpIIBbtIIvqbVAODscohuXBSQRaT37DKE2YKKzzZwkjxkdoEP06+Rrvg+IO/DbZfj9hh5VqdJ5i8r7JE+7CkmROV39MxqhmvZtMkSTW3V2bpGLURvmvM/BjfEeY384eC7ZcK4eo9ALC6zJ+jrMlLKOWL4WSiUiHcrqQaEVGwi6RCwS6SCAW7SCIU7CKJULCLJELBLpKIPq+zO5y8OT/b2wy2t1f4lNtl/j2sVeF9yvPh9updvMBCcZ6vrV5ZDheVKJO11VilHN+1ZLESLjyRRWzJU3O+/n2wFL647YjjzLX20j7NiO2BDo4sBtvfuLSPjoH5iASQ0YjXS6k3z/Wt6M4ukggFu0giFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJKKvSTXDQ3Xc88E3g30W6+GkjosLvJDASoHvSJIV+alnxXBxChuOSJLYt0z7XDkTTtrw99XpGIf3kQwgAAsNfl2+8+Y9wfYLh8bpGHcOXaV9iqQyyK78Ch2jkgsnYAHAQpMXr2iTgioTe6p0jGsZ323HSGEWAGjUwwlJrVb4/pxl3dt1ZxdJBA12M3vazGbM7Myax8bN7EUze6Pz/+7NnaaIbFTMnf0ZAA+947GnALzk7scAvNT5XES2MBrs7v4ygLl3PPwwgGc7Hz8L4JEez0tEemy9v7Pvd/cpAOj83/UvTGZ2yswmzWyyvhBRalVENsWm/4HO3U+7+0l3P1nexUsMi8jmWG+wT5vZAQDo/D/TuymJyGZYb7A/D+DxzsePA/hRb6YjIpuFZpaY2XMA7gcwYWYXAXwRwJcBfM/MPg3gbQCPxhxsZ2EVn5h4Ndjnd/Vw9ZHXK/vpcc7meZ/qCk+CAMLJFoXLZTrC6iiv2lJZIIkSK/zXn/oeXpFlaYmf83C5EWz/yI7wjjEA8N8Ld9M+u4rhpJlyjicsnVvmlWr2lXlCzG2VhfBcJniFn1+1+X1zeZW/Xpqr4ddL1gwfx7Pur1ka7O7+WJemj7GvFZGtQxl0IolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SiL5Wqql5CWdXDwb75JEF28dLvILJziH+hpul4RHaJzcXTlSpTNMhsPT+cGIOALSGwxVMdr3OjzPvPJHo9v9Yon0u/N2ecIc7+Fxm67w6zG2VcGWdmCo0d43wijjjBV4piMkZrzBzcIxf27davMpPpRw+73ojHLKhaji6s4skQsEukggFu0giFOwiiVCwiyRCwS6SCAW7SCL6us5etBYOlMKFAq41dwTbx4t83fSD41O0z6WZXbSPkx08miN8DX34Ev9+2ia1KbISX+c9+p+8SINPnqF9Ro//ZbD9ual76RiVPF8jZ6+D24t8Df1Ck+QEAPj54jHaZ2dxNdjOdq8BgCMjfEeemPX6c1cngu0HdofX86cK3eeqO7tIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SiL4m1eTh2JELF5aYt3BRiauNcNINADQzvjvKnQev0T5vLoULbWQl/r2yuYsnZJSuhee7FFEwYvjqEO2z446jfCBiqsqvf73Jd8H5+72vBNsXMl4AY67NC5C0nSc+XauPBtv3l3lhihx4wsyBoUXa53f5cIGL2eXwdWkFdqbRnV0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJRF+Taiq5Bu4uXw72WWyHkwbeaOyjx5mL2JHk2nWekIGRVrA5WynRIYpkVxkAyNfCiR8FvgkO5v+MP5XT94SThACgsTd8zqUVUlYHwD8e/x/aJyP3mVrGE3Pmm/w53EWq0ADA64vh3XTKufA1AYDpWkSyUZs/R06SgFaul4PtWdb96+md3cyeNrMZMzuz5rEvmdklM3ul8+8TbBwRGayYH+OfAfDQLR7/mruf6Px7obfTEpFeo8Hu7i8DmOvDXERkE23kD3RPmNlvOj/m7+7WycxOmdmkmU0uzIZ3aBWRzbPeYP8GgPcDOAFgCsBXunV099PuftLdT+7aoz/+iwzKuqLP3afdve3uGYBvAuDFxEVkoNYV7GZ2YM2nnwTAdx8QkYGiC39m9hyA+wFMmNlFAF8EcL+ZnQDgAN4C8JlNnKOI9AANdnd/7BYPf2s9Bxs1w32V8A8TbzbCVUFqEYkJtRZPyNg5FK6YAwBGtutZLPDkHVzkSSgRO1pRjYgcocYETw7JLYeTgMYO8uv2s9m7aJ87R8OVgsYK/DhN5wlLmfMfXvcOXQ+2V1vhRBYAmF3lr4VGi893eTY8jtXI+bRUqUYkeQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRLR1+IVVQdeJsund5engu13jBzpyVxi1l9rrfDlGRpu0DHqR/hOIUvj4byAfDViPbnCj2MVvjvN0N5wpYyjO/kbIN9XqdI+ry0coH0Y9vwAQDvjz/ORsflg+2yNJzEsRRT1aEWss6MQfrOYD5HnOde9XXd2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBF9TappZAW81ZgI9nmbtMfszhHjyjLfwYMlSlRKTTrGxASvTFHbFX4adpTrdIyZ6ijts6PCx8mRgh0HhxbpGDGFJ66SHXmuLw3RMXbvDhedAID5t7sWPv6Dpf3h57lQ4MlIK0s8qSZX5NWVd42HXy/V6+S6KKlGRBTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SiL4m1dS8iN/WwhVKfjl7NNjOdu8AgL0V3qeU54kSVwpjwfblRomOkc/xRIrVRrhSzQppB4A/3xeu8BNrqRlODjlX3UvHqOR5stEYSfA5OBbeGQgAzk+HE7AAoLDE72ft+XCCVeuuiC17VmN2pzHah+1ClLXZGN3bdWcXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFE9HWdvZ4VcH45vDZaJOvfr8/to8eJWds+OMqLMBwcCfcZ2cl3hJmu8SIZF1bDBRb27eY7rMQU9ZhaDecNAMClxZ3B9urbfIzcRESRDPIczeb5LizNxTLtg508nwL58Np27sowHcIKfEeeUGGJm1Zq4dyNY4dmgu1zxe45DrqziySCBruZHTazn5rZWTN7zcw+13l83MxeNLM3Ov/z+j8iMjAxd/YWgM+7+wcAfBTAZ83sOICnALzk7scAvNT5XES2KBrs7j7l7r/ufFwFcBbAIQAPA3i20+1ZAI9s1iRFZOPe0+/sZnY7gA8D+AWA/e4+Bdz4hgDgln85M7NTZjZpZpP1eV51VEQ2R3Swm9kogO8DeNLd+VuSOtz9tLufdPeT5d283K6IbI6oYDezIm4E+rfd/Qedh6fN7ECn/QCA8JqAiAxUzF/jDcC3AJx196+uaXoewOOdjx8H8KPeT09EeiUmqeY+AP8A4FUze6Xz2BcAfBnA98zs0wDeBvAoG6id5bDQCO9osdoKF2ooRBSdYDu5AMBF30X7DAcSFACgnOeJLFeXeXJIqx5+Gq7MhhNdAGB6jie7tFb40125GE7qGI74s4tP8SQUJ7UeWsM8ASV/lE+mXeWFP4YuhPvkI865xZ9mtMZ5slHWDt9/WXyECmTQZ9/df47u5S8+xr5eRLYGZdCJJELBLpIIBbtIIhTsIolQsIskQsEukggFu0gi+lqpxszpbiHnr+4Jtg9XeHWY2grfqWW1yhNvhsfC2RQeUZxkZZYnmAQ28QAAZFX+NJXm+fft0irfkWRoJnxSZMMSAECObwiDfCM80PKBiPvQTDhBCwCuH+FVi2p7w32O/JgnchWrPMHqzX28so4Ph8eZWw6/ntpZ9+umO7tIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SiL4m1dSaRZy5fCDYJ0e2yLGIrI6sScqgAChUeBJEg1SQ8UBVkJusErH90EK4+khlhp9PeZ4fBhEJMayCjEUkzIxMRSQ+TZCKRCt8su0yv/75Gu/T3Bt+LVz8W379S4u8Io4P80o1qIePtUoSxrKs+/nqzi6SCAW7SCIU7CKJULCLJELBLpIIBbtIIhTsIonoe/GKcjm8pvnA4TeC7T85fzc/UI1/D2tlEadOlmgtz9eCvcXXeVEIj9Ma4ccprPDjZLymB0oL5Dj1iDyHMr/+LEWhuMyPMzrFcxj2vMb7VI+EL8zsh/hc6rt5kYxcxFp8cSl8YRpDJD8kcGF1ZxdJhIJdJBEKdpFEKNhFEqFgF0mEgl0kEQp2kUQo2EUSYR6zrUmvDmZ2FcDv1zw0AeBa3yawcdtpvttprsD2mu9WnutRd997q4a+Bvu7Dm426e4nBzaB92g7zXc7zRXYXvPdTnNdSz/GiyRCwS6SiEEH++kBH/+92k7z3U5zBbbXfLfTXP9goL+zi0j/DPrOLiJ9omAXScTAgt3MHjKz183snJk9Nah5xDCzt8zsVTN7xcwmBz2fdzKzp81sxszOrHls3MxeNLM3Ov/vHuQc1+oy3y+Z2aXONX7FzD4xyDneZGaHzeynZnbWzF4zs891Ht+y17ebgQS7meUBfB3AxwEcB/CYmR0fxFzegwfc/cQWXV99BsBD73jsKQAvufsxAC91Pt8qnsG75wsAX+tc4xPu/kKf59RNC8Dn3f0DAD4K4LOd1+pWvr63NKg7+70Azrn7eXdvAPgugIcHNJdtz91fBjD3jocfBvBs5+NnATzS10kFdJnvluTuU+7+687HVQBnARzCFr6+3Qwq2A8BuLDm84udx7YqB/ATM/uVmZ0a9GQi7Xf3KeDGCxbAvgHPJ8YTZvabzo/5W+7HYjO7HcCHAfwC2/D6DirYb1UVbyuvAd7n7n+BG792fNbM/nrQE/oT9A0A7wdwAsAUgK8Mdjp/zMxGAXwfwJPuvjTo+azHoIL9IoDDaz6/DcDlAc2FcvfLnf9nAPwQN34N2eqmzewAAHT+nxnwfILcfdrd2+6eAfgmttA1NrMibgT6t939B52Ht9X1BQYX7L8EcMzM7jCzEoBPAXh+QHMJMrMRM9tx82MADwI4E/6qLeF5AI93Pn4cwI8GOBfqZuB0fBJb5BqbmQH4FoCz7v7VNU3b6voCA8yg6yyt/CuAPICn3f1fBjIRwszuxI27OXCjzv53ttpczew5APfjxlsvpwF8EcC/A/gegCMA3gbwqLtviT+KdZnv/bjxI7wDeAvAZ27+TjxIZvZXAH4G4FUAN4vDfwE3fm/fkte3G6XLiiRCGXQiiVCwiyRCwS6SCAW7SCIU7CKJULCLJELBLpKI/wcl/ss/Zcga1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_viz_train[20,7,5,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl #tensorly package\n",
    "from tensorly.decomposition import tucker #tucker decomp package\n",
    "# import hosvd as hosvd\n",
    "test_tensor = x_viz_train[30].numpy()\n",
    "# print(test_tensor.shape)\n",
    "\n",
    "# core, factors = tucker(test_tensor)\n",
    "# print(core.shape)\n",
    "# norms = get_norms_4d(test_tensor)\n",
    "# print((norms.cumsum()/norms.sum()).head(10)) #'cumsum of norms'\n",
    "\n",
    "# #try with rank [5,5,5]\n",
    "# core, factors = tucker(test_tensor, [5,5,5,5])\n",
    "# core.flatten()\n",
    "\n",
    "# #reconstruction accuracy: \n",
    "# approx = tucker_to_tensor(core, factors)\n",
    "# # print(hosvd.error(test_tensor, approx)) \n",
    "\n",
    "#function to calculate dimensional norms  \n",
    "def get_norms_4d(tensor):   \n",
    "  \n",
    "    tensor_shape = tensor.shape\n",
    "    dim = len(tensor.shape) \n",
    "    \n",
    "    core, _ = tucker(tensor, ranks=tensor_shape)\n",
    "     \n",
    "    norm0=[]\n",
    "    for i in range(core.shape[0]):\n",
    "        norm0.append(tl.norm(core[i,:,:,:]))  \n",
    "\n",
    "    norm1=[]\n",
    "    for i in range(core.shape[1]):\n",
    "        norm1.append(tl.norm(core[:,i,:,:]))  \n",
    "\n",
    "    norm2=[]\n",
    "    for i in range(core.shape[2]):\n",
    "        norm2.append(tl.norm(core[:,:,i,:]))  \n",
    "    \n",
    "    norm3 = [] \n",
    "    for i in range(core.shape[2]):\n",
    "        norm3.append(tl.norm(core[:,:,:,i])) \n",
    "    \n",
    "    norms = pd.concat([pd.Series(norm0),pd.Series(norm1),pd.Series(norm2),pd.Series(norm3)], axis=1) \n",
    "    norms_cumsum = norms.cumsum()/norms.sum()#'cumsum of norms'\n",
    "    return norms_cumsum \n",
    "\n",
    "#function reconstruct tensor given core and factors\n",
    "def tucker_to_tensor(core, factors):\n",
    "    tensor = core.copy()\n",
    "    dim = len(core.shape)\n",
    "    for i in range(dim):\n",
    "        tensor = tl.tenalg.mode_dot(tensor, factors[i], mode=i)\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.672566920518875\n"
     ]
    }
   ],
   "source": [
    "#vision data to array data using tensor decomp \n",
    "def viz_to_arr(tensor, reduced_ranks):\n",
    "    #low rank decomp \n",
    "    core, factors = tucker(tensor, reduced_ranks)\n",
    "    out_arr = core.flatten()\n",
    "    \n",
    "    #calculate approximation error\n",
    "    approx = tucker_to_tensor(core, factors)\n",
    "    approx_error = tl.norm(approx-tensor)/tl.norm(tensor)*100  #euclidean norm \n",
    "    \n",
    "    return out_arr,  approx_error\n",
    "\n",
    "out_arr, error = viz_to_arr(x_viz_train[50].numpy(), [5,7,10,10])\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.768218</td>\n",
       "      <td>0.486046</td>\n",
       "      <td>0.485992</td>\n",
       "      <td>0.531203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.867152</td>\n",
       "      <td>0.629811</td>\n",
       "      <td>0.643634</td>\n",
       "      <td>0.671907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908902</td>\n",
       "      <td>0.762647</td>\n",
       "      <td>0.740847</td>\n",
       "      <td>0.752590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937377</td>\n",
       "      <td>0.826369</td>\n",
       "      <td>0.791783</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.961314</td>\n",
       "      <td>0.884546</td>\n",
       "      <td>0.827399</td>\n",
       "      <td>0.846564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.977005</td>\n",
       "      <td>0.928143</td>\n",
       "      <td>0.853319</td>\n",
       "      <td>0.874254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.989584</td>\n",
       "      <td>0.963088</td>\n",
       "      <td>0.873027</td>\n",
       "      <td>0.891845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.890445</td>\n",
       "      <td>0.906335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904175</td>\n",
       "      <td>0.918492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.917839</td>\n",
       "      <td>0.929491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928717</td>\n",
       "      <td>0.938784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938114</td>\n",
       "      <td>0.947473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947484</td>\n",
       "      <td>0.954630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955190</td>\n",
       "      <td>0.961204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961805</td>\n",
       "      <td>0.966880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968125</td>\n",
       "      <td>0.971824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973685</td>\n",
       "      <td>0.976385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.980380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982755</td>\n",
       "      <td>0.983882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986646</td>\n",
       "      <td>0.987284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990404</td>\n",
       "      <td>0.990375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993409</td>\n",
       "      <td>0.993301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996274</td>\n",
       "      <td>0.995905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998490</td>\n",
       "      <td>0.998294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.768218  0.486046  0.485992  0.531203\n",
       "1   0.867152  0.629811  0.643634  0.671907\n",
       "2   0.908902  0.762647  0.740847  0.752590\n",
       "3   0.937377  0.826369  0.791783  0.815600\n",
       "4   0.961314  0.884546  0.827399  0.846564\n",
       "5   0.977005  0.928143  0.853319  0.874254\n",
       "6   0.989584  0.963088  0.873027  0.891845\n",
       "7   1.000000  0.991416  0.890445  0.906335\n",
       "8        NaN  1.000000  0.904175  0.918492\n",
       "9        NaN       NaN  0.917839  0.929491\n",
       "10       NaN       NaN  0.928717  0.938784\n",
       "11       NaN       NaN  0.938114  0.947473\n",
       "12       NaN       NaN  0.947484  0.954630\n",
       "13       NaN       NaN  0.955190  0.961204\n",
       "14       NaN       NaN  0.961805  0.966880\n",
       "15       NaN       NaN  0.968125  0.971824\n",
       "16       NaN       NaN  0.973685  0.976385\n",
       "17       NaN       NaN  0.978541  0.980380\n",
       "18       NaN       NaN  0.982755  0.983882\n",
       "19       NaN       NaN  0.986646  0.987284\n",
       "20       NaN       NaN  0.990404  0.990375\n",
       "21       NaN       NaN  0.993409  0.993301\n",
       "22       NaN       NaN  0.996274  0.995905\n",
       "23       NaN       NaN  0.998490  0.998294\n",
       "24       NaN       NaN  1.000000  1.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_norms_4d(x_viz_train[50].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average tensor approx pct error is 16.294653242929595\n",
      "average tensor approx pct error is 15.749946799845878\n"
     ]
    }
   ],
   "source": [
    "#function intaking x_stat, x_viz and concat them according to ranks \n",
    "def concat_viz_tensor(x_stat_train, x_viz_train, reduced_ranks): #third arg is vision tensor's dimensions \n",
    "    #get tabular data \n",
    "    X_train = x_stat_train.reshape(x_stat_train.shape[0], -1)\n",
    "\n",
    "    #get vision data according to tensor_ranks \n",
    "    viz = np.zeros((x_viz_train.shape[0], np.prod(reduced_ranks)))\n",
    "    avg_error = 0 \n",
    "    for i in range(x_viz_train.shape[0]):\n",
    "        viz[i,:], error = viz_to_arr(x_viz_train[i].numpy(), reduced_ranks)\n",
    "        avg_error += error \n",
    "    print('average tensor approx pct error is', avg_error/x_viz_train.shape[0])   \n",
    "    X_train = np.concatenate((X_train.numpy(), viz), axis=1)\n",
    "    return X_train \n",
    "\n",
    "#concat viz with tabular \n",
    "X_train =concat_viz_tensor(x_stat_train, x_viz_train, reduced_ranks=[5,7,10,10])\n",
    "X_test =concat_viz_tensor(x_stat_test, x_viz_test, reduced_ranks=[5,7,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.5453100158982512\n",
      "Baseline score 0.45151033386327505\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=80)\n",
    "xgb.fit(X_train, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2514, 8, 9, 25, 25])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_viz_train.shape\n",
    "#samples * timesteps * number of maps * size of map * size of map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2514, 8, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stat_train.shape\n",
    "#samples * number of past timesteps * number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 60, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "#number of storms * number of timesteps * number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2514, 80])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = x_stat_train.reshape(x_stat_train.shape[0], -1)\n",
    "X_test = x_stat_test.reshape(x_stat_test.shape[0], -1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2514, 45000])\n",
      "torch.Size([629, 45000])\n"
     ]
    }
   ],
   "source": [
    "X_train_vision = x_viz_train.reshape(x_viz_train.shape[0], -1)\n",
    "X_test_vision = x_viz_test.reshape(x_viz_test.shape[0], -1)\n",
    "print(X_train_vision.shape)\n",
    "print(X_test_vision.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tab_vision = np.concatenate((X_train, X_train_vision), axis = 1)\n",
    "X_test_tab_vision = np.concatenate((X_test, X_test_vision), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2514])\n",
      "torch.Size([629])\n"
     ]
    }
   ],
   "source": [
    "print(tgt_intensity_cat_train.shape)\n",
    "print(tgt_intensity_cat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.5405405405405406\n",
      "Baseline score 0.45151033386327505\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=80)\n",
    "xgb.fit(X_train, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB score 0.5405405405405406\n",
      "Baseline score 0.45151033386327505\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=5, n_estimators=80)\n",
    "xgb.fit(x_stat_train.reshape(x_stat_train.shape[0], -1), tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(x_stat_test.reshape(x_stat_test.shape[0], -1))\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-47b2e8190d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tab_vision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_cat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tab_vision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"XGB score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_intensity_cat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_intensity_cat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_cat_baseline_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    821\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1250\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=6, n_estimators=200)\n",
    "xgb.fit(X_train_tab_vision, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test_tab_vision)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=4, n_estimators=80)\n",
    "xgb.fit(X_train_vision, tgt_intensity_cat_train)\n",
    "yhat = xgb.predict(X_test_vision)\n",
    "print(\"XGB score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score 0.8814372999709048\n",
      "Baseline score 0.8910386965376782\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train, tgt_intensity_cat_train)\n",
    "yhat = rf.predict(X_test)\n",
    "print(\"RF score\", accuracy_score(tgt_intensity_cat_test, yhat))\n",
    "print(\"Baseline score\", accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:10:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[22:10:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB x score 0.34135345\n",
      "XGB y score 0.33949062\n"
     ]
    }
   ],
   "source": [
    "xgb_x = XGBRegressor(max_depth=3, n_estimators=80)\n",
    "xgb_y = XGBRegressor(max_depth=3, n_estimators=80)\n",
    "xgb_x.fit(X_train, tgt_displacement_train[:,0])\n",
    "xgb_y.fit(X_train, tgt_displacement_train[:,1])\n",
    "\n",
    "yhat_x = xgb_x.predict(X_test)\n",
    "yhat_y = xgb_y.predict(X_test)\n",
    "print(\"XGB x score\", mean_absolute_error(tgt_displacement_test[:,0], yhat_x))\n",
    "print(\"XGB y score\", mean_absolute_error(tgt_displacement_test[:,1], yhat_y))\n",
    "#be careful for interpretation because the displacement is in degree + standardized + I did not code any baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7578)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_displacement_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_displacement_train[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(steps_in, steps_out, max_depth=5):\n",
    "    train_test_split = 0.8\n",
    "    predict_at = steps_in #steps_out\n",
    "    window_size= steps_out #how many timesteps from the past to take ie steps_in\n",
    "\n",
    "    train_tensors, test_tensors = Prepro.process(vision_data, y, train_test_split, predict_at, window_size)\n",
    "    x_viz_train, x_stat_train, tgt_intensity_cat_train, tgt_intensity_cat_baseline_train, tgt_displacement_train, tgt_intensity_train = train_tensors\n",
    "    x_viz_test, x_stat_test, tgt_intensity_cat_test, tgt_intensity_cat_baseline_test, tgt_displacement_test, tgt_intensity_test = test_tensors\n",
    "\n",
    "    #reshape and concat\n",
    "    X_train = x_stat_train.reshape(x_stat_train.shape[0], -1)\n",
    "    X_test = x_stat_test.reshape(x_stat_test.shape[0], -1)\n",
    "    X_train_vision = x_viz_train.reshape(x_viz_train.shape[0], -1)\n",
    "    X_test_vision = x_viz_test.reshape(x_viz_test.shape[0], -1)\n",
    "    X_train_tab_vision = np.concatenate((X_train, X_train_vision), axis = 1)\n",
    "    X_test_tab_vision = np.concatenate((X_test, X_test_vision), axis = 1)\n",
    "\n",
    "    #run xgb for intensity\n",
    "    xgb = XGBClassifier(max_depth, n_estimators=100)\n",
    "    xgb.fit(X_train, tgt_intensity_cat_train)\n",
    "    intensity_xgb = xgb.predict(X_test)\n",
    "\n",
    "    #run random forrest for intensity\n",
    "    rf = RandomForestClassifier(n_estimators=200)\n",
    "    rf.fit(X_train, tgt_intensity_cat_train)\n",
    "    intensity_rf = rf.predict(X_test)\n",
    "\n",
    "    #run xbg for displacement x and y\n",
    "    xgb_x = XGBRegressor(max_depth, n_estimators=100)\n",
    "    xgb_y = XGBRegressor(max_depth, n_estimators=100)\n",
    "    xgb_x.fit(X_train, tgt_displacement_train[:,0])\n",
    "    xgb_y.fit(X_train, tgt_displacement_train[:,1])\n",
    "\n",
    "    dx_xgb= xgb_x.predict(X_test)\n",
    "    dy_xgb= xgb_y.predict(X_test)\n",
    "\n",
    "    # #calculate accuracy score for intensity\n",
    "    intensity_xgb_score = accuracy_score(tgt_intensity_cat_test, intensity_xgb).round(3)\n",
    "    intensity_rf_score = accuracy_score(tgt_intensity_cat_test, intensity_rf).round(3)\n",
    "    intensity_base_score = accuracy_score(tgt_intensity_cat_test, tgt_intensity_cat_baseline_test).round(3)\n",
    "\n",
    "    #calculate displacement mae\n",
    "    dx_xgb_mae =  mean_absolute_error(tgt_displacement_test[:,0], dx_xgb).round(3)\n",
    "    dy_xgb_mae = mean_absolute_error(tgt_displacement_test[:,1], dy_xgb).round(3)\n",
    "\n",
    "    return intensity_xgb_score, intensity_rf_score, intensity_base_score, dx_xgb_mae, dy_xgb_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "#vision_data = np.load('data/vision_data_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "vision_data = np.load('data/vision_data_50_20_60_3years_v2.npy', allow_pickle = True)\n",
    "# vision_data = np.load('../../../Volumes/Samsung_T5/vision_data_50_20_90_1980_v3.npy', allow_pickle = True)\n",
    "\n",
    "#y = np.load('data/y_30_16_120_3years_test2.npy', allow_pickle = True)\n",
    "y = np.load('data/y_50_20_60_3years_v2.npy', allow_pickle = True)\n",
    "# y = np.load('../../../Volumes/Samsung_T5/y_50_20_90_1980_v3.npy', allow_pickle = True)\n",
    "\n",
    "#set up empty dataframes\n",
    "accuracy = pd.DataFrame(columns={})\n",
    "\n",
    "#prediction steps\n",
    "steps_out_list= [2] #[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "#max_depth\n",
    "max_depth_list = [4,5]\n",
    "\n",
    "#steps_in\n",
    "steps_in_list = [8]\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "    for steps_in in steps_in_list:\n",
    "        for steps_out in steps_out_list:\n",
    "            #run model\n",
    "            intensity_xgb_score, intensity_rf_score, intensity_base_score, dx_xgb_mae, dy_xgb_mae = run_models(steps_in, steps_out, max_depth)\n",
    "            #record accuracy\n",
    "            accuracy = accuracy.append({'past_n_steps': str(steps_in),\n",
    "                                              'pred_n_steps': str(t),\n",
    "                                              'max_depth': str(max_depth),\n",
    "                                              'xgb_intensity_accu': intensity_xgb_score,\n",
    "                                              'rf_intensity_accu': intensity_rf_score,\n",
    "                                              'base_intensity_accu': intensity_base_score,\n",
    "                                              'dx_xgb_mae':dx_xgb_mae,\n",
    "                                              'dy_xgb_mae':dy_xgb_mae}, ignore_index=True)\n",
    "\n",
    "#output results df\n",
    "accuracy.to_csv('cluster_results/model_accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
