{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from run import Prepro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from utils import utils_tensor as utils #import local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'window_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-784bb9741126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#x_viz: pre-processed compressed vision data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_viz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_train_viz_reduce_1980_50_20_90_w'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranks_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx_viz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_test_viz_reduce_1980_50_20_90_w'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranks_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'window_size' is not defined"
     ]
    }
   ],
   "source": [
    "# load vision and stat data \n",
    "# Leonard: perhaps we can save X_train + X_test in one .npy file, and do train/test split here? Similar with y. \n",
    "# we can keep features such as SID, year, basin etc in the front. That way we have more flexibility? \n",
    "# We can even make a df, using pd.DataFrame(values, columns = keys). Values are based on the pre-existing function, and keys we can output it (as a list) in processing function?  \n",
    "\n",
    "wind_size=8\n",
    "reduced_ranks = [5,5,3,3]\n",
    "\n",
    "\n",
    "#load x_viz: pre-processed compressed vision data \n",
    "x_viz_train = np.load('data/X_train_viz_reduce_1980_50_20_90_w'+str(window_size)+'_'+utils.ranks_to_str(reduced_ranks)+'.npy', allow_pickle=True)\n",
    "x_viz_test = np.load('data/X_test_viz_reduce_1980_50_20_90_w'+str(window_size)+'_'+utils.ranks_to_str(reduced_ranks)+'.npy', allow_pickle=True)\n",
    "#load x_stat: stat_data \n",
    "x_stat_train = np.load('data/X_train_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True).reshape(-1, window_size, 22)[:,:,:7]\n",
    "x_stat_test = np.load('data/X_test_stat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True).reshape(-1, window_size, 22)[:,:,:7]\n",
    "#standardize x: \n",
    "x_viz_train, x_viz_test = utils.standardize_x_viz(x_viz_train, x_viz_test)\n",
    "x_stat_train, x_stat_test = utils.standardize_x_stat(x_stat_train, x_stat_test)\n",
    "#concat viz and stat \n",
    "X_train=utils.concat_stat_viz(x_stat_train, x_viz_train)\n",
    "X_test=utils.concat_stat_viz(x_stat_test, x_viz_test)\n",
    "\n",
    "#load y: intensity  \n",
    "tgt_intensity_train = np.load('data/y_train_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "tgt_intensity_test = np.load('data/y_test_intensity_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "#standardize y \n",
    "tgt_intensity_train,tgt_intensity_test, mean_intensity, std_intensity  = utils.standardize_y(tgt_intensity_train,tgt_intensity_test)\n",
    "\n",
    "#load y: displacement \n",
    "# tgt_displacement_train = np.load('data/y_train_displacement_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_displacement_test = np.load('data/y_test_displacement_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "#standardize y \n",
    "# tgt_dx_train,tgt_dx_test, mean_dx, std_dx  = utils.standardize_y(tgt_displacement_train[:,0],tgt_displacement_test[:,0])\n",
    "# tgt_dy_train,tgt_dy_test, mean_dy, std_dy  = utils.standardize_y(tgt_displacement_train[:,1],tgt_displacement_test[:,1])\n",
    "\n",
    "# load y: category  \n",
    "# tgt_intensity_cat_train = np.load('data/y_train_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_intensity_cat_test = np.load('data/y_test_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_intensity_cat_baseline_train = np.load('data/y_train_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "# tgt_intensity_cat_baseline_test = np.load('data/y_test_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature selection: skit learn has built-in feature selection function, we may not need to use iai. \n",
    "# https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/ \n",
    "# here is a small example: \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X_train_sparse = X_train.copy()\n",
    "\n",
    "# fit model on training data\n",
    "model = XGBRegressor(max_depth=5, n_estimators=100)\n",
    "model.fit(X_train, tgt_intensity_train)\n",
    "\n",
    "# select features using threshold\n",
    "select = SelectFromModel(model, threshold=\"mean\", prefit=True)\n",
    "X_train_sparse = select.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grid search \n",
    "grid = GridSearchCV(estimator = XGBRegressor(learning_rate = 0.15, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, subsample=0.8, seed=1),\n",
    " param_grid = params, n_jobs=4, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "grid.fit(X_train_sparse, tgt_intensity_train)\n",
    "\n",
    "params = {\n",
    " 'min_child_weight':range(1,6,2),\n",
    " 'n_estimators':[100, 140],\n",
    " 'subsample':[0.6,0.8,1],\n",
    " 'learning_rate':[0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code \n",
    "# trying Julia below\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from xgboost import XGBClassifier\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.model_selection ÃŸimport  GridSearchCV\n",
    "\n",
    "# from julia import Julia\n",
    "# Julia(sysimage='../sys.so', compiled_modules = False)\n",
    "# from interpretableai import iai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
