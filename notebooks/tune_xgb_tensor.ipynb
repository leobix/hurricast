{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/plot/plot.py:16: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tracks/plot.py:24: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/dataset.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(warn_message)\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/tornado/plot.py:21: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n",
      "/Users/cynthiazeng/anaconda3/lib/python3.7/site-packages/tropycal/recon/plot.py:22: UserWarning: Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\n",
      "  warnings.warn(\"Warning: Cartopy is not installed in your python environment. Plotting functions will not work.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from run import Prepro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from utils import utils_tensor as utils #import local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process vision data to compressed vision data\n",
    "#pre-specify ranks \n",
    "reduced_ranks = [3,5,3,3]\n",
    "\n",
    "#get vision data: specificify data path here \n",
    "x_viz_train = np.load('../data/X_train_vision_1980_34_20_120_w8_at_8.npy',  allow_pickle = True).reshape(-1, steps_in , 9, 25, 25)\n",
    "x_viz_test = np.load('../data/X_test_vision_1980_34_20_120_w8_at_8.npy', allow_pickle = True).reshape(-1, steps_in, 9, 25, 25)\n",
    "\n",
    "#crop out some regions \n",
    "x_viz_train = x_viz_train[:,:,:,3:20,3:20]\n",
    "x_viz_test = x_viz_test[:,:,:,3:20,3:20]\n",
    "\n",
    "#standardize x viz\n",
    "x_viz_train, x_viz_test = utils.standardize_x_viz(x_viz_train,x_viz_test)\n",
    "\n",
    "print('compressing vision data for ranks ', reduced_ranks)\n",
    "#compress vision data\n",
    "x_viz_train_reduce, compress_error_train = utils.viz_reduce(x_viz_train, reduced_ranks)\n",
    "x_viz_test_reduce, compress_error_test = utils.viz_reduce(x_viz_test, reduced_ranks)\n",
    "print('ranks, compression error=',reduced_ranks, compress_error)\n",
    "\n",
    "#save data: specify data out path and save \n",
    "np.save('../data/X_train_vision_comp_1980_34_20_120.npy', x_viz_train_reduce, allow_pickle=True)\n",
    "np.save('../data/X_test_vision_comp_1980_34_20_120.npy', x_viz_test_reduce, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'window_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-784bb9741126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#x_viz: pre-processed compressed vision data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_viz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_train_viz_reduce_1980_50_20_90_w'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranks_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx_viz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/X_test_viz_reduce_1980_50_20_90_w'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranks_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'window_size' is not defined"
     ]
    }
   ],
   "source": [
    "# load vision and stat data \n",
    "window_size=8\n",
    "predict_at = 8\n",
    "reduced_ranks = [3,5,3,3]\n",
    "\n",
    "\n",
    "#load x_viz: pre-processed compressed vision data \n",
    "x_viz_train = np.load('../data/X_train_vision_comp_1980_34_20_120.npy', allow_pickle=True)\n",
    "x_viz_test = np.load('../data/X_test_vision_comp_1980_34_20_120.npy', allow_pickle=True)\n",
    "#load x_stat: stat_data \n",
    "x_stat_train = np.load('../data/X_train_stat_1980_34_20_120_w8_at_8.npy', allow_pickle=True).reshape(-1, window_size, 30)#[:,:,:14]\n",
    "x_stat_test = np.load('../data/X_test_stat_1980_34_20_120_w8_at_8.npy', allow_pickle=True).reshape(-1, window_size, 30)#[:,:,:14]\n",
    "#standardize x: \n",
    "x_viz_train, x_viz_test = utils.standardize_x_viz(x_viz_train, x_viz_test)\n",
    "x_stat_train, x_stat_test = utils.standardize_x_stat(x_stat_train, x_stat_test)\n",
    "#concat viz and stat \n",
    "X_train_total = utils.concat_stat_viz(x_stat_train.reshape(-1, 8*30), x_viz_train.reshape(-1, 3*5*3*3))\n",
    "X_test_total = utils.concat_stat_viz(x_stat_test.reshape(-1, 8*30), x_viz_test.reshape(-1, 3*5*3*3))\n",
    "\n",
    "#load y: intensity  \n",
    "tgt_intensity_train = np.load('../data/y_train_intensity_1980_34_20_120_w8_at_8.npy', allow_pickle=True)\n",
    "tgt_intensity_test = np.load('../data/y_test_intensity_1980_34_20_120_w8_at_8.npy', allow_pickle=True)\n",
    "#standardize y \n",
    "tgt_intensity_train, tgt_intensity_test, mean_, std_  = utils.standardize_y(tgt_intensity_train,tgt_intensity_test)\n",
    "\n",
    "#load y: displacement \n",
    "# tgt_displacement_train = np.load('data/y_train_displacement_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_displacement_test = np.load('data/y_test_displacement_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "#standardize y \n",
    "# tgt_dx_train,tgt_dx_test, mean_dx, std_dx  = utils.standardize_y(tgt_displacement_train[:,0],tgt_displacement_test[:,0])\n",
    "# tgt_dy_train,tgt_dy_test, mean_dy, std_dy  = utils.standardize_y(tgt_displacement_train[:,1],tgt_displacement_test[:,1])\n",
    "\n",
    "# load y: category  \n",
    "# tgt_intensity_cat_train = np.load('data/y_train_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_intensity_cat_test = np.load('data/y_test_intensity_cat_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n",
    "# tgt_intensity_cat_baseline_train = np.load('data/y_train_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy',  allow_pickle = True)\n",
    "# tgt_intensity_cat_baseline_test = np.load('data/y_test_intensity_cat_baseline_1980_50_20_90_w' + str(window_size) + '.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_displacement_train = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature selection: skit learn has built-in feature selection function, we may not need to use iai. \n",
    "# https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/ \n",
    "# here is a small example: \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X_train_sparse = X_train.copy()\n",
    "\n",
    "# fit model on training data\n",
    "#model = XGBRegressor(max_depth=5, n_estimators=100)\n",
    "#model.fit(X_train, tgt_intensity_train)\n",
    "\n",
    "# select features using threshold\n",
    "\n",
    "\n",
    "xgb2 = XGBRegressor(max_depth=8, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb2.fit(X_train_total, tgt_intensity_train)\n",
    "select = SelectFromModel(xgb2, threshold=\"mean\", prefit=True)\n",
    "X_train_sparse = select.transform(X_train_total)\n",
    "X_test_sparse = select.transform(X_test_total)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb2.predict(X_test_total))*std_+mean_))\n",
    "\n",
    "\n",
    "xgb2.fit(X_train_sparse, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb2.predict(X_test_sparse))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bytearray = xgb2.save_raw()[4:]\n",
    "def myfun(self=None):\n",
    "    return model_bytearray\n",
    "\n",
    "xgb2.save_raw = myfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../data/X_train_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "X_test = np.load('../data/X_test_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category', 'cat_basin_AN',\n",
    "         'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "         'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i // 30)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-2:] == '_0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_withforecast_2661_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "X_test_dates = pd.DataFrame(np.load('../data/X_test_stat_with_dates_columns_1980_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True)[:,:4])\n",
    "\n",
    "X_test_dates.columns = ['YEAR', 'MONTH', 'DAY', 'HOUR']\n",
    "\n",
    "names_baselines = [#'SID',\n",
    "         'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category',\n",
    "         'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp',\n",
    "         'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp',\n",
    "         'AP01_24_lat', 'AP01_24_lon', 'AP01_24_vmax', 'AP01_24_mslp',\n",
    "         'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp',\n",
    "         'NAM_24_lat', 'NAM_24_lon', 'NAM_24_vmax', 'NAM_24_mslp',\n",
    "         'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp',\n",
    "         'cat_basin_AN', 'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP',\n",
    "         #'cat_nature_DS', 'cat_nature_ET',\n",
    "         #'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 48)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines\n",
    "\n",
    "X_test_baseline = pd.concat([X_test_baseline, X_test_dates], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgb_intensity(forecast = 'SHIP', basin = 'AN', max_depth=8, n_estimators = 140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5, forecast2 = 'HWRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##grid search \n",
    "grid = GridSearchCV(estimator = XGBRegressor(learning_rate = 0.15, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, subsample=0.8, seed=1),\n",
    " param_grid = params, n_jobs=4, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "grid.fit(X_train_sparse, tgt_intensity_train)\n",
    "\n",
    "params = {\n",
    " 'min_child_weight':range(1,6,2),\n",
    " 'n_estimators':[100, 140],\n",
    " 'subsample':[0.6,0.8,1],\n",
    " 'learning_rate':[0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "grid.grid_scores_, grid.best_params_, grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
